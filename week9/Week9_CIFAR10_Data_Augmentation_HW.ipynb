{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying CIFAR-10 with Data Augmentation\n",
    "\n",
    "In this exercise, we revisit CIFAR-10 and the networks we previously built.  We will use real-time data augmentation to try to improve our results.\n",
    "\n",
    "When you are done going through the notebook, experiment with different data augmentation parameters and see if they help (or hurt!) the performance of your classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# The data, shuffled and split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Exercise 6, we built two models.  One was smaller (181K parameters) while the second was larger (1.25M) parameters.  Below we use the smaller model and train it with data augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 32)        2432      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 6, 6, 32)          25632     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 6, 6, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 288)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               147968    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 181,162\n",
      "Trainable params: 181,162\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Let's build a CNN using Keras' Sequential capabilities\n",
    "\n",
    "model_1 = Sequential()\n",
    "\n",
    "\n",
    "## 5x5 convolution with 2x2 stride and 32 filters\n",
    "model_1.add(Conv2D(32, (5, 5), strides = (2,2), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model_1.add(Activation('relu'))\n",
    "\n",
    "## Another 5x5 convolution with 2x2 stride and 32 filters\n",
    "model_1.add(Conv2D(32, (5, 5), strides = (2,2)))\n",
    "model_1.add(Activation('relu'))\n",
    "\n",
    "## 2x2 max pooling reduces to 3 x 3 x 32\n",
    "model_1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_1.add(Dropout(0.25))\n",
    "\n",
    "## Flatten turns 3x3x32 into 288x1\n",
    "model_1.add(Flatten())\n",
    "model_1.add(Dense(512))\n",
    "model_1.add(Activation('relu'))\n",
    "model_1.add(Dropout(0.5))\n",
    "model_1.add(Dense(num_classes))\n",
    "model_1.add(Activation('softmax'))\n",
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still have 181K parameters, even though this is a \"small\" model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.rmsprop(lr=0.0005, decay=1e-6)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model_1.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define the `ImageDataGenerator` that we will use to serve images to our model during the training process.  Currently, it is configured to do some shifting and horizontal flipping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1562/1562 [==============================] - 42s 27ms/step - loss: 1.8197 - acc: 0.3363 - val_loss: 1.4811 - val_acc: 0.4510\n",
      "Epoch 2/15\n",
      "1562/1562 [==============================] - 49s 32ms/step - loss: 1.5840 - acc: 0.4277 - val_loss: 1.3514 - val_acc: 0.5065\n",
      "Epoch 3/15\n",
      "1562/1562 [==============================] - 46s 30ms/step - loss: 1.4940 - acc: 0.4636 - val_loss: 1.3178 - val_acc: 0.5231\n",
      "Epoch 4/15\n",
      "1562/1562 [==============================] - 46s 29ms/step - loss: 1.4397 - acc: 0.4833 - val_loss: 1.2475 - val_acc: 0.5536\n",
      "Epoch 5/15\n",
      "1562/1562 [==============================] - 46s 30ms/step - loss: 1.4073 - acc: 0.4970 - val_loss: 1.2242 - val_acc: 0.5624\n",
      "Epoch 6/15\n",
      "1562/1562 [==============================] - 46s 30ms/step - loss: 1.3844 - acc: 0.5104 - val_loss: 1.2074 - val_acc: 0.5801\n",
      "Epoch 7/15\n",
      "1562/1562 [==============================] - 47s 30ms/step - loss: 1.3663 - acc: 0.5179 - val_loss: 1.1453 - val_acc: 0.6011\n",
      "Epoch 8/15\n",
      "1562/1562 [==============================] - 47s 30ms/step - loss: 1.3542 - acc: 0.5238 - val_loss: 1.1284 - val_acc: 0.6062\n",
      "Epoch 9/15\n",
      "1562/1562 [==============================] - 47s 30ms/step - loss: 1.3657 - acc: 0.5199 - val_loss: 1.1516 - val_acc: 0.5973\n",
      "Epoch 10/15\n",
      "1562/1562 [==============================] - 46s 30ms/step - loss: 1.3672 - acc: 0.5208 - val_loss: 1.1939 - val_acc: 0.5994\n",
      "Epoch 11/15\n",
      "1562/1562 [==============================] - 46s 29ms/step - loss: 1.3730 - acc: 0.5223 - val_loss: 1.1669 - val_acc: 0.5979\n",
      "Epoch 12/15\n",
      "1562/1562 [==============================] - 46s 29ms/step - loss: 1.3697 - acc: 0.5215 - val_loss: 1.1734 - val_acc: 0.6033\n",
      "Epoch 13/15\n",
      "1562/1562 [==============================] - 46s 29ms/step - loss: 1.3763 - acc: 0.5192 - val_loss: 1.1879 - val_acc: 0.5896\n",
      "Epoch 14/15\n",
      "1562/1562 [==============================] - 48s 31ms/step - loss: 1.3901 - acc: 0.5185 - val_loss: 1.2289 - val_acc: 0.5863\n",
      "Epoch 15/15\n",
      "1562/1562 [==============================] - 45s 29ms/step - loss: 1.3960 - acc: 0.5178 - val_loss: 1.2037 - val_acc: 0.5891\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8cc83b0710>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "    samplewise_center=False,  # set each sample mean to 0\n",
    "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False,  # divide each input by its std\n",
    "    zca_whitening=False,  # apply ZCA whitening\n",
    "    rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip=True,  # randomly flip images\n",
    "    vertical_flip=False)  # randomly flip images\n",
    "                   \n",
    "datagen.fit(x_train)      # This computes any statistics that may be needed (e.g. for centering) from the training set.\n",
    "\n",
    "    \n",
    "# Fit the model on the batches generated by datagen.flow().\n",
    "model_1.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                 batch_size=batch_size),\n",
    "                    steps_per_epoch=x_train.shape[0] // batch_size,\n",
    "                    epochs=15,\n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does the performance compare with the non-augmented training?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "1562/1562 [==============================] - 47s 30ms/step - loss: 1.7990 - acc: 0.3406 - val_loss: 1.5096 - val_acc: 0.4606\n",
      "Epoch 2/8\n",
      "1562/1562 [==============================] - 58s 37ms/step - loss: 1.5225 - acc: 0.4488 - val_loss: 1.3486 - val_acc: 0.5149\n",
      "Epoch 3/8\n",
      "1562/1562 [==============================] - 39s 25ms/step - loss: 1.4085 - acc: 0.4960 - val_loss: 1.3050 - val_acc: 0.5413\n",
      "Epoch 4/8\n",
      "1562/1562 [==============================] - 40s 25ms/step - loss: 1.3367 - acc: 0.5242 - val_loss: 1.1917 - val_acc: 0.5780\n",
      "Epoch 5/8\n",
      "1562/1562 [==============================] - 32s 20ms/step - loss: 1.2962 - acc: 0.5433 - val_loss: 1.1528 - val_acc: 0.5944\n",
      "Epoch 6/8\n",
      "1562/1562 [==============================] - 33s 21ms/step - loss: 1.2725 - acc: 0.5553 - val_loss: 1.2614 - val_acc: 0.5805\n",
      "Epoch 7/8\n",
      "1562/1562 [==============================] - 36s 23ms/step - loss: 1.2570 - acc: 0.5616 - val_loss: 1.1331 - val_acc: 0.6068\n",
      "Epoch 8/8\n",
      "1562/1562 [==============================] - 30s 19ms/step - loss: 1.2545 - acc: 0.5655 - val_loss: 1.1091 - val_acc: 0.6140\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8cc6831e80>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1b = Sequential()\n",
    "model_1b.add(Conv2D(32, (5, 5), strides = (2,2), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model_1b.add(Activation('relu'))\n",
    "model_1b.add(Conv2D(32, (5, 5), strides = (2,2)))\n",
    "model_1b.add(Activation('relu'))\n",
    "model_1b.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_1b.add(Dropout(0.25))\n",
    "model_1b.add(Flatten())\n",
    "model_1b.add(Dense(512))\n",
    "model_1b.add(Activation('relu'))\n",
    "model_1b.add(Dropout(0.5))\n",
    "model_1b.add(Dense(num_classes))\n",
    "model_1b.add(Activation('softmax'))\n",
    "model_1b.compile(loss='categorical_crossentropy',\n",
    "                 optimizer=opt,\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "datagen_b = ImageDataGenerator(\n",
    "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "    samplewise_center=False,  # set each sample mean to 0\n",
    "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False,  # divide each input by its std\n",
    "    zca_whitening=False,  # apply ZCA whitening\n",
    "    rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    width_shift_range=0.0,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.0,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip=False,  # randomly flip images\n",
    "    vertical_flip=False)  # randomly flip images\n",
    "                   \n",
    "datagen_b.fit(x_train)      # This computes any statistics that may be needed (e.g. for centering) from the training set.\n",
    "\n",
    "    \n",
    "# Fit the model on the batches generated by datagen.flow().\n",
    "model_1b.fit_generator(datagen_b.flow(x_train, y_train,\n",
    "                                 batch_size=batch_size),\n",
    "                    steps_per_epoch=x_train.shape[0] // batch_size,\n",
    "                    epochs=8,\n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Exercise\n",
    "### Your Turn\n",
    "\n",
    "1. Experiment above with different settings of the data augmentation parameters.  Can you make the model do better?  Can you make it do worse?\n",
    "\n",
    "2. As in Exercise 6, Build a more complicated model with the following pattern:\n",
    "    - Conv -> Conv -> MaxPool -> Conv -> Conv -> MaxPool -> (Flatten) -> Dense -> Final Classification\n",
    "    - Use strides of 1 for all convolutional layers.\n",
    "\n",
    "3. Use data augmentation to train this model.  Can you get better performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 32, 32, 32)        2432      \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 28, 28, 32)        25632     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 26, 26, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 21632)             0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 512)               11076096  \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 11,127,786\n",
      "Trainable params: 11,127,786\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/8\n",
      "1562/1562 [==============================] - 534s 342ms/step - loss: 1.6352 - acc: 0.4082 - val_loss: 1.3018 - val_acc: 0.5357\n",
      "Epoch 2/8\n",
      "1562/1562 [==============================] - 488s 312ms/step - loss: 1.3496 - acc: 0.5211 - val_loss: 1.3362 - val_acc: 0.5426\n",
      "Epoch 3/8\n",
      "1562/1562 [==============================] - 533s 341ms/step - loss: 1.2367 - acc: 0.5663 - val_loss: 1.0910 - val_acc: 0.6202\n",
      "Epoch 4/8\n",
      "1562/1562 [==============================] - 489s 313ms/step - loss: 1.1853 - acc: 0.5851 - val_loss: 1.0485 - val_acc: 0.6307\n",
      "Epoch 5/8\n",
      "1562/1562 [==============================] - 549s 351ms/step - loss: 1.1636 - acc: 0.5987 - val_loss: 1.0041 - val_acc: 0.6550\n",
      "Epoch 6/8\n",
      "1562/1562 [==============================] - 601s 384ms/step - loss: 1.1447 - acc: 0.6078 - val_loss: 0.9906 - val_acc: 0.6643\n",
      "Epoch 7/8\n",
      "1562/1562 [==============================] - 577s 369ms/step - loss: 1.1560 - acc: 0.6084 - val_loss: 1.0513 - val_acc: 0.6477\n",
      "Epoch 8/8\n",
      "1562/1562 [==============================] - 583s 373ms/step - loss: 1.1571 - acc: 0.6095 - val_loss: 1.1236 - val_acc: 0.6095\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8cc624d9b0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's build a CNN using Keras' Sequential capabilities\n",
    "\n",
    "# Please provide your code here\n",
    "\n",
    "\n",
    "model_2 = Sequential()\n",
    "model_2.add(Conv2D(32, (5, 5), strides = (1, 1), padding='same',\n",
    "                 input_shape=x_train.shape[1:], activation='relu'))\n",
    "model_2.add(Conv2D(32, (5, 5), strides = (1, 1), activation='relu'))\n",
    "model_2.add(MaxPooling2D(pool_size=(1, 1)))\n",
    "model_2.add(Conv2D(32, (3, 3), strides = (1, 1), padding='same',\n",
    "                 input_shape=x_train.shape[1:], activation='relu'))\n",
    "model_2.add(Conv2D(32, (3, 3), strides = (1, 1), activation='relu'))\n",
    "model_2.add(MaxPooling2D(pool_size=(1, 1)))\n",
    "model_2.add(Flatten())\n",
    "model_2.add(Dense(512, activation='relu'))\n",
    "model_2.add(Dropout(0.5))\n",
    "model_2.add(Dense(num_classes, activation='softmax'))\n",
    "model_2.compile(loss='categorical_crossentropy',\n",
    "                 optimizer=opt,\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "model_2.summary()\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "    samplewise_center=False,  # set each sample mean to 0\n",
    "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False,  # divide each input by its std\n",
    "    zca_whitening=False,  # apply ZCA whitening\n",
    "    rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip=True,  # randomly flip images\n",
    "    vertical_flip=False)  # randomly flip images\n",
    "                   \n",
    "datagen.fit(x_train)      # This computes any statistics that may be needed (e.g. for centering) from the training set.\n",
    "\n",
    "    \n",
    "# Fit the model on the batches generated by datagen.flow().\n",
    "model_2.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                 batch_size=batch_size),\n",
    "                    steps_per_epoch=x_train.shape[0] // batch_size,\n",
    "                    epochs=8,\n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Check number of parameters (print the summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initiate RMSprop optimizer\n",
    "\n",
    "# Let's train the model using RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute quantities required for feature-wise normalization\n",
    "\n",
    "\n",
    "# Fit the model on the batches generated by datagen.flow()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_16 (Conv2D)           (None, 32, 32, 32)        2432      \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 28, 28, 32)        25632     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 26, 26, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 21632)             0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 512)               11076096  \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 11,127,786\n",
      "Trainable params: 11,127,786\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/4\n",
      "1562/1562 [==============================] - 565s 362ms/step - loss: 1.5420 - acc: 0.4454 - val_loss: 1.2744 - val_acc: 0.5458\n",
      "Epoch 2/4\n",
      "1562/1562 [==============================] - 529s 339ms/step - loss: 1.1825 - acc: 0.5861 - val_loss: 1.0556 - val_acc: 0.6337\n",
      "Epoch 3/4\n",
      "1562/1562 [==============================] - 526s 337ms/step - loss: 1.0457 - acc: 0.6365 - val_loss: 1.1330 - val_acc: 0.6020\n",
      "Epoch 4/4\n",
      "1562/1562 [==============================] - 474s 303ms/step - loss: 0.9604 - acc: 0.6713 - val_loss: 1.0251 - val_acc: 0.6508\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8c96bad978>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's build a CNN using Keras' Sequential capabilities\n",
    "\n",
    "# Please provide your code here\n",
    "\n",
    "\n",
    "model_2b = Sequential()\n",
    "model_2b.add(Conv2D(32, (5, 5), strides = (1, 1), padding='same',\n",
    "                 input_shape=x_train.shape[1:], activation='relu'))\n",
    "model_2b.add(Conv2D(32, (5, 5), strides = (1, 1), activation='relu'))\n",
    "model_2b.add(MaxPooling2D(pool_size=(1, 1)))\n",
    "model_2b.add(Conv2D(32, (3, 3), strides = (1, 1), padding='same',\n",
    "                 input_shape=x_train.shape[1:], activation='relu'))\n",
    "model_2b.add(Conv2D(32, (3, 3), strides = (1, 1), activation='relu'))\n",
    "model_2b.add(MaxPooling2D(pool_size=(1, 1)))\n",
    "model_2b.add(Flatten())\n",
    "model_2b.add(Dense(512, activation='relu'))\n",
    "model_2b.add(Dropout(0.5))\n",
    "model_2b.add(Dense(num_classes, activation='softmax'))\n",
    "model_2b.compile(loss='categorical_crossentropy',\n",
    "                 optimizer=opt,\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "model_2b.summary()\n",
    "\n",
    "datagen_b = ImageDataGenerator(\n",
    "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "    samplewise_center=False,  # set each sample mean to 0\n",
    "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False,  # divide each input by its std\n",
    "    zca_whitening=False,  # apply ZCA whitening\n",
    "    rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    width_shift_range=0.0,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.0,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip=False,  # randomly flip images\n",
    "    vertical_flip=False)  # randomly flip images\n",
    "                   \n",
    "datagen_b.fit(x_train)      # This computes any statistics that may be needed (e.g. for centering) from the training set.\n",
    "\n",
    "    \n",
    "# Fit the model on the batches generated by datagen.flow().\n",
    "model_2b.fit_generator(datagen_b.flow(x_train, y_train,\n",
    "                                 batch_size=batch_size),\n",
    "                    steps_per_epoch=x_train.shape[0] // batch_size,\n",
    "                    epochs=4,\n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1562/1562 [==============================] - 558s 357ms/step - loss: 0.9046 - acc: 0.6946 - val_loss: 1.1325 - val_acc: 0.6584\n",
      "Epoch 2/2\n",
      "1562/1562 [==============================] - 546s 350ms/step - loss: 0.8659 - acc: 0.7119 - val_loss: 1.0586 - val_acc: 0.6412\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8cc6409a20>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2b.fit_generator(datagen_b.flow(x_train, y_train,\n",
    "                                 batch_size=batch_size),\n",
    "                    steps_per_epoch=x_train.shape[0] // batch_size,\n",
    "                    epochs=2,\n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
