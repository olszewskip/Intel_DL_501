{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Skipgrams in Keras\n",
    "\n",
    "- In this lecture, we will implement Skipgrams in `Keras`.\n",
    "\n",
    "#### Loading in and preprocessing data\n",
    "- Load the Alice in Wonderland data in Corpus using Keras utility\n",
    "- `Keras` has some nice text preprocessing features too!\n",
    "- Split the text into sentences.\n",
    "- Use `Keras`' `Tokenizer` to tokenize sentences into words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "init_cell": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "# Basics\n",
    "from __future__ import print_function, division\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import random\n",
    "from IPython.display import SVG\n",
    "%matplotlib inline\n",
    "\n",
    "# nltk\n",
    "from nltk import sent_tokenize\n",
    "\n",
    "# keras\n",
    "np.random.seed(13)\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Embedding, Reshape, Activation\n",
    "from keras.layers import add\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils.vis_utils import model_to_dot \n",
    "from keras.preprocessing.sequence import skipgrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/olszewskip/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# We'll use Alice in Wonderland\n",
    "\n",
    "path = get_file('carrol-alice.txt', origin=\"http://www.gutenberg.org/files/11/11-0.txt\")\n",
    "corpus = open(path).read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163817"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ufeffProject Gutenberg’s Alice’s Adventures in Wonderland, by Lewis Carroll\\n\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[: corpus.index('\\n\\n')+2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CHAPTER I. Down the Rabbit-Hole\\n\\nAlice was beginning to get very tired of sitting by her sister on t'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = corpus.index(\"CHAPTER I\")\n",
    "corpus[start:start+100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split document into sentences first\n",
    "corpus = corpus[start:]  # remove header.\n",
    "sentences = sent_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CHAPTER I.',\n",
       " 'Down the Rabbit-Hole\\n\\nAlice was beginning to get very tired of sitting by her sister on the\\nbank, and of having nothing to do: once or twice she had peeped into the\\nbook her sister was reading, but it had no pictures or conversations in\\nit, ‘and what is the use of a book,’ thought Alice ‘without pictures or\\nconversations?’\\n\\nSo she was considering in her own mind (as well as she could, for the\\nhot day made her feel very sleepy and stupid), whether the pleasure\\nof making a daisy-chain would be worth the trouble of getting up and\\npicking the daisies, when suddenly a White Rabbit with pink eyes ran\\nclose by her.',\n",
       " 'There was nothing so VERY remarkable in that; nor did Alice think it so\\nVERY much out of the way to hear the Rabbit say to itself, ‘Oh dear!',\n",
       " 'Oh dear!',\n",
       " 'I shall be late!’ (when she thought it over afterwards, it\\noccurred to her that she ought to have wondered at this, but at the time\\nit all seemed quite natural); but when the Rabbit actually TOOK A WATCH\\nOUT OF ITS WAISTCOAT-POCKET, and looked at it, and then hurried on,\\nAlice started to her feet, for it flashed across her mind that she had\\nnever before seen a rabbit with either a waistcoat-pocket, or a watch\\nto take out of it, and burning with curiosity, she ran across the field\\nafter it, and fortunately was just in time to see it pop down a large\\nrabbit-hole under the hedge.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize using Keras\n",
    "base_filter='!\"#$%&()*+,-./:;`<=>?@[\\\\]^_{|}~\\t\\n' + \"'\"\n",
    "tokenizer = Tokenizer(filters=base_filter)\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "# Convert tokenized sentences to sequence format\n",
    "sequences = tokenizer.texts_to_sequences(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[343, 15],\n",
       " [37,\n",
       "  1,\n",
       "  109,\n",
       "  704,\n",
       "  12,\n",
       "  13,\n",
       "  275,\n",
       "  4,\n",
       "  116,\n",
       "  29,\n",
       "  550,\n",
       "  6,\n",
       "  405,\n",
       "  59,\n",
       "  17,\n",
       "  481,\n",
       "  20,\n",
       "  1,\n",
       "  1005,\n",
       "  3,\n",
       "  6,\n",
       "  406,\n",
       "  152,\n",
       "  4,\n",
       "  44,\n",
       "  148,\n",
       "  27,\n",
       "  705,\n",
       "  7,\n",
       "  22,\n",
       "  1006,\n",
       "  68,\n",
       "  1,\n",
       "  373,\n",
       "  17,\n",
       "  481,\n",
       "  13,\n",
       "  819,\n",
       "  30,\n",
       "  8,\n",
       "  22,\n",
       "  47,\n",
       "  820,\n",
       "  27,\n",
       "  1300,\n",
       "  10,\n",
       "  8,\n",
       "  79,\n",
       "  41,\n",
       "  31,\n",
       "  1,\n",
       "  161,\n",
       "  6,\n",
       "  5,\n",
       "  373,\n",
       "  2,\n",
       "  62,\n",
       "  12,\n",
       "  1829,\n",
       "  820,\n",
       "  27,\n",
       "  1300,\n",
       "  2,\n",
       "  28,\n",
       "  7,\n",
       "  13,\n",
       "  1007,\n",
       "  10,\n",
       "  17,\n",
       "  407,\n",
       "  374,\n",
       "  16,\n",
       "  121,\n",
       "  16,\n",
       "  7,\n",
       "  57,\n",
       "  24,\n",
       "  1,\n",
       "  551,\n",
       "  162,\n",
       "  153,\n",
       "  17,\n",
       "  482,\n",
       "  29,\n",
       "  706,\n",
       "  3,\n",
       "  1008,\n",
       "  375,\n",
       "  1,\n",
       "  1301,\n",
       "  6,\n",
       "  483,\n",
       "  5,\n",
       "  1830,\n",
       "  1831,\n",
       "  58,\n",
       "  25,\n",
       "  821,\n",
       "  1,\n",
       "  624,\n",
       "  6,\n",
       "  203,\n",
       "  39,\n",
       "  3,\n",
       "  1302,\n",
       "  1,\n",
       "  1832,\n",
       "  60,\n",
       "  314,\n",
       "  5,\n",
       "  154,\n",
       "  109,\n",
       "  18,\n",
       "  1833,\n",
       "  163,\n",
       "  258,\n",
       "  315,\n",
       "  59,\n",
       "  17]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1092 1092\n"
     ]
    }
   ],
   "source": [
    "# nb_samples = sum(len(s) for s in corpus)  # whats that for?\n",
    "\n",
    "print(len(sequences), tokenizer.document_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Caterpillar was the first to speak.\n",
      "[1, 181, 13, 1, 98, 4, 328]\n",
      "[1, 181, 13, 1, 98, 4, 328]\n"
     ]
    }
   ],
   "source": [
    "# To understand what is happening;\n",
    "\n",
    "print(sentences[323])  # this is a sentence\n",
    "print(sequences[323])  # this is the same sentence where words are encoded as numbers.\n",
    "print(list(tokenizer.word_index[word.lower().replace('.', '')] for word in sentences[323].split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Skipgrams: Generating Input and Output Labels\n",
    "- Now that we have sentences, and word tokenization, we are in good position to create our training set for skipgrams.\n",
    "- Now we need to generate our `X_train` and `y_train`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's first see how Keras' skipgrams function works.\n",
    "\n",
    "couples, labels = skipgrams(sequences[323], len(tokenizer.word_index) + 1,\n",
    "    window_size=2, negative_samples=0, shuffle=True,\n",
    "    categorical=False, sampling_table=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 181, 13, 1, 98, 4, 328]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[323]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[98, 13],\n",
       " [328, 4],\n",
       " [181, 1],\n",
       " [4, 98],\n",
       " [1, 4],\n",
       " [1, 13],\n",
       " [13, 98],\n",
       " [1, 181],\n",
       " [181, 13],\n",
       " [13, 1],\n",
       " [1, 98],\n",
       " [1, 181],\n",
       " [98, 4],\n",
       " [181, 1],\n",
       " [328, 98],\n",
       " [98, 1],\n",
       " [4, 328],\n",
       " [98, 328],\n",
       " [13, 1],\n",
       " [4, 1],\n",
       " [13, 181],\n",
       " [1, 13]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "couples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 1),\n",
       " ('’', 2),\n",
       " ('and', 3),\n",
       " ('to', 4),\n",
       " ('a', 5),\n",
       " ('of', 6),\n",
       " ('she', 7),\n",
       " ('it', 8),\n",
       " ('said', 9),\n",
       " ('in', 10)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tokenizer.word_index.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_2_word = {val: key for key, val in tokenizer.word_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first was\n",
      "speak to\n",
      "caterpillar the\n",
      "to first\n",
      "the to\n",
      "the was\n",
      "was first\n",
      "the caterpillar\n",
      "caterpillar was\n",
      "was the\n",
      "the first\n",
      "the caterpillar\n",
      "first to\n",
      "caterpillar the\n",
      "speak first\n",
      "first the\n",
      "to speak\n",
      "first speak\n",
      "was the\n",
      "to the\n",
      "was caterpillar\n",
      "the was\n"
     ]
    }
   ],
   "source": [
    "for w1, w2 in couples:\n",
    "    print(index_2_word[w1], index_2_word[w2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Function to generate the inputs and outputs for all windows\n",
    "\n",
    "# Vocab size\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "# Dimension to reduce to\n",
    "dim = 100\n",
    "window_size = 2\n",
    "\n",
    "\n",
    "def generate_data(sequences, window_size, vocab_size):\n",
    "    for seq in sequences:\n",
    "        X, y = [], []\n",
    "        couples, _ = skipgrams(\n",
    "            seq, vocab_size,\n",
    "            window_size=window_size, negative_samples=0, shuffle=True,\n",
    "            categorical=False, sampling_table=None)\n",
    "        if not couples:\n",
    "            continue\n",
    "        for in_word, out_word in couples:\n",
    "            X.append(in_word)\n",
    "            y.append(np_utils.to_categorical(out_word, vocab_size))\n",
    "        X, y = np.array(X), np.array(y)\n",
    "        X = X.reshape(len(X), 1)\n",
    "        y = y.reshape(len(X), vocab_size)\n",
    "        yield X, y\n",
    "        \n",
    "data_generator = generate_data(sequences, window_size, vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Skipgrams: Creating the Model\n",
    "- Lastly, we create the (shallow) network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"294pt\" viewBox=\"0.00 0.00 321.00 294.00\" width=\"321pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 290)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-290 317,-290 317,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 140201670946152 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>140201670946152</title>\n",
       "<polygon fill=\"none\" points=\"0,-166.5 0,-212.5 313,-212.5 313,-166.5 0,-166.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"80.5\" y=\"-185.8\">embedding_1: Embedding</text>\n",
       "<polyline fill=\"none\" points=\"161,-166.5 161,-212.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"188.5\" y=\"-197.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"161,-189.5 216,-189.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"188.5\" y=\"-174.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"216,-166.5 216,-212.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"264.5\" y=\"-197.3\">(None, 1)</text>\n",
       "<polyline fill=\"none\" points=\"216,-189.5 313,-189.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"264.5\" y=\"-174.3\">(None, 1, 100)</text>\n",
       "</g>\n",
       "<!-- 140201670942792 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>140201670942792</title>\n",
       "<polygon fill=\"none\" points=\"18,-83.5 18,-129.5 295,-129.5 295,-83.5 18,-83.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"80.5\" y=\"-102.8\">reshape_1: Reshape</text>\n",
       "<polyline fill=\"none\" points=\"143,-83.5 143,-129.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"170.5\" y=\"-114.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"143,-106.5 198,-106.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"170.5\" y=\"-91.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"198,-83.5 198,-129.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"246.5\" y=\"-114.3\">(None, 1, 100)</text>\n",
       "<polyline fill=\"none\" points=\"198,-106.5 295,-106.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"246.5\" y=\"-91.3\">(None, 100)</text>\n",
       "</g>\n",
       "<!-- 140201670946152&#45;&gt;140201670942792 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>140201670946152-&gt;140201670942792</title>\n",
       "<path d=\"M156.5,-166.3799C156.5,-158.1745 156.5,-148.7679 156.5,-139.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"160.0001,-139.784 156.5,-129.784 153.0001,-139.784 160.0001,-139.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140201670945592 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>140201670945592</title>\n",
       "<polygon fill=\"none\" points=\"33.5,-.5 33.5,-46.5 279.5,-46.5 279.5,-.5 33.5,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"84.5\" y=\"-19.8\">dense_1: Dense</text>\n",
       "<polyline fill=\"none\" points=\"135.5,-.5 135.5,-46.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"163\" y=\"-31.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"135.5,-23.5 190.5,-23.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"163\" y=\"-8.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"190.5,-.5 190.5,-46.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"235\" y=\"-31.3\">(None, 100)</text>\n",
       "<polyline fill=\"none\" points=\"190.5,-23.5 279.5,-23.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"235\" y=\"-8.3\">(None, 3384)</text>\n",
       "</g>\n",
       "<!-- 140201670942792&#45;&gt;140201670945592 -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>140201670942792-&gt;140201670945592</title>\n",
       "<path d=\"M156.5,-83.3799C156.5,-75.1745 156.5,-65.7679 156.5,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"160.0001,-56.784 156.5,-46.784 153.0001,-56.784 160.0001,-56.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140201670944864 -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>140201670944864</title>\n",
       "<polygon fill=\"none\" points=\"97.5,-249.5 97.5,-285.5 215.5,-285.5 215.5,-249.5 97.5,-249.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"156.5\" y=\"-263.8\">140201670944864</text>\n",
       "</g>\n",
       "<!-- 140201670944864&#45;&gt;140201670946152 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>140201670944864-&gt;140201670946152</title>\n",
       "<path d=\"M156.5,-249.4092C156.5,-241.4308 156.5,-231.795 156.5,-222.606\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"160.0001,-222.5333 156.5,-212.5333 153.0001,-222.5334 160.0001,-222.5333\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the Keras model and view it \n",
    "skipgram = Sequential()\n",
    "skipgram.add(Embedding(input_dim=vocab_size, output_dim=dim, embeddings_initializer='glorot_uniform', input_length=1))\n",
    "skipgram.add(Reshape((dim,)))\n",
    "skipgram.add(Dense(input_dim=dim, units=vocab_size, activation='softmax'))\n",
    "SVG(model_to_dot(skipgram, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Skipgrams: Compiling and Training\n",
    "- Time to compile and train\n",
    "- We use crossentropy, common loss for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0, loss is 6712.05944609642\n",
      "iteration 1, loss is 6683.798287391663\n",
      "iteration 2, loss is 6651.352287054062\n",
      "iteration 3, loss is 6619.84747672081\n",
      "iteration 4, loss is 6590.538501739502\n",
      "iteration 5, loss is 6564.116360425949\n",
      "iteration 6, loss is 6540.191687345505\n",
      "iteration 7, loss is 6518.1522924900055\n",
      "iteration 8, loss is 6497.632173061371\n",
      "iteration 9, loss is 6478.38989841938\n"
     ]
    }
   ],
   "source": [
    "# Compile the Keras Model\n",
    "#from keras.optimizers import SGD\n",
    "#sgd = SGD(lr=1e-4, decay=1e-6, momentum=0.9)\n",
    "\n",
    "skipgram.compile(loss='categorical_crossentropy', optimizer=\"adadelta\")\n",
    "\n",
    "# Fit the Skipgrams\n",
    "for iteration in range(10):\n",
    "    loss = 0\n",
    "    for x, y in generate_data(sequences, window_size, vocab_size):\n",
    "        loss += skipgram.train_on_batch(x, y)\n",
    "    print('iteration {}, loss is {}'.format(iteration, loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skipgrams: Looking at the vectors\n",
    "\n",
    "To get word_vectors now, we look at the weights of the first layer.\n",
    "\n",
    "Let's also write functions giving us similarity of two words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9441558718681335\n",
      "\n",
      "gryphon        0.954021\n",
      "duchess        0.946990\n",
      "king           0.944156\n",
      "hatter         0.940838\n",
      "dormouse       0.933425\n",
      "caterpillar    0.922985\n",
      "footman        0.919527\n",
      "cat            0.914474\n",
      "march          0.908806\n",
      "mouse          0.904107\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "word_vectors = skipgram.get_weights()[0]\n",
    "\n",
    "\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "\n",
    "def get_dist(w1, w2):\n",
    "    i1, i2 = tokenizer.word_index[w1], tokenizer.word_index[w2]\n",
    "    v1, v2 = word_vectors[i1], word_vectors[i2]\n",
    "    return cosine(v1, v2)\n",
    "\n",
    "def get_similarity(w1, w2):\n",
    "    return 1-get_dist(w1, w2)\n",
    "\n",
    "def get_most_similar(w1, n=10):\n",
    "    sims = {word: get_similarity(w1, word) \n",
    "            for word in tokenizer.word_index.keys()\n",
    "            if word != w1}\n",
    "    sims = pd.Series(sims)\n",
    "    sims.sort_values(inplace=True, ascending=False)\n",
    "    return sims.iloc[:n]\n",
    "\n",
    "\n",
    "print(get_similarity('king', 'queen'))\n",
    "print('')\n",
    "print(get_most_similar('queen'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Your turn -- Modify the code above to create a CBOW Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_cbow(sequences, window_size, vocab_size):\n",
    "    \n",
    "    for seq in sequences:\n",
    "        \n",
    "        if not seq:\n",
    "            continue\n",
    "        #assert(len(seq) > 0)  \n",
    "        \n",
    "        X = np.zeros((len(seq), 2 * window_size), 'int')\n",
    "        y = np.zeros((len(seq), vocab_size), 'int')\n",
    "        #print(seq, ':')\n",
    "        \n",
    "        for token_index, token in enumerate(seq):\n",
    "            y[token_index] = np_utils.to_categorical(token, vocab_size)\n",
    "            neighbors = seq[max(0, token_index - window_size) : token_index] +\\\n",
    "                        seq[min(len(seq)-1, token_index) + 1: token_index + 1 + window_size]\n",
    "            #print(token_index, token, neighbors)\n",
    "            #assert(len(neighbors) <= 2 * window_size)\n",
    "            for neighbor_index, neighbor in enumerate(neighbors):\n",
    "                X[token_index, neighbor_index] = neighbor\n",
    "            #print(X[token_index])\n",
    "\n",
    "        yield X, y\n",
    "        \n",
    "data_generator = generate_data_cbow(sequences, window_size, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [Input(shape=(1,), dtype='int32', name=f'neigbor_{n}') for n in range(2 * window_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_embedding = Embedding(input_dim=vocab_size,\\\n",
    "                          output_dim=dim,\\\n",
    "                          embeddings_initializer='glorot_uniform',\\\n",
    "                          input_length=1,\n",
    "                          name='embedding')\n",
    "embedded_inputs = [the_embedding(input_) for input_ in inputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbow = Reshape((dim,))(add(embedded_inputs))\n",
    "prediction = Dense(vocab_size, activation='softmax', name='predict_sparse_token')(cbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbow_model = Model(inputs=inputs, outputs=[prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"387pt\" viewBox=\"0.00 0.00 1114.00 387.00\" width=\"1114pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 383)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-383 1110,-383 1110,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 140200968300192 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>140200968300192</title>\n",
       "<polygon fill=\"none\" points=\"0,-332.5 0,-378.5 263,-378.5 263,-332.5 0,-332.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"69.5\" y=\"-351.8\">neigbor_0: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"139,-332.5 139,-378.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"166.5\" y=\"-363.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"139,-355.5 194,-355.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"166.5\" y=\"-340.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"194,-332.5 194,-378.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"228.5\" y=\"-363.3\">(None, 1)</text>\n",
       "<polyline fill=\"none\" points=\"194,-355.5 263,-355.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"228.5\" y=\"-340.3\">(None, 1)</text>\n",
       "</g>\n",
       "<!-- 140200968299856 -->\n",
       "<g class=\"node\" id=\"node5\">\n",
       "<title>140200968299856</title>\n",
       "<polygon fill=\"none\" points=\"402.5,-249.5 402.5,-295.5 702.5,-295.5 702.5,-249.5 402.5,-249.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"476.5\" y=\"-268.8\">embedding: Embedding</text>\n",
       "<polyline fill=\"none\" points=\"550.5,-249.5 550.5,-295.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"578\" y=\"-280.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"550.5,-272.5 605.5,-272.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"578\" y=\"-257.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"605.5,-249.5 605.5,-295.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"654\" y=\"-280.3\">(None, 1)</text>\n",
       "<polyline fill=\"none\" points=\"605.5,-272.5 702.5,-272.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"654\" y=\"-257.3\">(None, 1, 100)</text>\n",
       "</g>\n",
       "<!-- 140200968300192&#45;&gt;140200968299856 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>140200968300192-&gt;140200968299856</title>\n",
       "<path d=\"M248.2129,-332.4901C303.3078,-321.6282 369.1773,-308.642 425.519,-297.5343\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"426.4259,-300.9229 435.5601,-295.5547 425.0719,-294.0551 426.4259,-300.9229\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140200968299632 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>140200968299632</title>\n",
       "<polygon fill=\"none\" points=\"281,-332.5 281,-378.5 544,-378.5 544,-332.5 281,-332.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"350.5\" y=\"-351.8\">neigbor_1: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"420,-332.5 420,-378.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"447.5\" y=\"-363.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"420,-355.5 475,-355.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"447.5\" y=\"-340.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"475,-332.5 475,-378.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"509.5\" y=\"-363.3\">(None, 1)</text>\n",
       "<polyline fill=\"none\" points=\"475,-355.5 544,-355.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"509.5\" y=\"-340.3\">(None, 1)</text>\n",
       "</g>\n",
       "<!-- 140200968299632&#45;&gt;140200968299856 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>140200968299632-&gt;140200968299856</title>\n",
       "<path d=\"M451.4978,-332.3799C467.8956,-322.6583 487.1377,-311.2505 504.4029,-301.0147\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"506.4088,-303.8944 513.2258,-295.784 502.8389,-297.8731 506.4088,-303.8944\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140200968299744 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>140200968299744</title>\n",
       "<polygon fill=\"none\" points=\"562,-332.5 562,-378.5 825,-378.5 825,-332.5 562,-332.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"631.5\" y=\"-351.8\">neigbor_2: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"701,-332.5 701,-378.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"728.5\" y=\"-363.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"701,-355.5 756,-355.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"728.5\" y=\"-340.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"756,-332.5 756,-378.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"790.5\" y=\"-363.3\">(None, 1)</text>\n",
       "<polyline fill=\"none\" points=\"756,-355.5 825,-355.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"790.5\" y=\"-340.3\">(None, 1)</text>\n",
       "</g>\n",
       "<!-- 140200968299744&#45;&gt;140200968299856 -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>140200968299744-&gt;140200968299856</title>\n",
       "<path d=\"M654.2236,-332.3799C637.7087,-322.6583 618.3292,-311.2505 600.9406,-301.0147\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"602.4481,-297.8407 592.0548,-295.784 598.897,-303.8731 602.4481,-297.8407\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140200968299520 -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>140200968299520</title>\n",
       "<polygon fill=\"none\" points=\"843,-332.5 843,-378.5 1106,-378.5 1106,-332.5 843,-332.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"912.5\" y=\"-351.8\">neigbor_3: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"982,-332.5 982,-378.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1009.5\" y=\"-363.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"982,-355.5 1037,-355.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1009.5\" y=\"-340.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1037,-332.5 1037,-378.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1071.5\" y=\"-363.3\">(None, 1)</text>\n",
       "<polyline fill=\"none\" points=\"1037,-355.5 1106,-355.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1071.5\" y=\"-340.3\">(None, 1)</text>\n",
       "</g>\n",
       "<!-- 140200968299520&#45;&gt;140200968299856 -->\n",
       "<g class=\"edge\" id=\"edge4\">\n",
       "<title>140200968299520-&gt;140200968299856</title>\n",
       "<path d=\"M857.5099,-332.4901C802.2841,-321.6282 736.2582,-308.642 679.7826,-297.5343\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"680.2052,-294.0504 669.7177,-295.5547 678.8542,-300.9188 680.2052,-294.0504\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140200967391328 -->\n",
       "<g class=\"node\" id=\"node6\">\n",
       "<title>140200967391328</title>\n",
       "<polygon fill=\"none\" points=\"300.5,-166.5 300.5,-212.5 804.5,-212.5 804.5,-166.5 300.5,-166.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"340.5\" y=\"-185.8\">add_8: Add</text>\n",
       "<polyline fill=\"none\" points=\"380.5,-166.5 380.5,-212.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"408\" y=\"-197.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"380.5,-189.5 435.5,-189.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"408\" y=\"-174.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"435.5,-166.5 435.5,-212.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"620\" y=\"-197.3\">[(None, 1, 100), (None, 1, 100), (None, 1, 100), (None, 1, 100)]</text>\n",
       "<polyline fill=\"none\" points=\"435.5,-189.5 804.5,-189.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"620\" y=\"-174.3\">(None, 1, 100)</text>\n",
       "</g>\n",
       "<!-- 140200968299856&#45;&gt;140200967391328 -->\n",
       "<g class=\"edge\" id=\"edge5\">\n",
       "<title>140200968299856-&gt;140200967391328</title>\n",
       "<path d=\"M552.5,-249.3799C552.5,-241.1745 552.5,-231.7679 552.5,-222.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"556.0001,-222.784 552.5,-212.784 549.0001,-222.784 556.0001,-222.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140200968301312 -->\n",
       "<g class=\"node\" id=\"node7\">\n",
       "<title>140200968301312</title>\n",
       "<polygon fill=\"none\" points=\"414,-83.5 414,-129.5 691,-129.5 691,-83.5 414,-83.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"476.5\" y=\"-102.8\">reshape_9: Reshape</text>\n",
       "<polyline fill=\"none\" points=\"539,-83.5 539,-129.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"566.5\" y=\"-114.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"539,-106.5 594,-106.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"566.5\" y=\"-91.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"594,-83.5 594,-129.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"642.5\" y=\"-114.3\">(None, 1, 100)</text>\n",
       "<polyline fill=\"none\" points=\"594,-106.5 691,-106.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"642.5\" y=\"-91.3\">(None, 100)</text>\n",
       "</g>\n",
       "<!-- 140200967391328&#45;&gt;140200968301312 -->\n",
       "<g class=\"edge\" id=\"edge9\">\n",
       "<title>140200967391328-&gt;140200968301312</title>\n",
       "<path d=\"M552.5,-166.3799C552.5,-158.1745 552.5,-148.7679 552.5,-139.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"556.0001,-139.784 552.5,-129.784 549.0001,-139.784 556.0001,-139.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140200968301648 -->\n",
       "<g class=\"node\" id=\"node8\">\n",
       "<title>140200968301648</title>\n",
       "<polygon fill=\"none\" points=\"394,-.5 394,-46.5 711,-46.5 711,-.5 394,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"480.5\" y=\"-19.8\">predict_sparse_token: Dense</text>\n",
       "<polyline fill=\"none\" points=\"567,-.5 567,-46.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"594.5\" y=\"-31.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"567,-23.5 622,-23.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"594.5\" y=\"-8.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"622,-.5 622,-46.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"666.5\" y=\"-31.3\">(None, 100)</text>\n",
       "<polyline fill=\"none\" points=\"622,-23.5 711,-23.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"666.5\" y=\"-8.3\">(None, 3384)</text>\n",
       "</g>\n",
       "<!-- 140200968301312&#45;&gt;140200968301648 -->\n",
       "<g class=\"edge\" id=\"edge10\">\n",
       "<title>140200968301312-&gt;140200968301648</title>\n",
       "<path d=\"M552.5,-83.3799C552.5,-75.1745 552.5,-65.7679 552.5,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"556.0001,-56.784 552.5,-46.784 549.0001,-56.784 556.0001,-56.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVG(model_to_dot(cbow_model, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "neigbor_0 (InputLayer)          (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "neigbor_1 (InputLayer)          (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "neigbor_2 (InputLayer)          (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "neigbor_3 (InputLayer)          (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1, 100)       338400      neigbor_0[0][0]                  \n",
      "                                                                 neigbor_1[0][0]                  \n",
      "                                                                 neigbor_2[0][0]                  \n",
      "                                                                 neigbor_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 1, 100)       0           embedding[0][0]                  \n",
      "                                                                 embedding[1][0]                  \n",
      "                                                                 embedding[2][0]                  \n",
      "                                                                 embedding[3][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_9 (Reshape)             (None, 100)          0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "predict_sparse_token (Dense)    (None, 3384)         341784      reshape_9[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 680,184\n",
      "Trainable params: 680,184\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cbow_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0, loss is 7143.60152721405\n",
      "iteration 1, loss is 6874.8231472969055\n",
      "iteration 2, loss is 6691.971711874008\n",
      "iteration 3, loss is 6540.220075368881\n",
      "iteration 4, loss is 6411.5310690402985\n",
      "iteration 5, loss is 6301.271844148636\n",
      "iteration 6, loss is 6205.562391996384\n",
      "iteration 7, loss is 6119.319103002548\n",
      "iteration 8, loss is 6039.4762444496155\n",
      "iteration 9, loss is 5965.435489177704\n"
     ]
    }
   ],
   "source": [
    "cbow_model.compile(loss='categorical_crossentropy', optimizer=\"adadelta\")\n",
    "\n",
    "for iteration in range(10):\n",
    "    loss = 0\n",
    "    for X, y in generate_data_cbow(sequences, window_size, vocab_size):\n",
    "        loss += cbow_model.train_on_batch([X[:, idx] for idx in range(2 * window_size)], y)\n",
    "    print('iteration {}, loss is {}'.format(iteration, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3384, 100)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors = cbow_model.get_layer('embedding').get_weights()[0]\n",
    "word_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8831360936164856\n",
      "\n",
      "gryphon        0.913168\n",
      "hatter         0.898623\n",
      "footman        0.895087\n",
      "caterpillar    0.893760\n",
      "dormouse       0.890391\n",
      "king           0.883136\n",
      "duchess        0.882594\n",
      "soldiers       0.880809\n",
      "door           0.869426\n",
      "table          0.861104\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "word_vectors = cbow_model.get_layer('embedding').get_weights()[0]\n",
    "\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "\n",
    "def get_dist(w1, w2):\n",
    "    i1, i2 = tokenizer.word_index[w1], tokenizer.word_index[w2]\n",
    "    v1, v2 = word_vectors[i1], word_vectors[i2]\n",
    "    return cosine(v1, v2)\n",
    "\n",
    "def get_similarity(w1, w2):\n",
    "    return 1-get_dist(w1, w2)\n",
    "\n",
    "def get_most_similar(w1, n=10):\n",
    "    sims = {word: get_similarity(w1, word) \n",
    "            for word in tokenizer.word_index.keys()\n",
    "            if word != w1}\n",
    "    sims = pd.Series(sims)\n",
    "    sims.sort_values(inplace=True, ascending=False)\n",
    "    return sims.iloc[:n]\n",
    "\n",
    "\n",
    "print(get_similarity('king', 'queen'))\n",
    "print('')\n",
    "print(get_most_similar('queen'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  },
  "livereveal": {
   "height": "100%",
   "margin": 0,
   "maxScale": 1,
   "minScale": 1,
   "scroll": true,
   "start_slideshow_at": "selected",
   "theme": "sky",
   "transition": "zoom",
   "width": "100%"
  },
  "toc": {
   "nav_menu": {
    "height": "369px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {
    "height": "457px",
    "left": "0px",
    "right": "968px",
    "top": "130px",
    "width": "214px"
   },
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
