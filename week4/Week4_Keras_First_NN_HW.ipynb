{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Keras to Build and Train Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we will use a neural network to predict diabetes using the Pima Diabetes Dataset.  We will start by training a Random Forest to get a performance baseline.  Then we will use the Keras package to quickly build and train a neural network and compare the performance.  We will see how different network structures affect the performance, training time, and level of overfitting (or underfitting).\n",
    "\n",
    "## UCI Pima Diabetes Dataset\n",
    "\n",
    "* UCI ML Repositiory (http://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes)\n",
    "\n",
    "\n",
    "### Attributes: (all numeric-valued)\n",
    "   1. Number of times pregnant\n",
    "   2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "   3. Diastolic blood pressure (mm Hg)\n",
    "   4. Triceps skin fold thickness (mm)\n",
    "   5. 2-Hour serum insulin (mu U/ml)\n",
    "   6. Body mass index (weight in kg/(height in m)^2)\n",
    "   7. Diabetes pedigree function\n",
    "   8. Age (years)\n",
    "   9. Class variable (0 or 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The UCI Pima Diabetes Dataset which has 8 numerical predictors and a binary outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preliminaries\n",
    "\n",
    "from __future__ import absolute_import, division, print_function  # Python 2/3 compatibility\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "## Import Keras objects for Deep Learning\n",
    "\n",
    "from keras.models  import Sequential, K\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
    "from keras.optimizers import Adam, SGD, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load in the data set (Internet Access needed)\n",
    "\n",
    "url = \"http://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data\"\n",
    "names = [\"times_pregnant\", \"glucose_tolerance_test\", \"blood_pressure\", \"skin_thickness\", \"insulin\", \n",
    "         \"bmi\", \"pedigree_function\", \"age\", \"has_diabetes\"]\n",
    "diabetes_df = pd.read_csv(os.path.join('data', 'diabetes.csv'))\n",
    "diabetes_df.columns = names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>times_pregnant</th>\n",
       "      <th>glucose_tolerance_test</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>skin_thickness</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree_function</th>\n",
       "      <th>age</th>\n",
       "      <th>has_diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>5</td>\n",
       "      <td>99</td>\n",
       "      <td>54</td>\n",
       "      <td>28</td>\n",
       "      <td>83</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.499</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>3</td>\n",
       "      <td>173</td>\n",
       "      <td>82</td>\n",
       "      <td>48</td>\n",
       "      <td>465</td>\n",
       "      <td>38.4</td>\n",
       "      <td>2.137</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>2</td>\n",
       "      <td>106</td>\n",
       "      <td>64</td>\n",
       "      <td>35</td>\n",
       "      <td>119</td>\n",
       "      <td>30.5</td>\n",
       "      <td>1.400</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>8</td>\n",
       "      <td>84</td>\n",
       "      <td>74</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>38.3</td>\n",
       "      <td>0.457</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.259</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     times_pregnant  glucose_tolerance_test  blood_pressure  skin_thickness  \\\n",
       "365               5                      99              54              28   \n",
       "370               3                     173              82              48   \n",
       "147               2                     106              64              35   \n",
       "133               8                      84              74              31   \n",
       "284               2                     108              80               0   \n",
       "\n",
       "     insulin   bmi  pedigree_function  age  has_diabetes  \n",
       "365       83  34.0              0.499   30             0  \n",
       "370      465  38.4              2.137   25             1  \n",
       "147      119  30.5              1.400   34             0  \n",
       "133        0  38.3              0.457   39             0  \n",
       "284        0  27.0              0.259   52             1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a peek at the data -- if there are lots of \"NaN\" you may have internet connectivity issues\n",
    "print(diabetes_df.shape)\n",
    "diabetes_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>times_pregnant</th>\n",
       "      <th>glucose_tolerance_test</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>skin_thickness</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree_function</th>\n",
       "      <th>age</th>\n",
       "      <th>has_diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   times_pregnant  glucose_tolerance_test  blood_pressure  skin_thickness  \\\n",
       "0               6                     148              72              35   \n",
       "1               1                      85              66              29   \n",
       "2               8                     183              64               0   \n",
       "3               1                      89              66              23   \n",
       "4               0                     137              40              35   \n",
       "\n",
       "   insulin   bmi  pedigree_function  age  has_diabetes  \n",
       "0        0  33.6              0.627   50             1  \n",
       "1        0  26.6              0.351   31             0  \n",
       "2        0  23.3              0.672   32             1  \n",
       "3       94  28.1              0.167   21             0  \n",
       "4      168  43.1              2.288   33             1  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = diabetes_df.iloc[:, :-1].values\n",
    "y = diabetes_df[\"has_diabetes\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data to Train, and Test (75%, 25%)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=11111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3489583333333333, 0.6510416666666666)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y), np.mean(1-y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we see that about 35% of the patients in this dataset have diabetes, while 65% do not.  This means we can get an accuracy of 65% without any model - just declare that no one has diabetes. We will calculate the ROC-AUC score to evaluate performance of our model, and also look at the accuracy as well to see if we improved upon the 65% accuracy.\n",
    "## Exercise: Get a baseline performance using Random Forest\n",
    "To begin, and get a baseline for classifier performance:\n",
    "1. Train a Random Forest model with 200 trees on the training data.\n",
    "2. Calculate the accuracy and roc_auc_score of the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Train the RF Model\n",
    "rf_model = RandomForestClassifier(n_estimators=200)\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.776\n",
      "roc-auc is 0.831\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set - both \"hard\" predictions, and the scores (percent of trees voting yes)\n",
    "y_pred_class_rf = rf_model.predict(X_test)\n",
    "y_pred_prob_rf = rf_model.predict_proba(X_test)\n",
    "\n",
    "\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_rf)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_rf[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_roc(y_test, y_pred, model_name):\n",
    "    fpr, tpr, thr = roc_curve(y_test, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.plot(fpr, tpr, 'k-')\n",
    "    ax.plot([0, 1], [0, 1], 'k--', linewidth=.5)  # roc curve for random model\n",
    "    ax.grid(True)\n",
    "    ax.set(title='ROC Curve for {} on PIMA diabetes problem'.format(model_name),\n",
    "           xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])\n",
    "\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_rf[:, 1], 'RF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Single Hidden Layer Neural Network\n",
    "\n",
    "We will use the Sequential model to quickly build a neural network.  Our first network will be a single layer network.  We have 8 variables, so we set the input shape to 8.  Let's start by having a single hidden layer with 12 nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## First let's normalize the data\n",
    "## This aids the training of neural nets by providing numerical stability\n",
    "## Random Forest does not need this as it finds a split only, as opposed to performing matrix multiplications\n",
    "\n",
    "\n",
    "normalizer = StandardScaler()\n",
    "X_train_norm = normalizer.fit_transform(X_train)\n",
    "X_test_norm = normalizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Model \n",
    "# Input size is 8-dimensional\n",
    "# 1 hidden layer, 12 hidden nodes, sigmoid activation\n",
    "# Final layer has just one node with a sigmoid activation (standard for binary classification)\n",
    "\n",
    "model_1 = Sequential([\n",
    "    Dense(12, input_shape=(8,), activation=\"relu\"),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 12)                108       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 121\n",
      "Trainable params: 121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#  This is a nice tool to view the model you have created and count the parameters\n",
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comprehension question:\n",
    "Why do we have 121 parameters?  Does that make sense?\n",
    "\n",
    "\n",
    "Let's fit our model for 200 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 576 samples, validate on 192 samples\n",
      "Epoch 1/200\n",
      "576/576 [==============================] - 0s 849us/step - loss: 0.8649 - acc: 0.6354 - val_loss: 0.8960 - val_acc: 0.6302\n",
      "Epoch 2/200\n",
      "576/576 [==============================] - 0s 121us/step - loss: 0.8508 - acc: 0.6354 - val_loss: 0.8818 - val_acc: 0.6302\n",
      "Epoch 3/200\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.8375 - acc: 0.6372 - val_loss: 0.8683 - val_acc: 0.6302\n",
      "Epoch 4/200\n",
      "576/576 [==============================] - 0s 102us/step - loss: 0.8249 - acc: 0.6372 - val_loss: 0.8555 - val_acc: 0.6354\n",
      "Epoch 5/200\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.8129 - acc: 0.6372 - val_loss: 0.8434 - val_acc: 0.6354\n",
      "Epoch 6/200\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.8014 - acc: 0.6354 - val_loss: 0.8318 - val_acc: 0.6354\n",
      "Epoch 7/200\n",
      "576/576 [==============================] - 0s 110us/step - loss: 0.7905 - acc: 0.6372 - val_loss: 0.8208 - val_acc: 0.6354\n",
      "Epoch 8/200\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.7801 - acc: 0.6372 - val_loss: 0.8103 - val_acc: 0.6354\n",
      "Epoch 9/200\n",
      "576/576 [==============================] - 0s 183us/step - loss: 0.7702 - acc: 0.6372 - val_loss: 0.8002 - val_acc: 0.6406\n",
      "Epoch 10/200\n",
      "576/576 [==============================] - 0s 121us/step - loss: 0.7608 - acc: 0.6337 - val_loss: 0.7906 - val_acc: 0.6406\n",
      "Epoch 11/200\n",
      "576/576 [==============================] - 0s 118us/step - loss: 0.7517 - acc: 0.6406 - val_loss: 0.7815 - val_acc: 0.6458\n",
      "Epoch 12/200\n",
      "576/576 [==============================] - 0s 103us/step - loss: 0.7432 - acc: 0.6406 - val_loss: 0.7729 - val_acc: 0.6406\n",
      "Epoch 13/200\n",
      "576/576 [==============================] - 0s 129us/step - loss: 0.7350 - acc: 0.6389 - val_loss: 0.7646 - val_acc: 0.6406\n",
      "Epoch 14/200\n",
      "576/576 [==============================] - 0s 110us/step - loss: 0.7272 - acc: 0.6406 - val_loss: 0.7568 - val_acc: 0.6406\n",
      "Epoch 15/200\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.7198 - acc: 0.6406 - val_loss: 0.7493 - val_acc: 0.6406\n",
      "Epoch 16/200\n",
      "576/576 [==============================] - 0s 143us/step - loss: 0.7127 - acc: 0.6389 - val_loss: 0.7422 - val_acc: 0.6250\n",
      "Epoch 17/200\n",
      "576/576 [==============================] - 0s 140us/step - loss: 0.7060 - acc: 0.6389 - val_loss: 0.7354 - val_acc: 0.6198\n",
      "Epoch 18/200\n",
      "576/576 [==============================] - 0s 98us/step - loss: 0.6995 - acc: 0.6389 - val_loss: 0.7290 - val_acc: 0.6198\n",
      "Epoch 19/200\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.6934 - acc: 0.6337 - val_loss: 0.7229 - val_acc: 0.6198\n",
      "Epoch 20/200\n",
      "576/576 [==============================] - 0s 120us/step - loss: 0.6875 - acc: 0.6354 - val_loss: 0.7170 - val_acc: 0.6198\n",
      "Epoch 21/200\n",
      "576/576 [==============================] - 0s 147us/step - loss: 0.6817 - acc: 0.6372 - val_loss: 0.7113 - val_acc: 0.6198\n",
      "Epoch 22/200\n",
      "576/576 [==============================] - 0s 113us/step - loss: 0.6763 - acc: 0.6389 - val_loss: 0.7058 - val_acc: 0.6198\n",
      "Epoch 23/200\n",
      "576/576 [==============================] - 0s 128us/step - loss: 0.6709 - acc: 0.6389 - val_loss: 0.7006 - val_acc: 0.6250\n",
      "Epoch 24/200\n",
      "576/576 [==============================] - 0s 144us/step - loss: 0.6658 - acc: 0.6406 - val_loss: 0.6956 - val_acc: 0.6302\n",
      "Epoch 25/200\n",
      "576/576 [==============================] - 0s 93us/step - loss: 0.6608 - acc: 0.6441 - val_loss: 0.6908 - val_acc: 0.6302\n",
      "Epoch 26/200\n",
      "576/576 [==============================] - 0s 113us/step - loss: 0.6561 - acc: 0.6458 - val_loss: 0.6862 - val_acc: 0.6354\n",
      "Epoch 27/200\n",
      "576/576 [==============================] - 0s 122us/step - loss: 0.6516 - acc: 0.6441 - val_loss: 0.6817 - val_acc: 0.6406\n",
      "Epoch 28/200\n",
      "576/576 [==============================] - 0s 106us/step - loss: 0.6472 - acc: 0.6476 - val_loss: 0.6775 - val_acc: 0.6406\n",
      "Epoch 29/200\n",
      "576/576 [==============================] - 0s 144us/step - loss: 0.6430 - acc: 0.6528 - val_loss: 0.6734 - val_acc: 0.6406\n",
      "Epoch 30/200\n",
      "576/576 [==============================] - 0s 142us/step - loss: 0.6389 - acc: 0.6545 - val_loss: 0.6695 - val_acc: 0.6458\n",
      "Epoch 31/200\n",
      "576/576 [==============================] - 0s 179us/step - loss: 0.6350 - acc: 0.6580 - val_loss: 0.6657 - val_acc: 0.6458\n",
      "Epoch 32/200\n",
      "576/576 [==============================] - 0s 155us/step - loss: 0.6311 - acc: 0.6597 - val_loss: 0.6620 - val_acc: 0.6458\n",
      "Epoch 33/200\n",
      "576/576 [==============================] - 0s 112us/step - loss: 0.6274 - acc: 0.6615 - val_loss: 0.6584 - val_acc: 0.6510\n",
      "Epoch 34/200\n",
      "576/576 [==============================] - 0s 101us/step - loss: 0.6237 - acc: 0.6632 - val_loss: 0.6549 - val_acc: 0.6510\n",
      "Epoch 35/200\n",
      "576/576 [==============================] - 0s 195us/step - loss: 0.6202 - acc: 0.6632 - val_loss: 0.6516 - val_acc: 0.6406\n",
      "Epoch 36/200\n",
      "576/576 [==============================] - 0s 181us/step - loss: 0.6168 - acc: 0.6667 - val_loss: 0.6483 - val_acc: 0.6406\n",
      "Epoch 37/200\n",
      "576/576 [==============================] - 0s 108us/step - loss: 0.6135 - acc: 0.6719 - val_loss: 0.6451 - val_acc: 0.6510\n",
      "Epoch 38/200\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.6102 - acc: 0.6719 - val_loss: 0.6421 - val_acc: 0.6510\n",
      "Epoch 39/200\n",
      "576/576 [==============================] - 0s 103us/step - loss: 0.6071 - acc: 0.6771 - val_loss: 0.6391 - val_acc: 0.6458\n",
      "Epoch 40/200\n",
      "576/576 [==============================] - 0s 84us/step - loss: 0.6041 - acc: 0.6753 - val_loss: 0.6362 - val_acc: 0.6510\n",
      "Epoch 41/200\n",
      "576/576 [==============================] - 0s 68us/step - loss: 0.6011 - acc: 0.6771 - val_loss: 0.6334 - val_acc: 0.6510\n",
      "Epoch 42/200\n",
      "576/576 [==============================] - 0s 84us/step - loss: 0.5982 - acc: 0.6771 - val_loss: 0.6306 - val_acc: 0.6510\n",
      "Epoch 43/200\n",
      "576/576 [==============================] - 0s 66us/step - loss: 0.5954 - acc: 0.6788 - val_loss: 0.6279 - val_acc: 0.6510\n",
      "Epoch 44/200\n",
      "576/576 [==============================] - 0s 93us/step - loss: 0.5926 - acc: 0.6823 - val_loss: 0.6253 - val_acc: 0.6458\n",
      "Epoch 45/200\n",
      "576/576 [==============================] - 0s 70us/step - loss: 0.5900 - acc: 0.6840 - val_loss: 0.6228 - val_acc: 0.6458\n",
      "Epoch 46/200\n",
      "576/576 [==============================] - 0s 64us/step - loss: 0.5873 - acc: 0.6840 - val_loss: 0.6203 - val_acc: 0.6458\n",
      "Epoch 47/200\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.5848 - acc: 0.6858 - val_loss: 0.6178 - val_acc: 0.6302\n",
      "Epoch 48/200\n",
      "576/576 [==============================] - 0s 84us/step - loss: 0.5823 - acc: 0.6875 - val_loss: 0.6155 - val_acc: 0.6406\n",
      "Epoch 49/200\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.5798 - acc: 0.6910 - val_loss: 0.6132 - val_acc: 0.6406\n",
      "Epoch 50/200\n",
      "576/576 [==============================] - 0s 65us/step - loss: 0.5775 - acc: 0.6927 - val_loss: 0.6110 - val_acc: 0.6406\n",
      "Epoch 51/200\n",
      "576/576 [==============================] - 0s 85us/step - loss: 0.5751 - acc: 0.6927 - val_loss: 0.6088 - val_acc: 0.6406\n",
      "Epoch 52/200\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.5729 - acc: 0.6892 - val_loss: 0.6067 - val_acc: 0.6406\n",
      "Epoch 53/200\n",
      "576/576 [==============================] - 0s 90us/step - loss: 0.5707 - acc: 0.6944 - val_loss: 0.6046 - val_acc: 0.6406\n",
      "Epoch 54/200\n",
      "576/576 [==============================] - 0s 70us/step - loss: 0.5686 - acc: 0.6927 - val_loss: 0.6026 - val_acc: 0.6406\n",
      "Epoch 55/200\n",
      "576/576 [==============================] - 0s 60us/step - loss: 0.5665 - acc: 0.6979 - val_loss: 0.6006 - val_acc: 0.6406\n",
      "Epoch 56/200\n",
      "576/576 [==============================] - 0s 90us/step - loss: 0.5644 - acc: 0.7014 - val_loss: 0.5986 - val_acc: 0.6458\n",
      "Epoch 57/200\n",
      "576/576 [==============================] - 0s 74us/step - loss: 0.5624 - acc: 0.7049 - val_loss: 0.5968 - val_acc: 0.6458\n",
      "Epoch 58/200\n",
      "576/576 [==============================] - 0s 100us/step - loss: 0.5604 - acc: 0.7101 - val_loss: 0.5949 - val_acc: 0.6458\n",
      "Epoch 59/200\n",
      "576/576 [==============================] - 0s 83us/step - loss: 0.5585 - acc: 0.7118 - val_loss: 0.5931 - val_acc: 0.6458\n",
      "Epoch 60/200\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.5566 - acc: 0.7170 - val_loss: 0.5913 - val_acc: 0.6510\n",
      "Epoch 61/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 90us/step - loss: 0.5547 - acc: 0.7188 - val_loss: 0.5896 - val_acc: 0.6510\n",
      "Epoch 62/200\n",
      "576/576 [==============================] - 0s 83us/step - loss: 0.5529 - acc: 0.7188 - val_loss: 0.5879 - val_acc: 0.6510\n",
      "Epoch 63/200\n",
      "576/576 [==============================] - 0s 84us/step - loss: 0.5511 - acc: 0.7188 - val_loss: 0.5863 - val_acc: 0.6562\n",
      "Epoch 64/200\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.5494 - acc: 0.7170 - val_loss: 0.5847 - val_acc: 0.6562\n",
      "Epoch 65/200\n",
      "576/576 [==============================] - 0s 110us/step - loss: 0.5477 - acc: 0.7205 - val_loss: 0.5831 - val_acc: 0.6615\n",
      "Epoch 66/200\n",
      "576/576 [==============================] - 0s 128us/step - loss: 0.5460 - acc: 0.7222 - val_loss: 0.5816 - val_acc: 0.6615\n",
      "Epoch 67/200\n",
      "576/576 [==============================] - 0s 104us/step - loss: 0.5443 - acc: 0.7240 - val_loss: 0.5801 - val_acc: 0.6719\n",
      "Epoch 68/200\n",
      "576/576 [==============================] - 0s 98us/step - loss: 0.5427 - acc: 0.7257 - val_loss: 0.5786 - val_acc: 0.6719\n",
      "Epoch 69/200\n",
      "576/576 [==============================] - 0s 125us/step - loss: 0.5411 - acc: 0.7274 - val_loss: 0.5772 - val_acc: 0.6771\n",
      "Epoch 70/200\n",
      "576/576 [==============================] - 0s 123us/step - loss: 0.5396 - acc: 0.7257 - val_loss: 0.5758 - val_acc: 0.6823\n",
      "Epoch 71/200\n",
      "576/576 [==============================] - 0s 110us/step - loss: 0.5380 - acc: 0.7257 - val_loss: 0.5745 - val_acc: 0.6823\n",
      "Epoch 72/200\n",
      "576/576 [==============================] - 0s 104us/step - loss: 0.5366 - acc: 0.7309 - val_loss: 0.5731 - val_acc: 0.6823\n",
      "Epoch 73/200\n",
      "576/576 [==============================] - 0s 121us/step - loss: 0.5351 - acc: 0.7309 - val_loss: 0.5718 - val_acc: 0.6823\n",
      "Epoch 74/200\n",
      "576/576 [==============================] - 0s 98us/step - loss: 0.5337 - acc: 0.7326 - val_loss: 0.5706 - val_acc: 0.6823\n",
      "Epoch 75/200\n",
      "576/576 [==============================] - 0s 104us/step - loss: 0.5323 - acc: 0.7326 - val_loss: 0.5693 - val_acc: 0.6823\n",
      "Epoch 76/200\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.5309 - acc: 0.7344 - val_loss: 0.5681 - val_acc: 0.6823\n",
      "Epoch 77/200\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.5295 - acc: 0.7361 - val_loss: 0.5669 - val_acc: 0.6823\n",
      "Epoch 78/200\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.5282 - acc: 0.7378 - val_loss: 0.5658 - val_acc: 0.6823\n",
      "Epoch 79/200\n",
      "576/576 [==============================] - 0s 107us/step - loss: 0.5269 - acc: 0.7396 - val_loss: 0.5647 - val_acc: 0.6875\n",
      "Epoch 80/200\n",
      "576/576 [==============================] - 0s 144us/step - loss: 0.5256 - acc: 0.7378 - val_loss: 0.5636 - val_acc: 0.6875\n",
      "Epoch 81/200\n",
      "576/576 [==============================] - 0s 189us/step - loss: 0.5243 - acc: 0.7378 - val_loss: 0.5625 - val_acc: 0.6875\n",
      "Epoch 82/200\n",
      "576/576 [==============================] - 0s 183us/step - loss: 0.5231 - acc: 0.7378 - val_loss: 0.5614 - val_acc: 0.6927\n",
      "Epoch 83/200\n",
      "576/576 [==============================] - 0s 114us/step - loss: 0.5219 - acc: 0.7396 - val_loss: 0.5604 - val_acc: 0.6979\n",
      "Epoch 84/200\n",
      "576/576 [==============================] - 0s 140us/step - loss: 0.5207 - acc: 0.7413 - val_loss: 0.5594 - val_acc: 0.6979\n",
      "Epoch 85/200\n",
      "576/576 [==============================] - 0s 158us/step - loss: 0.5195 - acc: 0.7413 - val_loss: 0.5585 - val_acc: 0.6979\n",
      "Epoch 86/200\n",
      "576/576 [==============================] - 0s 101us/step - loss: 0.5184 - acc: 0.7431 - val_loss: 0.5575 - val_acc: 0.6979\n",
      "Epoch 87/200\n",
      "576/576 [==============================] - 0s 177us/step - loss: 0.5172 - acc: 0.7517 - val_loss: 0.5566 - val_acc: 0.6979\n",
      "Epoch 88/200\n",
      "576/576 [==============================] - 0s 109us/step - loss: 0.5161 - acc: 0.7535 - val_loss: 0.5557 - val_acc: 0.6979\n",
      "Epoch 89/200\n",
      "576/576 [==============================] - 0s 102us/step - loss: 0.5150 - acc: 0.7517 - val_loss: 0.5548 - val_acc: 0.6979\n",
      "Epoch 90/200\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.5140 - acc: 0.7535 - val_loss: 0.5539 - val_acc: 0.7031\n",
      "Epoch 91/200\n",
      "576/576 [==============================] - 0s 109us/step - loss: 0.5130 - acc: 0.7552 - val_loss: 0.5530 - val_acc: 0.7031\n",
      "Epoch 92/200\n",
      "576/576 [==============================] - 0s 110us/step - loss: 0.5119 - acc: 0.7552 - val_loss: 0.5522 - val_acc: 0.7083\n",
      "Epoch 93/200\n",
      "576/576 [==============================] - 0s 72us/step - loss: 0.5110 - acc: 0.7569 - val_loss: 0.5514 - val_acc: 0.7083\n",
      "Epoch 94/200\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.5100 - acc: 0.7569 - val_loss: 0.5506 - val_acc: 0.7031\n",
      "Epoch 95/200\n",
      "576/576 [==============================] - 0s 83us/step - loss: 0.5090 - acc: 0.7604 - val_loss: 0.5498 - val_acc: 0.6979\n",
      "Epoch 96/200\n",
      "576/576 [==============================] - 0s 88us/step - loss: 0.5080 - acc: 0.7639 - val_loss: 0.5491 - val_acc: 0.6979\n",
      "Epoch 97/200\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.5071 - acc: 0.7656 - val_loss: 0.5483 - val_acc: 0.6979\n",
      "Epoch 98/200\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.5062 - acc: 0.7656 - val_loss: 0.5476 - val_acc: 0.6927\n",
      "Epoch 99/200\n",
      "576/576 [==============================] - 0s 85us/step - loss: 0.5053 - acc: 0.7656 - val_loss: 0.5468 - val_acc: 0.6927\n",
      "Epoch 100/200\n",
      "576/576 [==============================] - 0s 88us/step - loss: 0.5044 - acc: 0.7656 - val_loss: 0.5461 - val_acc: 0.6927\n",
      "Epoch 101/200\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.5036 - acc: 0.7656 - val_loss: 0.5454 - val_acc: 0.6979\n",
      "Epoch 102/200\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.5027 - acc: 0.7639 - val_loss: 0.5448 - val_acc: 0.6979\n",
      "Epoch 103/200\n",
      "576/576 [==============================] - 0s 127us/step - loss: 0.5019 - acc: 0.7639 - val_loss: 0.5441 - val_acc: 0.6979\n",
      "Epoch 104/200\n",
      "576/576 [==============================] - 0s 103us/step - loss: 0.5011 - acc: 0.7639 - val_loss: 0.5435 - val_acc: 0.6979\n",
      "Epoch 105/200\n",
      "576/576 [==============================] - 0s 177us/step - loss: 0.5003 - acc: 0.7639 - val_loss: 0.5428 - val_acc: 0.6979\n",
      "Epoch 106/200\n",
      "576/576 [==============================] - 0s 160us/step - loss: 0.4995 - acc: 0.7622 - val_loss: 0.5422 - val_acc: 0.6979\n",
      "Epoch 107/200\n",
      "576/576 [==============================] - 0s 121us/step - loss: 0.4987 - acc: 0.7639 - val_loss: 0.5416 - val_acc: 0.6979\n",
      "Epoch 108/200\n",
      "576/576 [==============================] - 0s 106us/step - loss: 0.4979 - acc: 0.7639 - val_loss: 0.5410 - val_acc: 0.6979\n",
      "Epoch 109/200\n",
      "576/576 [==============================] - 0s 103us/step - loss: 0.4972 - acc: 0.7639 - val_loss: 0.5405 - val_acc: 0.6979\n",
      "Epoch 110/200\n",
      "576/576 [==============================] - 0s 104us/step - loss: 0.4965 - acc: 0.7639 - val_loss: 0.5399 - val_acc: 0.6979\n",
      "Epoch 111/200\n",
      "576/576 [==============================] - 0s 114us/step - loss: 0.4957 - acc: 0.7639 - val_loss: 0.5393 - val_acc: 0.6979\n",
      "Epoch 112/200\n",
      "576/576 [==============================] - 0s 154us/step - loss: 0.4950 - acc: 0.7622 - val_loss: 0.5388 - val_acc: 0.7031\n",
      "Epoch 113/200\n",
      "576/576 [==============================] - 0s 107us/step - loss: 0.4943 - acc: 0.7639 - val_loss: 0.5383 - val_acc: 0.7083\n",
      "Epoch 114/200\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.4937 - acc: 0.7639 - val_loss: 0.5378 - val_acc: 0.7083\n",
      "Epoch 115/200\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.4930 - acc: 0.7639 - val_loss: 0.5373 - val_acc: 0.7135\n",
      "Epoch 116/200\n",
      "576/576 [==============================] - 0s 112us/step - loss: 0.4923 - acc: 0.7656 - val_loss: 0.5368 - val_acc: 0.7135\n",
      "Epoch 117/200\n",
      "576/576 [==============================] - 0s 115us/step - loss: 0.4917 - acc: 0.7656 - val_loss: 0.5363 - val_acc: 0.7083\n",
      "Epoch 118/200\n",
      "576/576 [==============================] - 0s 112us/step - loss: 0.4911 - acc: 0.7639 - val_loss: 0.5358 - val_acc: 0.7083\n",
      "Epoch 119/200\n",
      "576/576 [==============================] - 0s 83us/step - loss: 0.4904 - acc: 0.7639 - val_loss: 0.5353 - val_acc: 0.7083\n",
      "Epoch 120/200\n",
      "576/576 [==============================] - 0s 92us/step - loss: 0.4898 - acc: 0.7656 - val_loss: 0.5349 - val_acc: 0.7135\n",
      "Epoch 121/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 81us/step - loss: 0.4893 - acc: 0.7674 - val_loss: 0.5345 - val_acc: 0.7188\n",
      "Epoch 122/200\n",
      "576/576 [==============================] - 0s 106us/step - loss: 0.4886 - acc: 0.7674 - val_loss: 0.5340 - val_acc: 0.7188\n",
      "Epoch 123/200\n",
      "576/576 [==============================] - 0s 64us/step - loss: 0.4881 - acc: 0.7674 - val_loss: 0.5336 - val_acc: 0.7188\n",
      "Epoch 124/200\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4875 - acc: 0.7674 - val_loss: 0.5332 - val_acc: 0.7188\n",
      "Epoch 125/200\n",
      "576/576 [==============================] - 0s 142us/step - loss: 0.4869 - acc: 0.7674 - val_loss: 0.5328 - val_acc: 0.7188\n",
      "Epoch 126/200\n",
      "576/576 [==============================] - 0s 144us/step - loss: 0.4864 - acc: 0.7674 - val_loss: 0.5324 - val_acc: 0.7188\n",
      "Epoch 127/200\n",
      "576/576 [==============================] - 0s 179us/step - loss: 0.4858 - acc: 0.7674 - val_loss: 0.5320 - val_acc: 0.7240\n",
      "Epoch 128/200\n",
      "576/576 [==============================] - 0s 149us/step - loss: 0.4853 - acc: 0.7674 - val_loss: 0.5316 - val_acc: 0.7188\n",
      "Epoch 129/200\n",
      "576/576 [==============================] - 0s 158us/step - loss: 0.4848 - acc: 0.7656 - val_loss: 0.5312 - val_acc: 0.7188\n",
      "Epoch 130/200\n",
      "576/576 [==============================] - 0s 104us/step - loss: 0.4843 - acc: 0.7656 - val_loss: 0.5309 - val_acc: 0.7188\n",
      "Epoch 131/200\n",
      "576/576 [==============================] - 0s 108us/step - loss: 0.4838 - acc: 0.7656 - val_loss: 0.5305 - val_acc: 0.7188\n",
      "Epoch 132/200\n",
      "576/576 [==============================] - 0s 88us/step - loss: 0.4833 - acc: 0.7656 - val_loss: 0.5302 - val_acc: 0.7240\n",
      "Epoch 133/200\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4828 - acc: 0.7656 - val_loss: 0.5299 - val_acc: 0.7240\n",
      "Epoch 134/200\n",
      "576/576 [==============================] - 0s 123us/step - loss: 0.4824 - acc: 0.7674 - val_loss: 0.5295 - val_acc: 0.7240\n",
      "Epoch 135/200\n",
      "576/576 [==============================] - 0s 159us/step - loss: 0.4819 - acc: 0.7674 - val_loss: 0.5292 - val_acc: 0.7292\n",
      "Epoch 136/200\n",
      "576/576 [==============================] - 0s 102us/step - loss: 0.4814 - acc: 0.7656 - val_loss: 0.5289 - val_acc: 0.7344\n",
      "Epoch 137/200\n",
      "576/576 [==============================] - 0s 108us/step - loss: 0.4810 - acc: 0.7639 - val_loss: 0.5286 - val_acc: 0.7344\n",
      "Epoch 138/200\n",
      "576/576 [==============================] - 0s 107us/step - loss: 0.4806 - acc: 0.7656 - val_loss: 0.5283 - val_acc: 0.7344\n",
      "Epoch 139/200\n",
      "576/576 [==============================] - 0s 107us/step - loss: 0.4801 - acc: 0.7656 - val_loss: 0.5280 - val_acc: 0.7344\n",
      "Epoch 140/200\n",
      "576/576 [==============================] - 0s 88us/step - loss: 0.4797 - acc: 0.7656 - val_loss: 0.5278 - val_acc: 0.7344\n",
      "Epoch 141/200\n",
      "576/576 [==============================] - 0s 104us/step - loss: 0.4793 - acc: 0.7656 - val_loss: 0.5275 - val_acc: 0.7344\n",
      "Epoch 142/200\n",
      "576/576 [==============================] - 0s 109us/step - loss: 0.4789 - acc: 0.7656 - val_loss: 0.5272 - val_acc: 0.7344\n",
      "Epoch 143/200\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4785 - acc: 0.7656 - val_loss: 0.5269 - val_acc: 0.7344\n",
      "Epoch 144/200\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4781 - acc: 0.7656 - val_loss: 0.5267 - val_acc: 0.7344\n",
      "Epoch 145/200\n",
      "576/576 [==============================] - 0s 125us/step - loss: 0.4777 - acc: 0.7656 - val_loss: 0.5264 - val_acc: 0.7396\n",
      "Epoch 146/200\n",
      "576/576 [==============================] - 0s 95us/step - loss: 0.4773 - acc: 0.7656 - val_loss: 0.5262 - val_acc: 0.7396\n",
      "Epoch 147/200\n",
      "576/576 [==============================] - 0s 92us/step - loss: 0.4770 - acc: 0.7674 - val_loss: 0.5260 - val_acc: 0.7396\n",
      "Epoch 148/200\n",
      "576/576 [==============================] - 0s 101us/step - loss: 0.4766 - acc: 0.7691 - val_loss: 0.5257 - val_acc: 0.7396\n",
      "Epoch 149/200\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.4762 - acc: 0.7674 - val_loss: 0.5255 - val_acc: 0.7396\n",
      "Epoch 150/200\n",
      "576/576 [==============================] - 0s 85us/step - loss: 0.4759 - acc: 0.7691 - val_loss: 0.5253 - val_acc: 0.7396\n",
      "Epoch 151/200\n",
      "576/576 [==============================] - 0s 87us/step - loss: 0.4755 - acc: 0.7674 - val_loss: 0.5251 - val_acc: 0.7396\n",
      "Epoch 152/200\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4752 - acc: 0.7674 - val_loss: 0.5248 - val_acc: 0.7396\n",
      "Epoch 153/200\n",
      "576/576 [==============================] - 0s 87us/step - loss: 0.4748 - acc: 0.7691 - val_loss: 0.5246 - val_acc: 0.7396\n",
      "Epoch 154/200\n",
      "576/576 [==============================] - 0s 70us/step - loss: 0.4745 - acc: 0.7691 - val_loss: 0.5244 - val_acc: 0.7396\n",
      "Epoch 155/200\n",
      "576/576 [==============================] - 0s 111us/step - loss: 0.4742 - acc: 0.7691 - val_loss: 0.5242 - val_acc: 0.7396\n",
      "Epoch 156/200\n",
      "576/576 [==============================] - 0s 83us/step - loss: 0.4739 - acc: 0.7674 - val_loss: 0.5240 - val_acc: 0.7396\n",
      "Epoch 157/200\n",
      "576/576 [==============================] - 0s 87us/step - loss: 0.4736 - acc: 0.7674 - val_loss: 0.5238 - val_acc: 0.7396\n",
      "Epoch 158/200\n",
      "576/576 [==============================] - 0s 85us/step - loss: 0.4732 - acc: 0.7674 - val_loss: 0.5236 - val_acc: 0.7396\n",
      "Epoch 159/200\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.4729 - acc: 0.7674 - val_loss: 0.5235 - val_acc: 0.7396\n",
      "Epoch 160/200\n",
      "576/576 [==============================] - 0s 88us/step - loss: 0.4726 - acc: 0.7674 - val_loss: 0.5233 - val_acc: 0.7396\n",
      "Epoch 161/200\n",
      "576/576 [==============================] - 0s 113us/step - loss: 0.4723 - acc: 0.7674 - val_loss: 0.5231 - val_acc: 0.7396\n",
      "Epoch 162/200\n",
      "576/576 [==============================] - 0s 140us/step - loss: 0.4721 - acc: 0.7656 - val_loss: 0.5229 - val_acc: 0.7396\n",
      "Epoch 163/200\n",
      "576/576 [==============================] - 0s 112us/step - loss: 0.4717 - acc: 0.7656 - val_loss: 0.5228 - val_acc: 0.7396\n",
      "Epoch 164/200\n",
      "576/576 [==============================] - 0s 146us/step - loss: 0.4715 - acc: 0.7656 - val_loss: 0.5226 - val_acc: 0.7396\n",
      "Epoch 165/200\n",
      "576/576 [==============================] - 0s 111us/step - loss: 0.4712 - acc: 0.7656 - val_loss: 0.5224 - val_acc: 0.7396\n",
      "Epoch 166/200\n",
      "576/576 [==============================] - 0s 160us/step - loss: 0.4709 - acc: 0.7639 - val_loss: 0.5223 - val_acc: 0.7396\n",
      "Epoch 167/200\n",
      "576/576 [==============================] - 0s 85us/step - loss: 0.4706 - acc: 0.7639 - val_loss: 0.5221 - val_acc: 0.7396\n",
      "Epoch 168/200\n",
      "576/576 [==============================] - 0s 118us/step - loss: 0.4704 - acc: 0.7639 - val_loss: 0.5220 - val_acc: 0.7396\n",
      "Epoch 169/200\n",
      "576/576 [==============================] - 0s 146us/step - loss: 0.4701 - acc: 0.7639 - val_loss: 0.5218 - val_acc: 0.7396\n",
      "Epoch 170/200\n",
      "576/576 [==============================] - 0s 125us/step - loss: 0.4698 - acc: 0.7639 - val_loss: 0.5217 - val_acc: 0.7396\n",
      "Epoch 171/200\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.4696 - acc: 0.7622 - val_loss: 0.5215 - val_acc: 0.7396\n",
      "Epoch 172/200\n",
      "576/576 [==============================] - 0s 86us/step - loss: 0.4693 - acc: 0.7639 - val_loss: 0.5214 - val_acc: 0.7396\n",
      "Epoch 173/200\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4690 - acc: 0.7639 - val_loss: 0.5212 - val_acc: 0.7396\n",
      "Epoch 174/200\n",
      "576/576 [==============================] - 0s 94us/step - loss: 0.4688 - acc: 0.7639 - val_loss: 0.5211 - val_acc: 0.7396\n",
      "Epoch 175/200\n",
      "576/576 [==============================] - 0s 115us/step - loss: 0.4685 - acc: 0.7622 - val_loss: 0.5210 - val_acc: 0.7396\n",
      "Epoch 176/200\n",
      "576/576 [==============================] - 0s 112us/step - loss: 0.4683 - acc: 0.7622 - val_loss: 0.5208 - val_acc: 0.7396\n",
      "Epoch 177/200\n",
      "576/576 [==============================] - 0s 88us/step - loss: 0.4681 - acc: 0.7622 - val_loss: 0.5207 - val_acc: 0.7396\n",
      "Epoch 178/200\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4678 - acc: 0.7622 - val_loss: 0.5206 - val_acc: 0.7396\n",
      "Epoch 179/200\n",
      "576/576 [==============================] - 0s 111us/step - loss: 0.4675 - acc: 0.7622 - val_loss: 0.5204 - val_acc: 0.7396\n",
      "Epoch 180/200\n",
      "576/576 [==============================] - 0s 85us/step - loss: 0.4673 - acc: 0.7622 - val_loss: 0.5203 - val_acc: 0.7396\n",
      "Epoch 181/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 92us/step - loss: 0.4671 - acc: 0.7622 - val_loss: 0.5202 - val_acc: 0.7396\n",
      "Epoch 182/200\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4668 - acc: 0.7622 - val_loss: 0.5201 - val_acc: 0.7396\n",
      "Epoch 183/200\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4666 - acc: 0.7622 - val_loss: 0.5199 - val_acc: 0.7396\n",
      "Epoch 184/200\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.4664 - acc: 0.7622 - val_loss: 0.5198 - val_acc: 0.7396\n",
      "Epoch 185/200\n",
      "576/576 [==============================] - 0s 82us/step - loss: 0.4661 - acc: 0.7639 - val_loss: 0.5197 - val_acc: 0.7396\n",
      "Epoch 186/200\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4659 - acc: 0.7622 - val_loss: 0.5196 - val_acc: 0.7396\n",
      "Epoch 187/200\n",
      "576/576 [==============================] - 0s 73us/step - loss: 0.4657 - acc: 0.7622 - val_loss: 0.5195 - val_acc: 0.7396\n",
      "Epoch 188/200\n",
      "576/576 [==============================] - 0s 69us/step - loss: 0.4655 - acc: 0.7622 - val_loss: 0.5194 - val_acc: 0.7396\n",
      "Epoch 189/200\n",
      "576/576 [==============================] - 0s 65us/step - loss: 0.4653 - acc: 0.7639 - val_loss: 0.5193 - val_acc: 0.7396\n",
      "Epoch 190/200\n",
      "576/576 [==============================] - 0s 86us/step - loss: 0.4650 - acc: 0.7639 - val_loss: 0.5191 - val_acc: 0.7396\n",
      "Epoch 191/200\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4648 - acc: 0.7639 - val_loss: 0.5190 - val_acc: 0.7396\n",
      "Epoch 192/200\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4646 - acc: 0.7639 - val_loss: 0.5189 - val_acc: 0.7396\n",
      "Epoch 193/200\n",
      "576/576 [==============================] - 0s 68us/step - loss: 0.4644 - acc: 0.7639 - val_loss: 0.5188 - val_acc: 0.7396\n",
      "Epoch 194/200\n",
      "576/576 [==============================] - 0s 92us/step - loss: 0.4642 - acc: 0.7656 - val_loss: 0.5188 - val_acc: 0.7396\n",
      "Epoch 195/200\n",
      "576/576 [==============================] - 0s 66us/step - loss: 0.4640 - acc: 0.7639 - val_loss: 0.5187 - val_acc: 0.7396\n",
      "Epoch 196/200\n",
      "576/576 [==============================] - 0s 87us/step - loss: 0.4638 - acc: 0.7656 - val_loss: 0.5186 - val_acc: 0.7396\n",
      "Epoch 197/200\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4636 - acc: 0.7656 - val_loss: 0.5185 - val_acc: 0.7396\n",
      "Epoch 198/200\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4634 - acc: 0.7656 - val_loss: 0.5184 - val_acc: 0.7396\n",
      "Epoch 199/200\n",
      "576/576 [==============================] - 0s 85us/step - loss: 0.4632 - acc: 0.7656 - val_loss: 0.5183 - val_acc: 0.7448\n",
      "Epoch 200/200\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4630 - acc: 0.7656 - val_loss: 0.5182 - val_acc: 0.7448\n"
     ]
    }
   ],
   "source": [
    "# Fit(Train) the Model\n",
    "\n",
    "# Compile the model with Optimizer, Loss Function and Metrics\n",
    "# Roc-Auc is not available in Keras as an off the shelf metric yet, so we will skip it here.\n",
    "\n",
    "model_1.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "run_hist_1 = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=200)\n",
    "# the fit function returns the run history. \n",
    "# It is very convenient, as it contains information about the model fit, iterations etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Like we did for the Random Forest, we generate two kinds of predictions\n",
    "#  One is a hard decision, the other is a probabilitistic score.\n",
    "\n",
    "y_pred_class_nn_1 = model_1.predict_classes(X_test_norm)\n",
    "y_pred_prob_nn_1 = model_1.predict(X_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0]], dtype=int32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check out the outputs to get a feel for how keras apis work.\n",
    "y_pred_class_nn_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.55365306],\n",
       "       [0.53650475],\n",
       "       [0.38256246],\n",
       "       [0.42659926],\n",
       "       [0.14416505],\n",
       "       [0.47174218],\n",
       "       [0.04601027],\n",
       "       [0.41514298],\n",
       "       [0.8642378 ],\n",
       "       [0.18176754]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob_nn_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.745\n",
      "roc-auc is 0.793\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print model performance and plot the roc curve\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_1)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_1)))\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_nn_1, 'NN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There may be some variation in exact numbers due to randomness, but you should get results in the same ballpark as the Random Forest - between 75% and 85% accuracy, between .8 and .9 for AUC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the `run_hist_1` object that was created, specifically its `history` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_hist_1.history.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the training loss and the validation loss over the different epochs and see how it looks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fc7a02606d8>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
    "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the losses are still going down on both the training set and the validation set.  This suggests that the model might benefit from further training.  Let's train the model a little more and see what happens. Note that it will pick up from where it left off. Train for 1000 more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 576 samples, validate on 192 samples\n",
      "Epoch 1/1000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.4628 - acc: 0.7656 - val_loss: 0.5181 - val_acc: 0.7448\n",
      "Epoch 2/1000\n",
      "576/576 [==============================] - 0s 120us/step - loss: 0.4626 - acc: 0.7656 - val_loss: 0.5181 - val_acc: 0.7448\n",
      "Epoch 3/1000\n",
      "576/576 [==============================] - 0s 106us/step - loss: 0.4624 - acc: 0.7674 - val_loss: 0.5180 - val_acc: 0.7448\n",
      "Epoch 4/1000\n",
      "576/576 [==============================] - 0s 129us/step - loss: 0.4623 - acc: 0.7656 - val_loss: 0.5179 - val_acc: 0.7448\n",
      "Epoch 5/1000\n",
      "576/576 [==============================] - 0s 101us/step - loss: 0.4621 - acc: 0.7656 - val_loss: 0.5178 - val_acc: 0.7448\n",
      "Epoch 6/1000\n",
      "576/576 [==============================] - 0s 105us/step - loss: 0.4619 - acc: 0.7674 - val_loss: 0.5177 - val_acc: 0.7448\n",
      "Epoch 7/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4617 - acc: 0.7691 - val_loss: 0.5177 - val_acc: 0.7448\n",
      "Epoch 8/1000\n",
      "576/576 [==============================] - 0s 82us/step - loss: 0.4615 - acc: 0.7674 - val_loss: 0.5176 - val_acc: 0.7448\n",
      "Epoch 9/1000\n",
      "576/576 [==============================] - 0s 100us/step - loss: 0.4614 - acc: 0.7691 - val_loss: 0.5175 - val_acc: 0.7448\n",
      "Epoch 10/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4612 - acc: 0.7691 - val_loss: 0.5174 - val_acc: 0.7448\n",
      "Epoch 11/1000\n",
      "576/576 [==============================] - 0s 91us/step - loss: 0.4610 - acc: 0.7708 - val_loss: 0.5174 - val_acc: 0.7448\n",
      "Epoch 12/1000\n",
      "576/576 [==============================] - 0s 62us/step - loss: 0.4609 - acc: 0.7708 - val_loss: 0.5173 - val_acc: 0.7448\n",
      "Epoch 13/1000\n",
      "576/576 [==============================] - 0s 90us/step - loss: 0.4607 - acc: 0.7691 - val_loss: 0.5172 - val_acc: 0.7448\n",
      "Epoch 14/1000\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.4606 - acc: 0.7708 - val_loss: 0.5171 - val_acc: 0.7448\n",
      "Epoch 15/1000\n",
      "576/576 [==============================] - 0s 72us/step - loss: 0.4604 - acc: 0.7708 - val_loss: 0.5171 - val_acc: 0.7448\n",
      "Epoch 16/1000\n",
      "576/576 [==============================] - 0s 62us/step - loss: 0.4602 - acc: 0.7708 - val_loss: 0.5170 - val_acc: 0.7448\n",
      "Epoch 17/1000\n",
      "576/576 [==============================] - 0s 85us/step - loss: 0.4601 - acc: 0.7708 - val_loss: 0.5170 - val_acc: 0.7396\n",
      "Epoch 18/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4599 - acc: 0.7691 - val_loss: 0.5169 - val_acc: 0.7396\n",
      "Epoch 19/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4598 - acc: 0.7708 - val_loss: 0.5168 - val_acc: 0.7396\n",
      "Epoch 20/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4596 - acc: 0.7708 - val_loss: 0.5168 - val_acc: 0.7396\n",
      "Epoch 21/1000\n",
      "576/576 [==============================] - 0s 74us/step - loss: 0.4595 - acc: 0.7708 - val_loss: 0.5167 - val_acc: 0.7396\n",
      "Epoch 22/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4593 - acc: 0.7708 - val_loss: 0.5167 - val_acc: 0.7396\n",
      "Epoch 23/1000\n",
      "576/576 [==============================] - 0s 106us/step - loss: 0.4592 - acc: 0.7726 - val_loss: 0.5166 - val_acc: 0.7396\n",
      "Epoch 24/1000\n",
      "576/576 [==============================] - 0s 64us/step - loss: 0.4590 - acc: 0.7726 - val_loss: 0.5166 - val_acc: 0.7396\n",
      "Epoch 25/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4589 - acc: 0.7726 - val_loss: 0.5165 - val_acc: 0.7448\n",
      "Epoch 26/1000\n",
      "576/576 [==============================] - 0s 73us/step - loss: 0.4587 - acc: 0.7726 - val_loss: 0.5164 - val_acc: 0.7448\n",
      "Epoch 27/1000\n",
      "576/576 [==============================] - 0s 85us/step - loss: 0.4586 - acc: 0.7726 - val_loss: 0.5164 - val_acc: 0.7448\n",
      "Epoch 28/1000\n",
      "576/576 [==============================] - 0s 93us/step - loss: 0.4585 - acc: 0.7726 - val_loss: 0.5164 - val_acc: 0.7448\n",
      "Epoch 29/1000\n",
      "576/576 [==============================] - 0s 85us/step - loss: 0.4583 - acc: 0.7726 - val_loss: 0.5163 - val_acc: 0.7448\n",
      "Epoch 30/1000\n",
      "576/576 [==============================] - 0s 74us/step - loss: 0.4582 - acc: 0.7726 - val_loss: 0.5163 - val_acc: 0.7448\n",
      "Epoch 31/1000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.4580 - acc: 0.7726 - val_loss: 0.5162 - val_acc: 0.7448\n",
      "Epoch 32/1000\n",
      "576/576 [==============================] - 0s 133us/step - loss: 0.4579 - acc: 0.7708 - val_loss: 0.5162 - val_acc: 0.7448\n",
      "Epoch 33/1000\n",
      "576/576 [==============================] - 0s 95us/step - loss: 0.4578 - acc: 0.7708 - val_loss: 0.5161 - val_acc: 0.7448\n",
      "Epoch 34/1000\n",
      "576/576 [==============================] - 0s 83us/step - loss: 0.4576 - acc: 0.7726 - val_loss: 0.5161 - val_acc: 0.7448\n",
      "Epoch 35/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.4575 - acc: 0.7726 - val_loss: 0.5160 - val_acc: 0.7448\n",
      "Epoch 36/1000\n",
      "576/576 [==============================] - 0s 65us/step - loss: 0.4573 - acc: 0.7708 - val_loss: 0.5160 - val_acc: 0.7448\n",
      "Epoch 37/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.4572 - acc: 0.7708 - val_loss: 0.5159 - val_acc: 0.7448\n",
      "Epoch 38/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4571 - acc: 0.7708 - val_loss: 0.5159 - val_acc: 0.7448\n",
      "Epoch 39/1000\n",
      "576/576 [==============================] - 0s 95us/step - loss: 0.4570 - acc: 0.7708 - val_loss: 0.5158 - val_acc: 0.7448\n",
      "Epoch 40/1000\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4568 - acc: 0.7708 - val_loss: 0.5158 - val_acc: 0.7396\n",
      "Epoch 41/1000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.4567 - acc: 0.7708 - val_loss: 0.5158 - val_acc: 0.7396\n",
      "Epoch 42/1000\n",
      "576/576 [==============================] - 0s 85us/step - loss: 0.4566 - acc: 0.7708 - val_loss: 0.5157 - val_acc: 0.7396\n",
      "Epoch 43/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4564 - acc: 0.7708 - val_loss: 0.5157 - val_acc: 0.7396\n",
      "Epoch 44/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4563 - acc: 0.7708 - val_loss: 0.5156 - val_acc: 0.7396\n",
      "Epoch 45/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4562 - acc: 0.7708 - val_loss: 0.5156 - val_acc: 0.7396\n",
      "Epoch 46/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4561 - acc: 0.7708 - val_loss: 0.5156 - val_acc: 0.7448\n",
      "Epoch 47/1000\n",
      "576/576 [==============================] - 0s 73us/step - loss: 0.4560 - acc: 0.7708 - val_loss: 0.5155 - val_acc: 0.7448\n",
      "Epoch 48/1000\n",
      "576/576 [==============================] - 0s 87us/step - loss: 0.4558 - acc: 0.7708 - val_loss: 0.5155 - val_acc: 0.7448\n",
      "Epoch 49/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4557 - acc: 0.7708 - val_loss: 0.5155 - val_acc: 0.7448\n",
      "Epoch 50/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4556 - acc: 0.7708 - val_loss: 0.5154 - val_acc: 0.7448\n",
      "Epoch 51/1000\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.4554 - acc: 0.7708 - val_loss: 0.5154 - val_acc: 0.7448\n",
      "Epoch 52/1000\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.4553 - acc: 0.7708 - val_loss: 0.5153 - val_acc: 0.7448\n",
      "Epoch 53/1000\n",
      "576/576 [==============================] - 0s 82us/step - loss: 0.4552 - acc: 0.7691 - val_loss: 0.5153 - val_acc: 0.7448\n",
      "Epoch 54/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4551 - acc: 0.7726 - val_loss: 0.5153 - val_acc: 0.7448\n",
      "Epoch 55/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4550 - acc: 0.7708 - val_loss: 0.5152 - val_acc: 0.7448\n",
      "Epoch 56/1000\n",
      "576/576 [==============================] - 0s 72us/step - loss: 0.4548 - acc: 0.7708 - val_loss: 0.5152 - val_acc: 0.7448\n",
      "Epoch 57/1000\n",
      "576/576 [==============================] - 0s 82us/step - loss: 0.4547 - acc: 0.7708 - val_loss: 0.5152 - val_acc: 0.7448\n",
      "Epoch 58/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4546 - acc: 0.7708 - val_loss: 0.5151 - val_acc: 0.7448\n",
      "Epoch 59/1000\n",
      "576/576 [==============================] - 0s 92us/step - loss: 0.4545 - acc: 0.7708 - val_loss: 0.5151 - val_acc: 0.7448\n",
      "Epoch 60/1000\n",
      "576/576 [==============================] - 0s 92us/step - loss: 0.4544 - acc: 0.7708 - val_loss: 0.5151 - val_acc: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/1000\n",
      "576/576 [==============================] - 0s 82us/step - loss: 0.4543 - acc: 0.7708 - val_loss: 0.5150 - val_acc: 0.7448\n",
      "Epoch 62/1000\n",
      "576/576 [==============================] - 0s 64us/step - loss: 0.4541 - acc: 0.7708 - val_loss: 0.5150 - val_acc: 0.7448\n",
      "Epoch 63/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4540 - acc: 0.7708 - val_loss: 0.5150 - val_acc: 0.7448\n",
      "Epoch 64/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4539 - acc: 0.7708 - val_loss: 0.5149 - val_acc: 0.7448\n",
      "Epoch 65/1000\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.4538 - acc: 0.7708 - val_loss: 0.5149 - val_acc: 0.7448\n",
      "Epoch 66/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4537 - acc: 0.7691 - val_loss: 0.5149 - val_acc: 0.7448\n",
      "Epoch 67/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4536 - acc: 0.7708 - val_loss: 0.5149 - val_acc: 0.7448\n",
      "Epoch 68/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4535 - acc: 0.7708 - val_loss: 0.5148 - val_acc: 0.7448\n",
      "Epoch 69/1000\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.4534 - acc: 0.7708 - val_loss: 0.5148 - val_acc: 0.7448\n",
      "Epoch 70/1000\n",
      "576/576 [==============================] - 0s 60us/step - loss: 0.4533 - acc: 0.7743 - val_loss: 0.5148 - val_acc: 0.7448\n",
      "Epoch 71/1000\n",
      "576/576 [==============================] - 0s 72us/step - loss: 0.4532 - acc: 0.7743 - val_loss: 0.5148 - val_acc: 0.7448\n",
      "Epoch 72/1000\n",
      "576/576 [==============================] - 0s 70us/step - loss: 0.4530 - acc: 0.7743 - val_loss: 0.5147 - val_acc: 0.7448\n",
      "Epoch 73/1000\n",
      "576/576 [==============================] - 0s 68us/step - loss: 0.4529 - acc: 0.7743 - val_loss: 0.5147 - val_acc: 0.7448\n",
      "Epoch 74/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4528 - acc: 0.7743 - val_loss: 0.5147 - val_acc: 0.7448\n",
      "Epoch 75/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4527 - acc: 0.7743 - val_loss: 0.5147 - val_acc: 0.7448\n",
      "Epoch 76/1000\n",
      "576/576 [==============================] - 0s 65us/step - loss: 0.4526 - acc: 0.7726 - val_loss: 0.5146 - val_acc: 0.7448\n",
      "Epoch 77/1000\n",
      "576/576 [==============================] - 0s 68us/step - loss: 0.4525 - acc: 0.7726 - val_loss: 0.5146 - val_acc: 0.7448\n",
      "Epoch 78/1000\n",
      "576/576 [==============================] - 0s 70us/step - loss: 0.4524 - acc: 0.7726 - val_loss: 0.5146 - val_acc: 0.7448\n",
      "Epoch 79/1000\n",
      "576/576 [==============================] - 0s 63us/step - loss: 0.4523 - acc: 0.7726 - val_loss: 0.5146 - val_acc: 0.7448\n",
      "Epoch 80/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4522 - acc: 0.7726 - val_loss: 0.5146 - val_acc: 0.7448\n",
      "Epoch 81/1000\n",
      "576/576 [==============================] - 0s 62us/step - loss: 0.4521 - acc: 0.7708 - val_loss: 0.5145 - val_acc: 0.7448\n",
      "Epoch 82/1000\n",
      "576/576 [==============================] - 0s 70us/step - loss: 0.4520 - acc: 0.7726 - val_loss: 0.5145 - val_acc: 0.7448\n",
      "Epoch 83/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4519 - acc: 0.7726 - val_loss: 0.5145 - val_acc: 0.7448\n",
      "Epoch 84/1000\n",
      "576/576 [==============================] - 0s 63us/step - loss: 0.4518 - acc: 0.7708 - val_loss: 0.5145 - val_acc: 0.7448\n",
      "Epoch 85/1000\n",
      "576/576 [==============================] - 0s 73us/step - loss: 0.4517 - acc: 0.7726 - val_loss: 0.5145 - val_acc: 0.7448\n",
      "Epoch 86/1000\n",
      "576/576 [==============================] - 0s 64us/step - loss: 0.4516 - acc: 0.7726 - val_loss: 0.5145 - val_acc: 0.7448\n",
      "Epoch 87/1000\n",
      "576/576 [==============================] - 0s 65us/step - loss: 0.4515 - acc: 0.7726 - val_loss: 0.5144 - val_acc: 0.7448\n",
      "Epoch 88/1000\n",
      "576/576 [==============================] - 0s 85us/step - loss: 0.4514 - acc: 0.7726 - val_loss: 0.5144 - val_acc: 0.7448\n",
      "Epoch 89/1000\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.4513 - acc: 0.7726 - val_loss: 0.5144 - val_acc: 0.7448\n",
      "Epoch 90/1000\n",
      "576/576 [==============================] - 0s 70us/step - loss: 0.4512 - acc: 0.7726 - val_loss: 0.5144 - val_acc: 0.7448\n",
      "Epoch 91/1000\n",
      "576/576 [==============================] - 0s 69us/step - loss: 0.4511 - acc: 0.7726 - val_loss: 0.5144 - val_acc: 0.7448\n",
      "Epoch 92/1000\n",
      "576/576 [==============================] - 0s 65us/step - loss: 0.4510 - acc: 0.7726 - val_loss: 0.5144 - val_acc: 0.7448\n",
      "Epoch 93/1000\n",
      "576/576 [==============================] - 0s 72us/step - loss: 0.4509 - acc: 0.7726 - val_loss: 0.5143 - val_acc: 0.7448\n",
      "Epoch 94/1000\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.4508 - acc: 0.7726 - val_loss: 0.5143 - val_acc: 0.7448\n",
      "Epoch 95/1000\n",
      "576/576 [==============================] - 0s 72us/step - loss: 0.4507 - acc: 0.7726 - val_loss: 0.5143 - val_acc: 0.7448\n",
      "Epoch 96/1000\n",
      "576/576 [==============================] - 0s 70us/step - loss: 0.4506 - acc: 0.7726 - val_loss: 0.5143 - val_acc: 0.7448\n",
      "Epoch 97/1000\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4505 - acc: 0.7726 - val_loss: 0.5143 - val_acc: 0.7448\n",
      "Epoch 98/1000\n",
      "576/576 [==============================] - 0s 65us/step - loss: 0.4504 - acc: 0.7726 - val_loss: 0.5142 - val_acc: 0.7448\n",
      "Epoch 99/1000\n",
      "576/576 [==============================] - 0s 72us/step - loss: 0.4503 - acc: 0.7726 - val_loss: 0.5142 - val_acc: 0.7448\n",
      "Epoch 100/1000\n",
      "576/576 [==============================] - 0s 104us/step - loss: 0.4502 - acc: 0.7726 - val_loss: 0.5142 - val_acc: 0.7448\n",
      "Epoch 101/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4502 - acc: 0.7726 - val_loss: 0.5142 - val_acc: 0.7448\n",
      "Epoch 102/1000\n",
      "576/576 [==============================] - 0s 94us/step - loss: 0.4500 - acc: 0.7726 - val_loss: 0.5142 - val_acc: 0.7448\n",
      "Epoch 103/1000\n",
      "576/576 [==============================] - 0s 93us/step - loss: 0.4499 - acc: 0.7726 - val_loss: 0.5142 - val_acc: 0.7448\n",
      "Epoch 104/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4499 - acc: 0.7726 - val_loss: 0.5142 - val_acc: 0.7448\n",
      "Epoch 105/1000\n",
      "576/576 [==============================] - 0s 65us/step - loss: 0.4498 - acc: 0.7726 - val_loss: 0.5142 - val_acc: 0.7448\n",
      "Epoch 106/1000\n",
      "576/576 [==============================] - 0s 83us/step - loss: 0.4497 - acc: 0.7726 - val_loss: 0.5141 - val_acc: 0.7448\n",
      "Epoch 107/1000\n",
      "576/576 [==============================] - 0s 84us/step - loss: 0.4496 - acc: 0.7743 - val_loss: 0.5141 - val_acc: 0.7448\n",
      "Epoch 108/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4495 - acc: 0.7708 - val_loss: 0.5141 - val_acc: 0.7448\n",
      "Epoch 109/1000\n",
      "576/576 [==============================] - 0s 67us/step - loss: 0.4494 - acc: 0.7726 - val_loss: 0.5141 - val_acc: 0.7448\n",
      "Epoch 110/1000\n",
      "576/576 [==============================] - 0s 67us/step - loss: 0.4493 - acc: 0.7726 - val_loss: 0.5141 - val_acc: 0.7448\n",
      "Epoch 111/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4492 - acc: 0.7726 - val_loss: 0.5141 - val_acc: 0.7448\n",
      "Epoch 112/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4491 - acc: 0.7708 - val_loss: 0.5141 - val_acc: 0.7448\n",
      "Epoch 113/1000\n",
      "576/576 [==============================] - 0s 69us/step - loss: 0.4491 - acc: 0.7743 - val_loss: 0.5141 - val_acc: 0.7448\n",
      "Epoch 114/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4490 - acc: 0.7708 - val_loss: 0.5141 - val_acc: 0.7448\n",
      "Epoch 115/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4489 - acc: 0.7708 - val_loss: 0.5141 - val_acc: 0.7448\n",
      "Epoch 116/1000\n",
      "576/576 [==============================] - 0s 72us/step - loss: 0.4488 - acc: 0.7708 - val_loss: 0.5141 - val_acc: 0.7448\n",
      "Epoch 117/1000\n",
      "576/576 [==============================] - 0s 62us/step - loss: 0.4487 - acc: 0.7726 - val_loss: 0.5141 - val_acc: 0.7448\n",
      "Epoch 118/1000\n",
      "576/576 [==============================] - 0s 82us/step - loss: 0.4487 - acc: 0.7691 - val_loss: 0.5141 - val_acc: 0.7448\n",
      "Epoch 119/1000\n",
      "576/576 [==============================] - 0s 74us/step - loss: 0.4486 - acc: 0.7708 - val_loss: 0.5140 - val_acc: 0.7448\n",
      "Epoch 120/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4484 - acc: 0.7691 - val_loss: 0.5140 - val_acc: 0.7448\n",
      "Epoch 121/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 69us/step - loss: 0.4484 - acc: 0.7691 - val_loss: 0.5140 - val_acc: 0.7448\n",
      "Epoch 122/1000\n",
      "576/576 [==============================] - 0s 65us/step - loss: 0.4483 - acc: 0.7708 - val_loss: 0.5140 - val_acc: 0.7448\n",
      "Epoch 123/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4482 - acc: 0.7708 - val_loss: 0.5140 - val_acc: 0.7448\n",
      "Epoch 124/1000\n",
      "576/576 [==============================] - 0s 64us/step - loss: 0.4481 - acc: 0.7708 - val_loss: 0.5140 - val_acc: 0.7448\n",
      "Epoch 125/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4480 - acc: 0.7708 - val_loss: 0.5140 - val_acc: 0.7448\n",
      "Epoch 126/1000\n",
      "576/576 [==============================] - 0s 64us/step - loss: 0.4480 - acc: 0.7708 - val_loss: 0.5140 - val_acc: 0.7448\n",
      "Epoch 127/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4479 - acc: 0.7708 - val_loss: 0.5140 - val_acc: 0.7448\n",
      "Epoch 128/1000\n",
      "576/576 [==============================] - 0s 63us/step - loss: 0.4478 - acc: 0.7708 - val_loss: 0.5140 - val_acc: 0.7448\n",
      "Epoch 129/1000\n",
      "576/576 [==============================] - 0s 67us/step - loss: 0.4477 - acc: 0.7691 - val_loss: 0.5140 - val_acc: 0.7448\n",
      "Epoch 130/1000\n",
      "576/576 [==============================] - 0s 68us/step - loss: 0.4476 - acc: 0.7708 - val_loss: 0.5140 - val_acc: 0.7448\n",
      "Epoch 131/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4476 - acc: 0.7708 - val_loss: 0.5140 - val_acc: 0.7448\n",
      "Epoch 132/1000\n",
      "576/576 [==============================] - 0s 70us/step - loss: 0.4475 - acc: 0.7708 - val_loss: 0.5140 - val_acc: 0.7448\n",
      "Epoch 133/1000\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.4474 - acc: 0.7691 - val_loss: 0.5140 - val_acc: 0.7448\n",
      "Epoch 134/1000\n",
      "576/576 [==============================] - 0s 62us/step - loss: 0.4473 - acc: 0.7708 - val_loss: 0.5140 - val_acc: 0.7448\n",
      "Epoch 135/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4472 - acc: 0.7708 - val_loss: 0.5140 - val_acc: 0.7448\n",
      "Epoch 136/1000\n",
      "576/576 [==============================] - 0s 64us/step - loss: 0.4471 - acc: 0.7708 - val_loss: 0.5139 - val_acc: 0.7448\n",
      "Epoch 137/1000\n",
      "576/576 [==============================] - 0s 64us/step - loss: 0.4471 - acc: 0.7708 - val_loss: 0.5139 - val_acc: 0.7448\n",
      "Epoch 138/1000\n",
      "576/576 [==============================] - 0s 106us/step - loss: 0.4470 - acc: 0.7708 - val_loss: 0.5139 - val_acc: 0.7448\n",
      "Epoch 139/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.4469 - acc: 0.7674 - val_loss: 0.5139 - val_acc: 0.7448\n",
      "Epoch 140/1000\n",
      "576/576 [==============================] - 0s 87us/step - loss: 0.4468 - acc: 0.7691 - val_loss: 0.5139 - val_acc: 0.7448\n",
      "Epoch 141/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.4468 - acc: 0.7691 - val_loss: 0.5139 - val_acc: 0.7448\n",
      "Epoch 142/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4467 - acc: 0.7708 - val_loss: 0.5139 - val_acc: 0.7448\n",
      "Epoch 143/1000\n",
      "576/576 [==============================] - 0s 85us/step - loss: 0.4467 - acc: 0.7691 - val_loss: 0.5139 - val_acc: 0.7448\n",
      "Epoch 144/1000\n",
      "576/576 [==============================] - 0s 65us/step - loss: 0.4466 - acc: 0.7691 - val_loss: 0.5139 - val_acc: 0.7448\n",
      "Epoch 145/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4465 - acc: 0.7691 - val_loss: 0.5139 - val_acc: 0.7448\n",
      "Epoch 146/1000\n",
      "576/576 [==============================] - 0s 70us/step - loss: 0.4464 - acc: 0.7691 - val_loss: 0.5139 - val_acc: 0.7448\n",
      "Epoch 147/1000\n",
      "576/576 [==============================] - 0s 69us/step - loss: 0.4463 - acc: 0.7691 - val_loss: 0.5139 - val_acc: 0.7448\n",
      "Epoch 148/1000\n",
      "576/576 [==============================] - 0s 94us/step - loss: 0.4463 - acc: 0.7691 - val_loss: 0.5139 - val_acc: 0.7448\n",
      "Epoch 149/1000\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.4462 - acc: 0.7691 - val_loss: 0.5139 - val_acc: 0.7448\n",
      "Epoch 150/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4461 - acc: 0.7691 - val_loss: 0.5139 - val_acc: 0.7448\n",
      "Epoch 151/1000\n",
      "576/576 [==============================] - 0s 69us/step - loss: 0.4461 - acc: 0.7691 - val_loss: 0.5140 - val_acc: 0.7448\n",
      "Epoch 152/1000\n",
      "576/576 [==============================] - 0s 82us/step - loss: 0.4460 - acc: 0.7691 - val_loss: 0.5140 - val_acc: 0.7448\n",
      "Epoch 153/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4459 - acc: 0.7691 - val_loss: 0.5140 - val_acc: 0.7448\n",
      "Epoch 154/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4459 - acc: 0.7691 - val_loss: 0.5140 - val_acc: 0.7448\n",
      "Epoch 155/1000\n",
      "576/576 [==============================] - 0s 73us/step - loss: 0.4458 - acc: 0.7691 - val_loss: 0.5140 - val_acc: 0.7448\n",
      "Epoch 156/1000\n",
      "576/576 [==============================] - 0s 67us/step - loss: 0.4457 - acc: 0.7691 - val_loss: 0.5140 - val_acc: 0.7448\n",
      "Epoch 157/1000\n",
      "576/576 [==============================] - 0s 101us/step - loss: 0.4456 - acc: 0.7691 - val_loss: 0.5140 - val_acc: 0.7448\n",
      "Epoch 158/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4455 - acc: 0.7691 - val_loss: 0.5140 - val_acc: 0.7448\n",
      "Epoch 159/1000\n",
      "576/576 [==============================] - 0s 84us/step - loss: 0.4455 - acc: 0.7691 - val_loss: 0.5140 - val_acc: 0.7448\n",
      "Epoch 160/1000\n",
      "576/576 [==============================] - 0s 69us/step - loss: 0.4454 - acc: 0.7691 - val_loss: 0.5140 - val_acc: 0.7448\n",
      "Epoch 161/1000\n",
      "576/576 [==============================] - 0s 82us/step - loss: 0.4454 - acc: 0.7691 - val_loss: 0.5140 - val_acc: 0.7448\n",
      "Epoch 162/1000\n",
      "576/576 [==============================] - 0s 60us/step - loss: 0.4453 - acc: 0.7691 - val_loss: 0.5140 - val_acc: 0.7448\n",
      "Epoch 163/1000\n",
      "576/576 [==============================] - 0s 82us/step - loss: 0.4452 - acc: 0.7691 - val_loss: 0.5140 - val_acc: 0.7396\n",
      "Epoch 164/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4452 - acc: 0.7691 - val_loss: 0.5140 - val_acc: 0.7396\n",
      "Epoch 165/1000\n",
      "576/576 [==============================] - 0s 102us/step - loss: 0.4451 - acc: 0.7691 - val_loss: 0.5140 - val_acc: 0.7396\n",
      "Epoch 166/1000\n",
      "576/576 [==============================] - 0s 190us/step - loss: 0.4450 - acc: 0.7674 - val_loss: 0.5140 - val_acc: 0.7396\n",
      "Epoch 167/1000\n",
      "576/576 [==============================] - 0s 156us/step - loss: 0.4449 - acc: 0.7674 - val_loss: 0.5140 - val_acc: 0.7344\n",
      "Epoch 168/1000\n",
      "576/576 [==============================] - 0s 151us/step - loss: 0.4449 - acc: 0.7691 - val_loss: 0.5140 - val_acc: 0.7344\n",
      "Epoch 169/1000\n",
      "576/576 [==============================] - 0s 133us/step - loss: 0.4448 - acc: 0.7674 - val_loss: 0.5140 - val_acc: 0.7344\n",
      "Epoch 170/1000\n",
      "576/576 [==============================] - 0s 124us/step - loss: 0.4447 - acc: 0.7691 - val_loss: 0.5140 - val_acc: 0.7344\n",
      "Epoch 171/1000\n",
      "576/576 [==============================] - 0s 143us/step - loss: 0.4447 - acc: 0.7674 - val_loss: 0.5140 - val_acc: 0.7344\n",
      "Epoch 172/1000\n",
      "576/576 [==============================] - 0s 112us/step - loss: 0.4446 - acc: 0.7674 - val_loss: 0.5140 - val_acc: 0.7344\n",
      "Epoch 173/1000\n",
      "576/576 [==============================] - 0s 101us/step - loss: 0.4446 - acc: 0.7674 - val_loss: 0.5140 - val_acc: 0.7344\n",
      "Epoch 174/1000\n",
      "576/576 [==============================] - 0s 73us/step - loss: 0.4445 - acc: 0.7674 - val_loss: 0.5140 - val_acc: 0.7344\n",
      "Epoch 175/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4444 - acc: 0.7674 - val_loss: 0.5140 - val_acc: 0.7344\n",
      "Epoch 176/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4444 - acc: 0.7691 - val_loss: 0.5140 - val_acc: 0.7344\n",
      "Epoch 177/1000\n",
      "576/576 [==============================] - 0s 90us/step - loss: 0.4443 - acc: 0.7674 - val_loss: 0.5140 - val_acc: 0.7344\n",
      "Epoch 178/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4442 - acc: 0.7674 - val_loss: 0.5140 - val_acc: 0.7344\n",
      "Epoch 179/1000\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.4442 - acc: 0.7674 - val_loss: 0.5140 - val_acc: 0.7344\n",
      "Epoch 180/1000\n",
      "576/576 [==============================] - 0s 132us/step - loss: 0.4441 - acc: 0.7691 - val_loss: 0.5140 - val_acc: 0.7396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/1000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.4440 - acc: 0.7691 - val_loss: 0.5140 - val_acc: 0.7396\n",
      "Epoch 182/1000\n",
      "576/576 [==============================] - 0s 109us/step - loss: 0.4440 - acc: 0.7691 - val_loss: 0.5140 - val_acc: 0.7396\n",
      "Epoch 183/1000\n",
      "576/576 [==============================] - 0s 113us/step - loss: 0.4439 - acc: 0.7691 - val_loss: 0.5140 - val_acc: 0.7396\n",
      "Epoch 184/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4438 - acc: 0.7691 - val_loss: 0.5140 - val_acc: 0.7396\n",
      "Epoch 185/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4438 - acc: 0.7691 - val_loss: 0.5140 - val_acc: 0.7396\n",
      "Epoch 186/1000\n",
      "576/576 [==============================] - 0s 68us/step - loss: 0.4437 - acc: 0.7691 - val_loss: 0.5141 - val_acc: 0.7396\n",
      "Epoch 187/1000\n",
      "576/576 [==============================] - 0s 72us/step - loss: 0.4437 - acc: 0.7691 - val_loss: 0.5141 - val_acc: 0.7396\n",
      "Epoch 188/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.4436 - acc: 0.7691 - val_loss: 0.5141 - val_acc: 0.7396\n",
      "Epoch 189/1000\n",
      "576/576 [==============================] - 0s 74us/step - loss: 0.4435 - acc: 0.7691 - val_loss: 0.5141 - val_acc: 0.7396\n",
      "Epoch 190/1000\n",
      "576/576 [==============================] - 0s 111us/step - loss: 0.4435 - acc: 0.7691 - val_loss: 0.5141 - val_acc: 0.7396\n",
      "Epoch 191/1000\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.4434 - acc: 0.7691 - val_loss: 0.5141 - val_acc: 0.7396\n",
      "Epoch 192/1000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.4434 - acc: 0.7691 - val_loss: 0.5141 - val_acc: 0.7396\n",
      "Epoch 193/1000\n",
      "576/576 [==============================] - 0s 124us/step - loss: 0.4433 - acc: 0.7691 - val_loss: 0.5141 - val_acc: 0.7448\n",
      "Epoch 194/1000\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.4432 - acc: 0.7691 - val_loss: 0.5141 - val_acc: 0.7448\n",
      "Epoch 195/1000\n",
      "576/576 [==============================] - 0s 88us/step - loss: 0.4432 - acc: 0.7691 - val_loss: 0.5141 - val_acc: 0.7448\n",
      "Epoch 196/1000\n",
      "576/576 [==============================] - 0s 74us/step - loss: 0.4431 - acc: 0.7691 - val_loss: 0.5141 - val_acc: 0.7448\n",
      "Epoch 197/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4430 - acc: 0.7691 - val_loss: 0.5141 - val_acc: 0.7448\n",
      "Epoch 198/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4430 - acc: 0.7691 - val_loss: 0.5141 - val_acc: 0.7448\n",
      "Epoch 199/1000\n",
      "576/576 [==============================] - 0s 91us/step - loss: 0.4429 - acc: 0.7691 - val_loss: 0.5141 - val_acc: 0.7448\n",
      "Epoch 200/1000\n",
      "576/576 [==============================] - 0s 101us/step - loss: 0.4429 - acc: 0.7691 - val_loss: 0.5141 - val_acc: 0.7448\n",
      "Epoch 201/1000\n",
      "576/576 [==============================] - 0s 98us/step - loss: 0.4428 - acc: 0.7691 - val_loss: 0.5142 - val_acc: 0.7448\n",
      "Epoch 202/1000\n",
      "576/576 [==============================] - 0s 85us/step - loss: 0.4427 - acc: 0.7691 - val_loss: 0.5142 - val_acc: 0.7448\n",
      "Epoch 203/1000\n",
      "576/576 [==============================] - 0s 82us/step - loss: 0.4427 - acc: 0.7691 - val_loss: 0.5142 - val_acc: 0.7448\n",
      "Epoch 204/1000\n",
      "576/576 [==============================] - 0s 101us/step - loss: 0.4426 - acc: 0.7708 - val_loss: 0.5142 - val_acc: 0.7448\n",
      "Epoch 205/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.4425 - acc: 0.7708 - val_loss: 0.5142 - val_acc: 0.7448\n",
      "Epoch 206/1000\n",
      "576/576 [==============================] - 0s 130us/step - loss: 0.4425 - acc: 0.7708 - val_loss: 0.5142 - val_acc: 0.7448\n",
      "Epoch 207/1000\n",
      "576/576 [==============================] - 0s 114us/step - loss: 0.4424 - acc: 0.7708 - val_loss: 0.5142 - val_acc: 0.7500\n",
      "Epoch 208/1000\n",
      "576/576 [==============================] - 0s 112us/step - loss: 0.4423 - acc: 0.7708 - val_loss: 0.5142 - val_acc: 0.7500\n",
      "Epoch 209/1000\n",
      "576/576 [==============================] - 0s 89us/step - loss: 0.4423 - acc: 0.7708 - val_loss: 0.5142 - val_acc: 0.7500\n",
      "Epoch 210/1000\n",
      "576/576 [==============================] - 0s 85us/step - loss: 0.4422 - acc: 0.7708 - val_loss: 0.5143 - val_acc: 0.7500\n",
      "Epoch 211/1000\n",
      "576/576 [==============================] - 0s 95us/step - loss: 0.4422 - acc: 0.7708 - val_loss: 0.5143 - val_acc: 0.7500\n",
      "Epoch 212/1000\n",
      "576/576 [==============================] - 0s 101us/step - loss: 0.4421 - acc: 0.7708 - val_loss: 0.5143 - val_acc: 0.7500\n",
      "Epoch 213/1000\n",
      "576/576 [==============================] - 0s 125us/step - loss: 0.4421 - acc: 0.7708 - val_loss: 0.5143 - val_acc: 0.7500\n",
      "Epoch 214/1000\n",
      "576/576 [==============================] - 0s 116us/step - loss: 0.4420 - acc: 0.7708 - val_loss: 0.5143 - val_acc: 0.7500\n",
      "Epoch 215/1000\n",
      "576/576 [==============================] - 0s 118us/step - loss: 0.4419 - acc: 0.7708 - val_loss: 0.5143 - val_acc: 0.7500\n",
      "Epoch 216/1000\n",
      "576/576 [==============================] - 0s 153us/step - loss: 0.4419 - acc: 0.7708 - val_loss: 0.5143 - val_acc: 0.7500\n",
      "Epoch 217/1000\n",
      "576/576 [==============================] - 0s 118us/step - loss: 0.4418 - acc: 0.7691 - val_loss: 0.5143 - val_acc: 0.7500\n",
      "Epoch 218/1000\n",
      "576/576 [==============================] - 0s 111us/step - loss: 0.4418 - acc: 0.7708 - val_loss: 0.5144 - val_acc: 0.7500\n",
      "Epoch 219/1000\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.4417 - acc: 0.7691 - val_loss: 0.5144 - val_acc: 0.7500\n",
      "Epoch 220/1000\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4416 - acc: 0.7691 - val_loss: 0.5144 - val_acc: 0.7500\n",
      "Epoch 221/1000\n",
      "576/576 [==============================] - 0s 114us/step - loss: 0.4416 - acc: 0.7691 - val_loss: 0.5144 - val_acc: 0.7500\n",
      "Epoch 222/1000\n",
      "576/576 [==============================] - 0s 101us/step - loss: 0.4415 - acc: 0.7691 - val_loss: 0.5144 - val_acc: 0.7500\n",
      "Epoch 223/1000\n",
      "576/576 [==============================] - 0s 108us/step - loss: 0.4415 - acc: 0.7691 - val_loss: 0.5144 - val_acc: 0.7448\n",
      "Epoch 224/1000\n",
      "576/576 [==============================] - 0s 82us/step - loss: 0.4414 - acc: 0.7674 - val_loss: 0.5144 - val_acc: 0.7448\n",
      "Epoch 225/1000\n",
      "576/576 [==============================] - 0s 95us/step - loss: 0.4414 - acc: 0.7691 - val_loss: 0.5145 - val_acc: 0.7448\n",
      "Epoch 226/1000\n",
      "576/576 [==============================] - 0s 104us/step - loss: 0.4413 - acc: 0.7691 - val_loss: 0.5145 - val_acc: 0.7448\n",
      "Epoch 227/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4412 - acc: 0.7691 - val_loss: 0.5145 - val_acc: 0.7448\n",
      "Epoch 228/1000\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4412 - acc: 0.7691 - val_loss: 0.5145 - val_acc: 0.7448\n",
      "Epoch 229/1000\n",
      "576/576 [==============================] - 0s 112us/step - loss: 0.4412 - acc: 0.7691 - val_loss: 0.5145 - val_acc: 0.7448\n",
      "Epoch 230/1000\n",
      "576/576 [==============================] - 0s 105us/step - loss: 0.4411 - acc: 0.7691 - val_loss: 0.5145 - val_acc: 0.7448\n",
      "Epoch 231/1000\n",
      "576/576 [==============================] - 0s 145us/step - loss: 0.4410 - acc: 0.7691 - val_loss: 0.5145 - val_acc: 0.7448\n",
      "Epoch 232/1000\n",
      "576/576 [==============================] - 0s 117us/step - loss: 0.4410 - acc: 0.7708 - val_loss: 0.5146 - val_acc: 0.7448\n",
      "Epoch 233/1000\n",
      "576/576 [==============================] - 0s 104us/step - loss: 0.4409 - acc: 0.7708 - val_loss: 0.5146 - val_acc: 0.7448\n",
      "Epoch 234/1000\n",
      "576/576 [==============================] - 0s 121us/step - loss: 0.4409 - acc: 0.7674 - val_loss: 0.5146 - val_acc: 0.7448\n",
      "Epoch 235/1000\n",
      "576/576 [==============================] - 0s 115us/step - loss: 0.4409 - acc: 0.7691 - val_loss: 0.5146 - val_acc: 0.7448\n",
      "Epoch 236/1000\n",
      "576/576 [==============================] - 0s 119us/step - loss: 0.4408 - acc: 0.7708 - val_loss: 0.5146 - val_acc: 0.7448\n",
      "Epoch 237/1000\n",
      "576/576 [==============================] - 0s 100us/step - loss: 0.4407 - acc: 0.7708 - val_loss: 0.5146 - val_acc: 0.7448\n",
      "Epoch 238/1000\n",
      "576/576 [==============================] - 0s 127us/step - loss: 0.4407 - acc: 0.7691 - val_loss: 0.5146 - val_acc: 0.7500\n",
      "Epoch 239/1000\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.4406 - acc: 0.7691 - val_loss: 0.5147 - val_acc: 0.7500\n",
      "Epoch 240/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 119us/step - loss: 0.4406 - acc: 0.7691 - val_loss: 0.5147 - val_acc: 0.7500\n",
      "Epoch 241/1000\n",
      "576/576 [==============================] - 0s 94us/step - loss: 0.4405 - acc: 0.7708 - val_loss: 0.5147 - val_acc: 0.7500\n",
      "Epoch 242/1000\n",
      "576/576 [==============================] - 0s 124us/step - loss: 0.4405 - acc: 0.7708 - val_loss: 0.5147 - val_acc: 0.7500\n",
      "Epoch 243/1000\n",
      "576/576 [==============================] - 0s 114us/step - loss: 0.4404 - acc: 0.7708 - val_loss: 0.5147 - val_acc: 0.7500\n",
      "Epoch 244/1000\n",
      "576/576 [==============================] - 0s 82us/step - loss: 0.4404 - acc: 0.7726 - val_loss: 0.5147 - val_acc: 0.7500\n",
      "Epoch 245/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.4403 - acc: 0.7708 - val_loss: 0.5147 - val_acc: 0.7500\n",
      "Epoch 246/1000\n",
      "576/576 [==============================] - 0s 74us/step - loss: 0.4403 - acc: 0.7726 - val_loss: 0.5148 - val_acc: 0.7500\n",
      "Epoch 247/1000\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.4403 - acc: 0.7743 - val_loss: 0.5148 - val_acc: 0.7500\n",
      "Epoch 248/1000\n",
      "576/576 [==============================] - 0s 86us/step - loss: 0.4402 - acc: 0.7743 - val_loss: 0.5148 - val_acc: 0.7500\n",
      "Epoch 249/1000\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4401 - acc: 0.7708 - val_loss: 0.5148 - val_acc: 0.7500\n",
      "Epoch 250/1000\n",
      "576/576 [==============================] - 0s 147us/step - loss: 0.4401 - acc: 0.7743 - val_loss: 0.5148 - val_acc: 0.7500\n",
      "Epoch 251/1000\n",
      "576/576 [==============================] - 0s 111us/step - loss: 0.4401 - acc: 0.7743 - val_loss: 0.5148 - val_acc: 0.7500\n",
      "Epoch 252/1000\n",
      "576/576 [==============================] - 0s 113us/step - loss: 0.4400 - acc: 0.7743 - val_loss: 0.5148 - val_acc: 0.7500\n",
      "Epoch 253/1000\n",
      "576/576 [==============================] - 0s 115us/step - loss: 0.4400 - acc: 0.7743 - val_loss: 0.5149 - val_acc: 0.7500\n",
      "Epoch 254/1000\n",
      "576/576 [==============================] - 0s 140us/step - loss: 0.4399 - acc: 0.7743 - val_loss: 0.5149 - val_acc: 0.7500\n",
      "Epoch 255/1000\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.4399 - acc: 0.7743 - val_loss: 0.5149 - val_acc: 0.7500\n",
      "Epoch 256/1000\n",
      "576/576 [==============================] - 0s 129us/step - loss: 0.4398 - acc: 0.7743 - val_loss: 0.5149 - val_acc: 0.7500\n",
      "Epoch 257/1000\n",
      "576/576 [==============================] - 0s 101us/step - loss: 0.4398 - acc: 0.7726 - val_loss: 0.5149 - val_acc: 0.7552\n",
      "Epoch 258/1000\n",
      "576/576 [==============================] - 0s 110us/step - loss: 0.4398 - acc: 0.7743 - val_loss: 0.5149 - val_acc: 0.7552\n",
      "Epoch 259/1000\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.4397 - acc: 0.7726 - val_loss: 0.5149 - val_acc: 0.7552\n",
      "Epoch 260/1000\n",
      "576/576 [==============================] - 0s 83us/step - loss: 0.4396 - acc: 0.7743 - val_loss: 0.5149 - val_acc: 0.7604\n",
      "Epoch 261/1000\n",
      "576/576 [==============================] - 0s 112us/step - loss: 0.4396 - acc: 0.7743 - val_loss: 0.5150 - val_acc: 0.7604\n",
      "Epoch 262/1000\n",
      "576/576 [==============================] - 0s 120us/step - loss: 0.4396 - acc: 0.7726 - val_loss: 0.5150 - val_acc: 0.7604\n",
      "Epoch 263/1000\n",
      "576/576 [==============================] - 0s 155us/step - loss: 0.4395 - acc: 0.7743 - val_loss: 0.5150 - val_acc: 0.7604\n",
      "Epoch 264/1000\n",
      "576/576 [==============================] - 0s 119us/step - loss: 0.4395 - acc: 0.7743 - val_loss: 0.5150 - val_acc: 0.7604\n",
      "Epoch 265/1000\n",
      "576/576 [==============================] - 0s 119us/step - loss: 0.4394 - acc: 0.7743 - val_loss: 0.5150 - val_acc: 0.7604\n",
      "Epoch 266/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4394 - acc: 0.7743 - val_loss: 0.5150 - val_acc: 0.7604\n",
      "Epoch 267/1000\n",
      "576/576 [==============================] - 0s 91us/step - loss: 0.4393 - acc: 0.7743 - val_loss: 0.5150 - val_acc: 0.7604\n",
      "Epoch 268/1000\n",
      "576/576 [==============================] - 0s 73us/step - loss: 0.4393 - acc: 0.7726 - val_loss: 0.5151 - val_acc: 0.7604\n",
      "Epoch 269/1000\n",
      "576/576 [==============================] - 0s 117us/step - loss: 0.4392 - acc: 0.7708 - val_loss: 0.5151 - val_acc: 0.7604\n",
      "Epoch 270/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4392 - acc: 0.7726 - val_loss: 0.5151 - val_acc: 0.7604\n",
      "Epoch 271/1000\n",
      "576/576 [==============================] - 0s 87us/step - loss: 0.4392 - acc: 0.7743 - val_loss: 0.5151 - val_acc: 0.7604\n",
      "Epoch 272/1000\n",
      "576/576 [==============================] - 0s 92us/step - loss: 0.4391 - acc: 0.7743 - val_loss: 0.5151 - val_acc: 0.7604\n",
      "Epoch 273/1000\n",
      "576/576 [==============================] - 0s 111us/step - loss: 0.4391 - acc: 0.7726 - val_loss: 0.5151 - val_acc: 0.7604\n",
      "Epoch 274/1000\n",
      "576/576 [==============================] - 0s 114us/step - loss: 0.4390 - acc: 0.7726 - val_loss: 0.5152 - val_acc: 0.7604\n",
      "Epoch 275/1000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.4390 - acc: 0.7726 - val_loss: 0.5152 - val_acc: 0.7604\n",
      "Epoch 276/1000\n",
      "576/576 [==============================] - 0s 82us/step - loss: 0.4389 - acc: 0.7726 - val_loss: 0.5152 - val_acc: 0.7604\n",
      "Epoch 277/1000\n",
      "576/576 [==============================] - 0s 63us/step - loss: 0.4389 - acc: 0.7726 - val_loss: 0.5152 - val_acc: 0.7604\n",
      "Epoch 278/1000\n",
      "576/576 [==============================] - 0s 98us/step - loss: 0.4389 - acc: 0.7726 - val_loss: 0.5152 - val_acc: 0.7604\n",
      "Epoch 279/1000\n",
      "576/576 [==============================] - 0s 107us/step - loss: 0.4388 - acc: 0.7726 - val_loss: 0.5152 - val_acc: 0.7604\n",
      "Epoch 280/1000\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4388 - acc: 0.7726 - val_loss: 0.5153 - val_acc: 0.7604\n",
      "Epoch 281/1000\n",
      "576/576 [==============================] - 0s 124us/step - loss: 0.4387 - acc: 0.7708 - val_loss: 0.5153 - val_acc: 0.7604\n",
      "Epoch 282/1000\n",
      "576/576 [==============================] - 0s 92us/step - loss: 0.4387 - acc: 0.7726 - val_loss: 0.5153 - val_acc: 0.7604\n",
      "Epoch 283/1000\n",
      "576/576 [==============================] - 0s 115us/step - loss: 0.4387 - acc: 0.7708 - val_loss: 0.5153 - val_acc: 0.7604\n",
      "Epoch 284/1000\n",
      "576/576 [==============================] - 0s 86us/step - loss: 0.4386 - acc: 0.7726 - val_loss: 0.5153 - val_acc: 0.7604\n",
      "Epoch 285/1000\n",
      "576/576 [==============================] - 0s 84us/step - loss: 0.4386 - acc: 0.7726 - val_loss: 0.5153 - val_acc: 0.7604\n",
      "Epoch 286/1000\n",
      "576/576 [==============================] - 0s 84us/step - loss: 0.4385 - acc: 0.7743 - val_loss: 0.5154 - val_acc: 0.7604\n",
      "Epoch 287/1000\n",
      "576/576 [==============================] - 0s 104us/step - loss: 0.4385 - acc: 0.7743 - val_loss: 0.5154 - val_acc: 0.7604\n",
      "Epoch 288/1000\n",
      "576/576 [==============================] - 0s 125us/step - loss: 0.4385 - acc: 0.7708 - val_loss: 0.5154 - val_acc: 0.7604\n",
      "Epoch 289/1000\n",
      "576/576 [==============================] - 0s 89us/step - loss: 0.4384 - acc: 0.7743 - val_loss: 0.5154 - val_acc: 0.7604\n",
      "Epoch 290/1000\n",
      "576/576 [==============================] - 0s 110us/step - loss: 0.4384 - acc: 0.7743 - val_loss: 0.5154 - val_acc: 0.7604\n",
      "Epoch 291/1000\n",
      "576/576 [==============================] - 0s 86us/step - loss: 0.4383 - acc: 0.7760 - val_loss: 0.5154 - val_acc: 0.7604\n",
      "Epoch 292/1000\n",
      "576/576 [==============================] - 0s 106us/step - loss: 0.4383 - acc: 0.7726 - val_loss: 0.5154 - val_acc: 0.7604\n",
      "Epoch 293/1000\n",
      "576/576 [==============================] - 0s 86us/step - loss: 0.4383 - acc: 0.7743 - val_loss: 0.5155 - val_acc: 0.7604\n",
      "Epoch 294/1000\n",
      "576/576 [==============================] - 0s 94us/step - loss: 0.4382 - acc: 0.7760 - val_loss: 0.5155 - val_acc: 0.7604\n",
      "Epoch 295/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4382 - acc: 0.7743 - val_loss: 0.5155 - val_acc: 0.7604\n",
      "Epoch 296/1000\n",
      "576/576 [==============================] - 0s 95us/step - loss: 0.4381 - acc: 0.7760 - val_loss: 0.5155 - val_acc: 0.7604\n",
      "Epoch 297/1000\n",
      "576/576 [==============================] - 0s 65us/step - loss: 0.4381 - acc: 0.7760 - val_loss: 0.5155 - val_acc: 0.7604\n",
      "Epoch 298/1000\n",
      "576/576 [==============================] - 0s 110us/step - loss: 0.4380 - acc: 0.7760 - val_loss: 0.5155 - val_acc: 0.7604\n",
      "Epoch 299/1000\n",
      "576/576 [==============================] - 0s 126us/step - loss: 0.4380 - acc: 0.7760 - val_loss: 0.5156 - val_acc: 0.7604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300/1000\n",
      "576/576 [==============================] - 0s 98us/step - loss: 0.4380 - acc: 0.7760 - val_loss: 0.5156 - val_acc: 0.7604\n",
      "Epoch 301/1000\n",
      "576/576 [==============================] - 0s 111us/step - loss: 0.4379 - acc: 0.7743 - val_loss: 0.5156 - val_acc: 0.7604\n",
      "Epoch 302/1000\n",
      "576/576 [==============================] - 0s 100us/step - loss: 0.4379 - acc: 0.7760 - val_loss: 0.5156 - val_acc: 0.7604\n",
      "Epoch 303/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4378 - acc: 0.7760 - val_loss: 0.5156 - val_acc: 0.7604\n",
      "Epoch 304/1000\n",
      "576/576 [==============================] - 0s 109us/step - loss: 0.4378 - acc: 0.7743 - val_loss: 0.5156 - val_acc: 0.7604\n",
      "Epoch 305/1000\n",
      "576/576 [==============================] - 0s 62us/step - loss: 0.4378 - acc: 0.7760 - val_loss: 0.5157 - val_acc: 0.7604\n",
      "Epoch 306/1000\n",
      "576/576 [==============================] - 0s 92us/step - loss: 0.4377 - acc: 0.7760 - val_loss: 0.5157 - val_acc: 0.7604\n",
      "Epoch 307/1000\n",
      "576/576 [==============================] - 0s 84us/step - loss: 0.4377 - acc: 0.7760 - val_loss: 0.5157 - val_acc: 0.7604\n",
      "Epoch 308/1000\n",
      "576/576 [==============================] - 0s 104us/step - loss: 0.4377 - acc: 0.7778 - val_loss: 0.5157 - val_acc: 0.7604\n",
      "Epoch 309/1000\n",
      "576/576 [==============================] - 0s 109us/step - loss: 0.4376 - acc: 0.7760 - val_loss: 0.5157 - val_acc: 0.7604\n",
      "Epoch 310/1000\n",
      "576/576 [==============================] - 0s 100us/step - loss: 0.4376 - acc: 0.7778 - val_loss: 0.5157 - val_acc: 0.7604\n",
      "Epoch 311/1000\n",
      "576/576 [==============================] - 0s 86us/step - loss: 0.4375 - acc: 0.7778 - val_loss: 0.5157 - val_acc: 0.7604\n",
      "Epoch 312/1000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.4375 - acc: 0.7778 - val_loss: 0.5158 - val_acc: 0.7604\n",
      "Epoch 313/1000\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.4374 - acc: 0.7778 - val_loss: 0.5158 - val_acc: 0.7604\n",
      "Epoch 314/1000\n",
      "576/576 [==============================] - 0s 103us/step - loss: 0.4374 - acc: 0.7778 - val_loss: 0.5158 - val_acc: 0.7604\n",
      "Epoch 315/1000\n",
      "576/576 [==============================] - 0s 109us/step - loss: 0.4374 - acc: 0.7778 - val_loss: 0.5158 - val_acc: 0.7604\n",
      "Epoch 316/1000\n",
      "576/576 [==============================] - 0s 84us/step - loss: 0.4373 - acc: 0.7778 - val_loss: 0.5158 - val_acc: 0.7604\n",
      "Epoch 317/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.4373 - acc: 0.7778 - val_loss: 0.5158 - val_acc: 0.7604\n",
      "Epoch 318/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4372 - acc: 0.7778 - val_loss: 0.5159 - val_acc: 0.7604\n",
      "Epoch 319/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4372 - acc: 0.7778 - val_loss: 0.5159 - val_acc: 0.7604\n",
      "Epoch 320/1000\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4371 - acc: 0.7778 - val_loss: 0.5159 - val_acc: 0.7604\n",
      "Epoch 321/1000\n",
      "576/576 [==============================] - 0s 92us/step - loss: 0.4371 - acc: 0.7760 - val_loss: 0.5159 - val_acc: 0.7604\n",
      "Epoch 322/1000\n",
      "576/576 [==============================] - 0s 87us/step - loss: 0.4371 - acc: 0.7778 - val_loss: 0.5159 - val_acc: 0.7604\n",
      "Epoch 323/1000\n",
      "576/576 [==============================] - 0s 89us/step - loss: 0.4370 - acc: 0.7778 - val_loss: 0.5159 - val_acc: 0.7604\n",
      "Epoch 324/1000\n",
      "576/576 [==============================] - 0s 101us/step - loss: 0.4370 - acc: 0.7778 - val_loss: 0.5160 - val_acc: 0.7604\n",
      "Epoch 325/1000\n",
      "576/576 [==============================] - 0s 90us/step - loss: 0.4369 - acc: 0.7778 - val_loss: 0.5160 - val_acc: 0.7604\n",
      "Epoch 326/1000\n",
      "576/576 [==============================] - 0s 109us/step - loss: 0.4369 - acc: 0.7778 - val_loss: 0.5160 - val_acc: 0.7604\n",
      "Epoch 327/1000\n",
      "576/576 [==============================] - 0s 94us/step - loss: 0.4368 - acc: 0.7778 - val_loss: 0.5160 - val_acc: 0.7604\n",
      "Epoch 328/1000\n",
      "576/576 [==============================] - 0s 117us/step - loss: 0.4368 - acc: 0.7778 - val_loss: 0.5160 - val_acc: 0.7604\n",
      "Epoch 329/1000\n",
      "576/576 [==============================] - 0s 105us/step - loss: 0.4368 - acc: 0.7778 - val_loss: 0.5161 - val_acc: 0.7604\n",
      "Epoch 330/1000\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.4367 - acc: 0.7760 - val_loss: 0.5161 - val_acc: 0.7604\n",
      "Epoch 331/1000\n",
      "576/576 [==============================] - 0s 72us/step - loss: 0.4367 - acc: 0.7778 - val_loss: 0.5161 - val_acc: 0.7604\n",
      "Epoch 332/1000\n",
      "576/576 [==============================] - 0s 85us/step - loss: 0.4367 - acc: 0.7778 - val_loss: 0.5161 - val_acc: 0.7604\n",
      "Epoch 333/1000\n",
      "576/576 [==============================] - 0s 73us/step - loss: 0.4366 - acc: 0.7778 - val_loss: 0.5161 - val_acc: 0.7604\n",
      "Epoch 334/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4366 - acc: 0.7778 - val_loss: 0.5161 - val_acc: 0.7552\n",
      "Epoch 335/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4365 - acc: 0.7760 - val_loss: 0.5162 - val_acc: 0.7552\n",
      "Epoch 336/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4365 - acc: 0.7778 - val_loss: 0.5162 - val_acc: 0.7552\n",
      "Epoch 337/1000\n",
      "576/576 [==============================] - 0s 111us/step - loss: 0.4365 - acc: 0.7778 - val_loss: 0.5162 - val_acc: 0.7552\n",
      "Epoch 338/1000\n",
      "576/576 [==============================] - 0s 91us/step - loss: 0.4364 - acc: 0.7778 - val_loss: 0.5162 - val_acc: 0.7552\n",
      "Epoch 339/1000\n",
      "576/576 [==============================] - 0s 104us/step - loss: 0.4364 - acc: 0.7778 - val_loss: 0.5162 - val_acc: 0.7552\n",
      "Epoch 340/1000\n",
      "576/576 [==============================] - 0s 119us/step - loss: 0.4363 - acc: 0.7795 - val_loss: 0.5162 - val_acc: 0.7552\n",
      "Epoch 341/1000\n",
      "576/576 [==============================] - 0s 103us/step - loss: 0.4363 - acc: 0.7778 - val_loss: 0.5163 - val_acc: 0.7552\n",
      "Epoch 342/1000\n",
      "576/576 [==============================] - 0s 82us/step - loss: 0.4363 - acc: 0.7795 - val_loss: 0.5163 - val_acc: 0.7552\n",
      "Epoch 343/1000\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.4362 - acc: 0.7795 - val_loss: 0.5163 - val_acc: 0.7552\n",
      "Epoch 344/1000\n",
      "576/576 [==============================] - 0s 84us/step - loss: 0.4362 - acc: 0.7795 - val_loss: 0.5163 - val_acc: 0.7552\n",
      "Epoch 345/1000\n",
      "576/576 [==============================] - 0s 67us/step - loss: 0.4361 - acc: 0.7795 - val_loss: 0.5163 - val_acc: 0.7552\n",
      "Epoch 346/1000\n",
      "576/576 [==============================] - 0s 82us/step - loss: 0.4361 - acc: 0.7778 - val_loss: 0.5163 - val_acc: 0.7552\n",
      "Epoch 347/1000\n",
      "576/576 [==============================] - 0s 68us/step - loss: 0.4361 - acc: 0.7795 - val_loss: 0.5163 - val_acc: 0.7552\n",
      "Epoch 348/1000\n",
      "576/576 [==============================] - 0s 66us/step - loss: 0.4360 - acc: 0.7795 - val_loss: 0.5164 - val_acc: 0.7552\n",
      "Epoch 349/1000\n",
      "576/576 [==============================] - 0s 74us/step - loss: 0.4360 - acc: 0.7795 - val_loss: 0.5164 - val_acc: 0.7552\n",
      "Epoch 350/1000\n",
      "576/576 [==============================] - 0s 72us/step - loss: 0.4360 - acc: 0.7795 - val_loss: 0.5164 - val_acc: 0.7552\n",
      "Epoch 351/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4359 - acc: 0.7795 - val_loss: 0.5164 - val_acc: 0.7552\n",
      "Epoch 352/1000\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.4359 - acc: 0.7795 - val_loss: 0.5164 - val_acc: 0.7552\n",
      "Epoch 353/1000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.4358 - acc: 0.7795 - val_loss: 0.5164 - val_acc: 0.7552\n",
      "Epoch 354/1000\n",
      "576/576 [==============================] - 0s 91us/step - loss: 0.4358 - acc: 0.7795 - val_loss: 0.5164 - val_acc: 0.7500\n",
      "Epoch 355/1000\n",
      "576/576 [==============================] - 0s 120us/step - loss: 0.4358 - acc: 0.7795 - val_loss: 0.5164 - val_acc: 0.7500\n",
      "Epoch 356/1000\n",
      "576/576 [==============================] - 0s 84us/step - loss: 0.4357 - acc: 0.7795 - val_loss: 0.5164 - val_acc: 0.7500\n",
      "Epoch 357/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4357 - acc: 0.7795 - val_loss: 0.5165 - val_acc: 0.7500\n",
      "Epoch 358/1000\n",
      "576/576 [==============================] - 0s 67us/step - loss: 0.4357 - acc: 0.7795 - val_loss: 0.5165 - val_acc: 0.7500\n",
      "Epoch 359/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 92us/step - loss: 0.4356 - acc: 0.7795 - val_loss: 0.5165 - val_acc: 0.7500\n",
      "Epoch 360/1000\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.4356 - acc: 0.7778 - val_loss: 0.5165 - val_acc: 0.7500\n",
      "Epoch 361/1000\n",
      "576/576 [==============================] - 0s 53us/step - loss: 0.4356 - acc: 0.7778 - val_loss: 0.5165 - val_acc: 0.7500\n",
      "Epoch 362/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4355 - acc: 0.7795 - val_loss: 0.5165 - val_acc: 0.7500\n",
      "Epoch 363/1000\n",
      "576/576 [==============================] - 0s 64us/step - loss: 0.4355 - acc: 0.7795 - val_loss: 0.5165 - val_acc: 0.7500\n",
      "Epoch 364/1000\n",
      "576/576 [==============================] - 0s 69us/step - loss: 0.4354 - acc: 0.7795 - val_loss: 0.5165 - val_acc: 0.7500\n",
      "Epoch 365/1000\n",
      "576/576 [==============================] - 0s 72us/step - loss: 0.4354 - acc: 0.7795 - val_loss: 0.5165 - val_acc: 0.7500\n",
      "Epoch 366/1000\n",
      "576/576 [==============================] - 0s 67us/step - loss: 0.4354 - acc: 0.7795 - val_loss: 0.5165 - val_acc: 0.7500\n",
      "Epoch 367/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4353 - acc: 0.7795 - val_loss: 0.5165 - val_acc: 0.7500\n",
      "Epoch 368/1000\n",
      "576/576 [==============================] - 0s 72us/step - loss: 0.4353 - acc: 0.7795 - val_loss: 0.5165 - val_acc: 0.7500\n",
      "Epoch 369/1000\n",
      "576/576 [==============================] - 0s 74us/step - loss: 0.4352 - acc: 0.7795 - val_loss: 0.5165 - val_acc: 0.7500\n",
      "Epoch 370/1000\n",
      "576/576 [==============================] - 0s 98us/step - loss: 0.4352 - acc: 0.7795 - val_loss: 0.5166 - val_acc: 0.7500\n",
      "Epoch 371/1000\n",
      "576/576 [==============================] - 0s 94us/step - loss: 0.4352 - acc: 0.7795 - val_loss: 0.5166 - val_acc: 0.7500\n",
      "Epoch 372/1000\n",
      "576/576 [==============================] - 0s 98us/step - loss: 0.4352 - acc: 0.7778 - val_loss: 0.5166 - val_acc: 0.7500\n",
      "Epoch 373/1000\n",
      "576/576 [==============================] - 0s 107us/step - loss: 0.4351 - acc: 0.7778 - val_loss: 0.5166 - val_acc: 0.7500\n",
      "Epoch 374/1000\n",
      "576/576 [==============================] - 0s 103us/step - loss: 0.4351 - acc: 0.7795 - val_loss: 0.5166 - val_acc: 0.7500\n",
      "Epoch 375/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4350 - acc: 0.7795 - val_loss: 0.5166 - val_acc: 0.7500\n",
      "Epoch 376/1000\n",
      "576/576 [==============================] - 0s 109us/step - loss: 0.4350 - acc: 0.7778 - val_loss: 0.5166 - val_acc: 0.7500\n",
      "Epoch 377/1000\n",
      "576/576 [==============================] - 0s 83us/step - loss: 0.4350 - acc: 0.7795 - val_loss: 0.5166 - val_acc: 0.7500\n",
      "Epoch 378/1000\n",
      "576/576 [==============================] - 0s 102us/step - loss: 0.4349 - acc: 0.7778 - val_loss: 0.5166 - val_acc: 0.7500\n",
      "Epoch 379/1000\n",
      "576/576 [==============================] - 0s 63us/step - loss: 0.4349 - acc: 0.7778 - val_loss: 0.5166 - val_acc: 0.7500\n",
      "Epoch 380/1000\n",
      "576/576 [==============================] - 0s 83us/step - loss: 0.4349 - acc: 0.7795 - val_loss: 0.5166 - val_acc: 0.7500\n",
      "Epoch 381/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4349 - acc: 0.7795 - val_loss: 0.5166 - val_acc: 0.7500\n",
      "Epoch 382/1000\n",
      "576/576 [==============================] - 0s 69us/step - loss: 0.4348 - acc: 0.7795 - val_loss: 0.5166 - val_acc: 0.7500\n",
      "Epoch 383/1000\n",
      "576/576 [==============================] - 0s 92us/step - loss: 0.4348 - acc: 0.7778 - val_loss: 0.5166 - val_acc: 0.7500\n",
      "Epoch 384/1000\n",
      "576/576 [==============================] - 0s 103us/step - loss: 0.4347 - acc: 0.7795 - val_loss: 0.5166 - val_acc: 0.7500\n",
      "Epoch 385/1000\n",
      "576/576 [==============================] - 0s 101us/step - loss: 0.4347 - acc: 0.7778 - val_loss: 0.5166 - val_acc: 0.7500\n",
      "Epoch 386/1000\n",
      "576/576 [==============================] - 0s 95us/step - loss: 0.4347 - acc: 0.7778 - val_loss: 0.5166 - val_acc: 0.7500\n",
      "Epoch 387/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4347 - acc: 0.7778 - val_loss: 0.5166 - val_acc: 0.7500\n",
      "Epoch 388/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4346 - acc: 0.7795 - val_loss: 0.5167 - val_acc: 0.7500\n",
      "Epoch 389/1000\n",
      "576/576 [==============================] - 0s 62us/step - loss: 0.4346 - acc: 0.7795 - val_loss: 0.5166 - val_acc: 0.7500\n",
      "Epoch 390/1000\n",
      "576/576 [==============================] - 0s 64us/step - loss: 0.4346 - acc: 0.7778 - val_loss: 0.5166 - val_acc: 0.7500\n",
      "Epoch 391/1000\n",
      "576/576 [==============================] - 0s 92us/step - loss: 0.4345 - acc: 0.7795 - val_loss: 0.5167 - val_acc: 0.7500\n",
      "Epoch 392/1000\n",
      "576/576 [==============================] - 0s 64us/step - loss: 0.4345 - acc: 0.7795 - val_loss: 0.5167 - val_acc: 0.7500\n",
      "Epoch 393/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.4345 - acc: 0.7778 - val_loss: 0.5167 - val_acc: 0.7500\n",
      "Epoch 394/1000\n",
      "576/576 [==============================] - 0s 85us/step - loss: 0.4344 - acc: 0.7778 - val_loss: 0.5166 - val_acc: 0.7500\n",
      "Epoch 395/1000\n",
      "576/576 [==============================] - 0s 115us/step - loss: 0.4344 - acc: 0.7795 - val_loss: 0.5166 - val_acc: 0.7500\n",
      "Epoch 396/1000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.4344 - acc: 0.7812 - val_loss: 0.5167 - val_acc: 0.7500\n",
      "Epoch 397/1000\n",
      "576/576 [==============================] - 0s 106us/step - loss: 0.4343 - acc: 0.7795 - val_loss: 0.5166 - val_acc: 0.7500\n",
      "Epoch 398/1000\n",
      "576/576 [==============================] - 0s 112us/step - loss: 0.4343 - acc: 0.7778 - val_loss: 0.5166 - val_acc: 0.7500\n",
      "Epoch 399/1000\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.4343 - acc: 0.7778 - val_loss: 0.5166 - val_acc: 0.7500\n",
      "Epoch 400/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4342 - acc: 0.7795 - val_loss: 0.5166 - val_acc: 0.7500\n",
      "Epoch 401/1000\n",
      "576/576 [==============================] - 0s 91us/step - loss: 0.4342 - acc: 0.7795 - val_loss: 0.5167 - val_acc: 0.7500\n",
      "Epoch 402/1000\n",
      "576/576 [==============================] - 0s 84us/step - loss: 0.4342 - acc: 0.7795 - val_loss: 0.5166 - val_acc: 0.7500\n",
      "Epoch 403/1000\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.4342 - acc: 0.7795 - val_loss: 0.5166 - val_acc: 0.7500\n",
      "Epoch 404/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4341 - acc: 0.7812 - val_loss: 0.5166 - val_acc: 0.7500\n",
      "Epoch 405/1000\n",
      "576/576 [==============================] - 0s 84us/step - loss: 0.4341 - acc: 0.7812 - val_loss: 0.5166 - val_acc: 0.7500\n",
      "Epoch 406/1000\n",
      "576/576 [==============================] - 0s 102us/step - loss: 0.4341 - acc: 0.7812 - val_loss: 0.5166 - val_acc: 0.7500\n",
      "Epoch 407/1000\n",
      "576/576 [==============================] - 0s 89us/step - loss: 0.4340 - acc: 0.7830 - val_loss: 0.5166 - val_acc: 0.7500\n",
      "Epoch 408/1000\n",
      "576/576 [==============================] - 0s 103us/step - loss: 0.4340 - acc: 0.7830 - val_loss: 0.5166 - val_acc: 0.7500\n",
      "Epoch 409/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4340 - acc: 0.7830 - val_loss: 0.5166 - val_acc: 0.7500\n",
      "Epoch 410/1000\n",
      "576/576 [==============================] - 0s 88us/step - loss: 0.4339 - acc: 0.7830 - val_loss: 0.5166 - val_acc: 0.7500\n",
      "Epoch 411/1000\n",
      "576/576 [==============================] - 0s 70us/step - loss: 0.4339 - acc: 0.7830 - val_loss: 0.5166 - val_acc: 0.7500\n",
      "Epoch 412/1000\n",
      "576/576 [==============================] - 0s 85us/step - loss: 0.4339 - acc: 0.7830 - val_loss: 0.5166 - val_acc: 0.7500\n",
      "Epoch 413/1000\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.4339 - acc: 0.7830 - val_loss: 0.5166 - val_acc: 0.7500\n",
      "Epoch 414/1000\n",
      "576/576 [==============================] - 0s 65us/step - loss: 0.4338 - acc: 0.7830 - val_loss: 0.5166 - val_acc: 0.7500\n",
      "Epoch 415/1000\n",
      "576/576 [==============================] - 0s 74us/step - loss: 0.4338 - acc: 0.7830 - val_loss: 0.5166 - val_acc: 0.7500\n",
      "Epoch 416/1000\n",
      "576/576 [==============================] - 0s 66us/step - loss: 0.4338 - acc: 0.7830 - val_loss: 0.5166 - val_acc: 0.7500\n",
      "Epoch 417/1000\n",
      "576/576 [==============================] - 0s 85us/step - loss: 0.4337 - acc: 0.7830 - val_loss: 0.5166 - val_acc: 0.7500\n",
      "Epoch 418/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4337 - acc: 0.7830 - val_loss: 0.5166 - val_acc: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 419/1000\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.4337 - acc: 0.7830 - val_loss: 0.5166 - val_acc: 0.7500\n",
      "Epoch 420/1000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.4336 - acc: 0.7830 - val_loss: 0.5166 - val_acc: 0.7500\n",
      "Epoch 421/1000\n",
      "576/576 [==============================] - 0s 117us/step - loss: 0.4336 - acc: 0.7830 - val_loss: 0.5166 - val_acc: 0.7500\n",
      "Epoch 422/1000\n",
      "576/576 [==============================] - 0s 121us/step - loss: 0.4336 - acc: 0.7812 - val_loss: 0.5166 - val_acc: 0.7500\n",
      "Epoch 423/1000\n",
      "576/576 [==============================] - 0s 89us/step - loss: 0.4336 - acc: 0.7812 - val_loss: 0.5166 - val_acc: 0.7500\n",
      "Epoch 424/1000\n",
      "576/576 [==============================] - 0s 84us/step - loss: 0.4335 - acc: 0.7830 - val_loss: 0.5166 - val_acc: 0.7500\n",
      "Epoch 425/1000\n",
      "576/576 [==============================] - 0s 65us/step - loss: 0.4335 - acc: 0.7830 - val_loss: 0.5166 - val_acc: 0.7500\n",
      "Epoch 426/1000\n",
      "576/576 [==============================] - 0s 84us/step - loss: 0.4334 - acc: 0.7830 - val_loss: 0.5166 - val_acc: 0.7500\n",
      "Epoch 427/1000\n",
      "576/576 [==============================] - 0s 63us/step - loss: 0.4334 - acc: 0.7830 - val_loss: 0.5166 - val_acc: 0.7500\n",
      "Epoch 428/1000\n",
      "576/576 [==============================] - 0s 66us/step - loss: 0.4334 - acc: 0.7830 - val_loss: 0.5166 - val_acc: 0.7500\n",
      "Epoch 429/1000\n",
      "576/576 [==============================] - 0s 69us/step - loss: 0.4334 - acc: 0.7830 - val_loss: 0.5166 - val_acc: 0.7500\n",
      "Epoch 430/1000\n",
      "576/576 [==============================] - 0s 67us/step - loss: 0.4333 - acc: 0.7830 - val_loss: 0.5167 - val_acc: 0.7500\n",
      "Epoch 431/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4333 - acc: 0.7830 - val_loss: 0.5167 - val_acc: 0.7500\n",
      "Epoch 432/1000\n",
      "576/576 [==============================] - 0s 70us/step - loss: 0.4333 - acc: 0.7830 - val_loss: 0.5167 - val_acc: 0.7500\n",
      "Epoch 433/1000\n",
      "576/576 [==============================] - 0s 83us/step - loss: 0.4333 - acc: 0.7830 - val_loss: 0.5167 - val_acc: 0.7500\n",
      "Epoch 434/1000\n",
      "576/576 [==============================] - 0s 106us/step - loss: 0.4332 - acc: 0.7847 - val_loss: 0.5167 - val_acc: 0.7500\n",
      "Epoch 435/1000\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4332 - acc: 0.7847 - val_loss: 0.5167 - val_acc: 0.7500\n",
      "Epoch 436/1000\n",
      "576/576 [==============================] - 0s 167us/step - loss: 0.4332 - acc: 0.7812 - val_loss: 0.5167 - val_acc: 0.7500\n",
      "Epoch 437/1000\n",
      "576/576 [==============================] - 0s 84us/step - loss: 0.4331 - acc: 0.7847 - val_loss: 0.5167 - val_acc: 0.7500\n",
      "Epoch 438/1000\n",
      "576/576 [==============================] - 0s 95us/step - loss: 0.4331 - acc: 0.7830 - val_loss: 0.5167 - val_acc: 0.7500\n",
      "Epoch 439/1000\n",
      "576/576 [==============================] - 0s 70us/step - loss: 0.4331 - acc: 0.7847 - val_loss: 0.5167 - val_acc: 0.7500\n",
      "Epoch 440/1000\n",
      "576/576 [==============================] - 0s 87us/step - loss: 0.4331 - acc: 0.7830 - val_loss: 0.5167 - val_acc: 0.7500\n",
      "Epoch 441/1000\n",
      "576/576 [==============================] - 0s 84us/step - loss: 0.4330 - acc: 0.7847 - val_loss: 0.5167 - val_acc: 0.7500\n",
      "Epoch 442/1000\n",
      "576/576 [==============================] - 0s 95us/step - loss: 0.4330 - acc: 0.7847 - val_loss: 0.5167 - val_acc: 0.7500\n",
      "Epoch 443/1000\n",
      "576/576 [==============================] - 0s 86us/step - loss: 0.4329 - acc: 0.7847 - val_loss: 0.5167 - val_acc: 0.7500\n",
      "Epoch 444/1000\n",
      "576/576 [==============================] - 0s 115us/step - loss: 0.4329 - acc: 0.7830 - val_loss: 0.5167 - val_acc: 0.7500\n",
      "Epoch 445/1000\n",
      "576/576 [==============================] - 0s 94us/step - loss: 0.4329 - acc: 0.7830 - val_loss: 0.5167 - val_acc: 0.7500\n",
      "Epoch 446/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4329 - acc: 0.7830 - val_loss: 0.5167 - val_acc: 0.7500\n",
      "Epoch 447/1000\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.4328 - acc: 0.7830 - val_loss: 0.5167 - val_acc: 0.7500\n",
      "Epoch 448/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4328 - acc: 0.7830 - val_loss: 0.5167 - val_acc: 0.7500\n",
      "Epoch 449/1000\n",
      "576/576 [==============================] - 0s 62us/step - loss: 0.4328 - acc: 0.7830 - val_loss: 0.5167 - val_acc: 0.7500\n",
      "Epoch 450/1000\n",
      "576/576 [==============================] - 0s 72us/step - loss: 0.4327 - acc: 0.7830 - val_loss: 0.5167 - val_acc: 0.7500\n",
      "Epoch 451/1000\n",
      "576/576 [==============================] - 0s 70us/step - loss: 0.4327 - acc: 0.7830 - val_loss: 0.5167 - val_acc: 0.7500\n",
      "Epoch 452/1000\n",
      "576/576 [==============================] - 0s 70us/step - loss: 0.4327 - acc: 0.7830 - val_loss: 0.5167 - val_acc: 0.7500\n",
      "Epoch 453/1000\n",
      "576/576 [==============================] - 0s 72us/step - loss: 0.4327 - acc: 0.7830 - val_loss: 0.5167 - val_acc: 0.7500\n",
      "Epoch 454/1000\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.4326 - acc: 0.7830 - val_loss: 0.5167 - val_acc: 0.7500\n",
      "Epoch 455/1000\n",
      "576/576 [==============================] - 0s 85us/step - loss: 0.4326 - acc: 0.7830 - val_loss: 0.5167 - val_acc: 0.7500\n",
      "Epoch 456/1000\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.4326 - acc: 0.7830 - val_loss: 0.5167 - val_acc: 0.7500\n",
      "Epoch 457/1000\n",
      "576/576 [==============================] - 0s 92us/step - loss: 0.4326 - acc: 0.7830 - val_loss: 0.5167 - val_acc: 0.7500\n",
      "Epoch 458/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.4325 - acc: 0.7830 - val_loss: 0.5167 - val_acc: 0.7500\n",
      "Epoch 459/1000\n",
      "576/576 [==============================] - 0s 127us/step - loss: 0.4325 - acc: 0.7830 - val_loss: 0.5167 - val_acc: 0.7500\n",
      "Epoch 460/1000\n",
      "576/576 [==============================] - 0s 109us/step - loss: 0.4325 - acc: 0.7830 - val_loss: 0.5167 - val_acc: 0.7500\n",
      "Epoch 461/1000\n",
      "576/576 [==============================] - 0s 101us/step - loss: 0.4324 - acc: 0.7830 - val_loss: 0.5167 - val_acc: 0.7500\n",
      "Epoch 462/1000\n",
      "576/576 [==============================] - 0s 102us/step - loss: 0.4324 - acc: 0.7830 - val_loss: 0.5167 - val_acc: 0.7500\n",
      "Epoch 463/1000\n",
      "576/576 [==============================] - 0s 87us/step - loss: 0.4324 - acc: 0.7830 - val_loss: 0.5167 - val_acc: 0.7500\n",
      "Epoch 464/1000\n",
      "576/576 [==============================] - 0s 91us/step - loss: 0.4324 - acc: 0.7830 - val_loss: 0.5167 - val_acc: 0.7500\n",
      "Epoch 465/1000\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.4323 - acc: 0.7830 - val_loss: 0.5167 - val_acc: 0.7500\n",
      "Epoch 466/1000\n",
      "576/576 [==============================] - 0s 82us/step - loss: 0.4323 - acc: 0.7830 - val_loss: 0.5167 - val_acc: 0.7500\n",
      "Epoch 467/1000\n",
      "576/576 [==============================] - 0s 67us/step - loss: 0.4323 - acc: 0.7830 - val_loss: 0.5167 - val_acc: 0.7500\n",
      "Epoch 468/1000\n",
      "576/576 [==============================] - 0s 72us/step - loss: 0.4322 - acc: 0.7847 - val_loss: 0.5167 - val_acc: 0.7500\n",
      "Epoch 469/1000\n",
      "576/576 [==============================] - 0s 98us/step - loss: 0.4322 - acc: 0.7830 - val_loss: 0.5167 - val_acc: 0.7500\n",
      "Epoch 470/1000\n",
      "576/576 [==============================] - 0s 100us/step - loss: 0.4322 - acc: 0.7847 - val_loss: 0.5167 - val_acc: 0.7552\n",
      "Epoch 471/1000\n",
      "576/576 [==============================] - 0s 95us/step - loss: 0.4322 - acc: 0.7847 - val_loss: 0.5167 - val_acc: 0.7552\n",
      "Epoch 472/1000\n",
      "576/576 [==============================] - 0s 123us/step - loss: 0.4321 - acc: 0.7847 - val_loss: 0.5167 - val_acc: 0.7552\n",
      "Epoch 473/1000\n",
      "576/576 [==============================] - 0s 88us/step - loss: 0.4321 - acc: 0.7847 - val_loss: 0.5167 - val_acc: 0.7552\n",
      "Epoch 474/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4321 - acc: 0.7847 - val_loss: 0.5167 - val_acc: 0.7552\n",
      "Epoch 475/1000\n",
      "576/576 [==============================] - 0s 91us/step - loss: 0.4320 - acc: 0.7847 - val_loss: 0.5167 - val_acc: 0.7552\n",
      "Epoch 476/1000\n",
      "576/576 [==============================] - 0s 94us/step - loss: 0.4320 - acc: 0.7847 - val_loss: 0.5167 - val_acc: 0.7552\n",
      "Epoch 477/1000\n",
      "576/576 [==============================] - 0s 67us/step - loss: 0.4320 - acc: 0.7847 - val_loss: 0.5167 - val_acc: 0.7552\n",
      "Epoch 478/1000\n",
      "576/576 [==============================] - 0s 128us/step - loss: 0.4320 - acc: 0.7847 - val_loss: 0.5168 - val_acc: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 479/1000\n",
      "576/576 [==============================] - 0s 105us/step - loss: 0.4319 - acc: 0.7847 - val_loss: 0.5168 - val_acc: 0.7552\n",
      "Epoch 480/1000\n",
      "576/576 [==============================] - 0s 101us/step - loss: 0.4319 - acc: 0.7847 - val_loss: 0.5168 - val_acc: 0.7552\n",
      "Epoch 481/1000\n",
      "576/576 [==============================] - 0s 120us/step - loss: 0.4319 - acc: 0.7865 - val_loss: 0.5168 - val_acc: 0.7552\n",
      "Epoch 482/1000\n",
      "576/576 [==============================] - 0s 88us/step - loss: 0.4318 - acc: 0.7865 - val_loss: 0.5168 - val_acc: 0.7552\n",
      "Epoch 483/1000\n",
      "576/576 [==============================] - 0s 98us/step - loss: 0.4318 - acc: 0.7865 - val_loss: 0.5168 - val_acc: 0.7552\n",
      "Epoch 484/1000\n",
      "576/576 [==============================] - 0s 67us/step - loss: 0.4318 - acc: 0.7865 - val_loss: 0.5168 - val_acc: 0.7552\n",
      "Epoch 485/1000\n",
      "576/576 [==============================] - 0s 113us/step - loss: 0.4317 - acc: 0.7865 - val_loss: 0.5168 - val_acc: 0.7552\n",
      "Epoch 486/1000\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.4317 - acc: 0.7865 - val_loss: 0.5168 - val_acc: 0.7552\n",
      "Epoch 487/1000\n",
      "576/576 [==============================] - 0s 94us/step - loss: 0.4317 - acc: 0.7865 - val_loss: 0.5168 - val_acc: 0.7552\n",
      "Epoch 488/1000\n",
      "576/576 [==============================] - 0s 143us/step - loss: 0.4317 - acc: 0.7865 - val_loss: 0.5168 - val_acc: 0.7552\n",
      "Epoch 489/1000\n",
      "576/576 [==============================] - 0s 119us/step - loss: 0.4316 - acc: 0.7865 - val_loss: 0.5168 - val_acc: 0.7552\n",
      "Epoch 490/1000\n",
      "576/576 [==============================] - 0s 106us/step - loss: 0.4316 - acc: 0.7865 - val_loss: 0.5168 - val_acc: 0.7552\n",
      "Epoch 491/1000\n",
      "576/576 [==============================] - 0s 109us/step - loss: 0.4316 - acc: 0.7865 - val_loss: 0.5168 - val_acc: 0.7552\n",
      "Epoch 492/1000\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4316 - acc: 0.7865 - val_loss: 0.5168 - val_acc: 0.7552\n",
      "Epoch 493/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4315 - acc: 0.7865 - val_loss: 0.5168 - val_acc: 0.7552\n",
      "Epoch 494/1000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.4315 - acc: 0.7865 - val_loss: 0.5168 - val_acc: 0.7552\n",
      "Epoch 495/1000\n",
      "576/576 [==============================] - 0s 62us/step - loss: 0.4315 - acc: 0.7865 - val_loss: 0.5168 - val_acc: 0.7552\n",
      "Epoch 496/1000\n",
      "576/576 [==============================] - 0s 89us/step - loss: 0.4314 - acc: 0.7865 - val_loss: 0.5168 - val_acc: 0.7552\n",
      "Epoch 497/1000\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.4314 - acc: 0.7865 - val_loss: 0.5168 - val_acc: 0.7552\n",
      "Epoch 498/1000\n",
      "576/576 [==============================] - 0s 68us/step - loss: 0.4314 - acc: 0.7865 - val_loss: 0.5168 - val_acc: 0.7552\n",
      "Epoch 499/1000\n",
      "576/576 [==============================] - 0s 83us/step - loss: 0.4314 - acc: 0.7865 - val_loss: 0.5168 - val_acc: 0.7552\n",
      "Epoch 500/1000\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.4314 - acc: 0.7865 - val_loss: 0.5168 - val_acc: 0.7552\n",
      "Epoch 501/1000\n",
      "576/576 [==============================] - 0s 73us/step - loss: 0.4313 - acc: 0.7865 - val_loss: 0.5168 - val_acc: 0.7552\n",
      "Epoch 502/1000\n",
      "576/576 [==============================] - 0s 68us/step - loss: 0.4313 - acc: 0.7865 - val_loss: 0.5168 - val_acc: 0.7552\n",
      "Epoch 503/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4313 - acc: 0.7865 - val_loss: 0.5168 - val_acc: 0.7552\n",
      "Epoch 504/1000\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.4312 - acc: 0.7865 - val_loss: 0.5168 - val_acc: 0.7552\n",
      "Epoch 505/1000\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.4312 - acc: 0.7865 - val_loss: 0.5169 - val_acc: 0.7552\n",
      "Epoch 506/1000\n",
      "576/576 [==============================] - 0s 87us/step - loss: 0.4312 - acc: 0.7865 - val_loss: 0.5169 - val_acc: 0.7552\n",
      "Epoch 507/1000\n",
      "576/576 [==============================] - 0s 65us/step - loss: 0.4311 - acc: 0.7865 - val_loss: 0.5169 - val_acc: 0.7552\n",
      "Epoch 508/1000\n",
      "576/576 [==============================] - 0s 95us/step - loss: 0.4311 - acc: 0.7865 - val_loss: 0.5169 - val_acc: 0.7552\n",
      "Epoch 509/1000\n",
      "576/576 [==============================] - 0s 90us/step - loss: 0.4311 - acc: 0.7865 - val_loss: 0.5169 - val_acc: 0.7552\n",
      "Epoch 510/1000\n",
      "576/576 [==============================] - 0s 157us/step - loss: 0.4311 - acc: 0.7865 - val_loss: 0.5169 - val_acc: 0.7552\n",
      "Epoch 511/1000\n",
      "576/576 [==============================] - 0s 120us/step - loss: 0.4310 - acc: 0.7865 - val_loss: 0.5169 - val_acc: 0.7552\n",
      "Epoch 512/1000\n",
      "576/576 [==============================] - 0s 115us/step - loss: 0.4310 - acc: 0.7865 - val_loss: 0.5169 - val_acc: 0.7552\n",
      "Epoch 513/1000\n",
      "576/576 [==============================] - 0s 94us/step - loss: 0.4310 - acc: 0.7865 - val_loss: 0.5169 - val_acc: 0.7552\n",
      "Epoch 514/1000\n",
      "576/576 [==============================] - 0s 101us/step - loss: 0.4310 - acc: 0.7865 - val_loss: 0.5169 - val_acc: 0.7552\n",
      "Epoch 515/1000\n",
      "576/576 [==============================] - 0s 91us/step - loss: 0.4309 - acc: 0.7865 - val_loss: 0.5170 - val_acc: 0.7552\n",
      "Epoch 516/1000\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.4309 - acc: 0.7865 - val_loss: 0.5170 - val_acc: 0.7552\n",
      "Epoch 517/1000\n",
      "576/576 [==============================] - 0s 100us/step - loss: 0.4309 - acc: 0.7865 - val_loss: 0.5170 - val_acc: 0.7552\n",
      "Epoch 518/1000\n",
      "576/576 [==============================] - 0s 112us/step - loss: 0.4308 - acc: 0.7865 - val_loss: 0.5170 - val_acc: 0.7552\n",
      "Epoch 519/1000\n",
      "576/576 [==============================] - 0s 100us/step - loss: 0.4308 - acc: 0.7865 - val_loss: 0.5170 - val_acc: 0.7552\n",
      "Epoch 520/1000\n",
      "576/576 [==============================] - 0s 68us/step - loss: 0.4308 - acc: 0.7865 - val_loss: 0.5170 - val_acc: 0.7552\n",
      "Epoch 521/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4307 - acc: 0.7865 - val_loss: 0.5170 - val_acc: 0.7552\n",
      "Epoch 522/1000\n",
      "576/576 [==============================] - 0s 89us/step - loss: 0.4307 - acc: 0.7865 - val_loss: 0.5170 - val_acc: 0.7552\n",
      "Epoch 523/1000\n",
      "576/576 [==============================] - 0s 101us/step - loss: 0.4307 - acc: 0.7865 - val_loss: 0.5170 - val_acc: 0.7552\n",
      "Epoch 524/1000\n",
      "576/576 [==============================] - 0s 110us/step - loss: 0.4307 - acc: 0.7865 - val_loss: 0.5170 - val_acc: 0.7552\n",
      "Epoch 525/1000\n",
      "576/576 [==============================] - 0s 105us/step - loss: 0.4306 - acc: 0.7865 - val_loss: 0.5170 - val_acc: 0.7552\n",
      "Epoch 526/1000\n",
      "576/576 [==============================] - 0s 92us/step - loss: 0.4306 - acc: 0.7865 - val_loss: 0.5170 - val_acc: 0.7552\n",
      "Epoch 527/1000\n",
      "576/576 [==============================] - 0s 117us/step - loss: 0.4306 - acc: 0.7865 - val_loss: 0.5170 - val_acc: 0.7552\n",
      "Epoch 528/1000\n",
      "576/576 [==============================] - 0s 106us/step - loss: 0.4305 - acc: 0.7865 - val_loss: 0.5171 - val_acc: 0.7552\n",
      "Epoch 529/1000\n",
      "576/576 [==============================] - 0s 67us/step - loss: 0.4305 - acc: 0.7865 - val_loss: 0.5171 - val_acc: 0.7552\n",
      "Epoch 530/1000\n",
      "576/576 [==============================] - 0s 88us/step - loss: 0.4305 - acc: 0.7865 - val_loss: 0.5171 - val_acc: 0.7552\n",
      "Epoch 531/1000\n",
      "576/576 [==============================] - 0s 102us/step - loss: 0.4305 - acc: 0.7865 - val_loss: 0.5171 - val_acc: 0.7552\n",
      "Epoch 532/1000\n",
      "576/576 [==============================] - 0s 131us/step - loss: 0.4304 - acc: 0.7865 - val_loss: 0.5171 - val_acc: 0.7552\n",
      "Epoch 533/1000\n",
      "576/576 [==============================] - 0s 101us/step - loss: 0.4304 - acc: 0.7865 - val_loss: 0.5171 - val_acc: 0.7552\n",
      "Epoch 534/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.4304 - acc: 0.7865 - val_loss: 0.5171 - val_acc: 0.7552\n",
      "Epoch 535/1000\n",
      "576/576 [==============================] - 0s 89us/step - loss: 0.4304 - acc: 0.7865 - val_loss: 0.5171 - val_acc: 0.7552\n",
      "Epoch 536/1000\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.4304 - acc: 0.7865 - val_loss: 0.5171 - val_acc: 0.7552\n",
      "Epoch 537/1000\n",
      "576/576 [==============================] - 0s 147us/step - loss: 0.4303 - acc: 0.7865 - val_loss: 0.5171 - val_acc: 0.7552\n",
      "Epoch 538/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 128us/step - loss: 0.4303 - acc: 0.7865 - val_loss: 0.5171 - val_acc: 0.7552\n",
      "Epoch 539/1000\n",
      "576/576 [==============================] - 0s 92us/step - loss: 0.4303 - acc: 0.7865 - val_loss: 0.5171 - val_acc: 0.7552\n",
      "Epoch 540/1000\n",
      "576/576 [==============================] - 0s 111us/step - loss: 0.4303 - acc: 0.7865 - val_loss: 0.5171 - val_acc: 0.7552\n",
      "Epoch 541/1000\n",
      "576/576 [==============================] - 0s 144us/step - loss: 0.4302 - acc: 0.7865 - val_loss: 0.5172 - val_acc: 0.7552\n",
      "Epoch 542/1000\n",
      "576/576 [==============================] - 0s 122us/step - loss: 0.4302 - acc: 0.7865 - val_loss: 0.5172 - val_acc: 0.7552\n",
      "Epoch 543/1000\n",
      "576/576 [==============================] - 0s 101us/step - loss: 0.4302 - acc: 0.7865 - val_loss: 0.5172 - val_acc: 0.7552\n",
      "Epoch 544/1000\n",
      "576/576 [==============================] - 0s 176us/step - loss: 0.4301 - acc: 0.7865 - val_loss: 0.5172 - val_acc: 0.7552\n",
      "Epoch 545/1000\n",
      "576/576 [==============================] - 0s 117us/step - loss: 0.4301 - acc: 0.7865 - val_loss: 0.5172 - val_acc: 0.7552\n",
      "Epoch 546/1000\n",
      "576/576 [==============================] - 0s 89us/step - loss: 0.4301 - acc: 0.7865 - val_loss: 0.5172 - val_acc: 0.7552\n",
      "Epoch 547/1000\n",
      "576/576 [==============================] - 0s 133us/step - loss: 0.4300 - acc: 0.7865 - val_loss: 0.5172 - val_acc: 0.7552\n",
      "Epoch 548/1000\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4300 - acc: 0.7865 - val_loss: 0.5172 - val_acc: 0.7552\n",
      "Epoch 549/1000\n",
      "576/576 [==============================] - 0s 113us/step - loss: 0.4300 - acc: 0.7865 - val_loss: 0.5172 - val_acc: 0.7552\n",
      "Epoch 550/1000\n",
      "576/576 [==============================] - 0s 102us/step - loss: 0.4300 - acc: 0.7865 - val_loss: 0.5173 - val_acc: 0.7552\n",
      "Epoch 551/1000\n",
      "576/576 [==============================] - 0s 106us/step - loss: 0.4299 - acc: 0.7865 - val_loss: 0.5173 - val_acc: 0.7552\n",
      "Epoch 552/1000\n",
      "576/576 [==============================] - 0s 104us/step - loss: 0.4299 - acc: 0.7865 - val_loss: 0.5173 - val_acc: 0.7552\n",
      "Epoch 553/1000\n",
      "576/576 [==============================] - 0s 128us/step - loss: 0.4299 - acc: 0.7865 - val_loss: 0.5173 - val_acc: 0.7552\n",
      "Epoch 554/1000\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4299 - acc: 0.7865 - val_loss: 0.5173 - val_acc: 0.7552\n",
      "Epoch 555/1000\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4298 - acc: 0.7865 - val_loss: 0.5173 - val_acc: 0.7552\n",
      "Epoch 556/1000\n",
      "576/576 [==============================] - 0s 92us/step - loss: 0.4298 - acc: 0.7865 - val_loss: 0.5173 - val_acc: 0.7552\n",
      "Epoch 557/1000\n",
      "576/576 [==============================] - 0s 91us/step - loss: 0.4298 - acc: 0.7865 - val_loss: 0.5173 - val_acc: 0.7552\n",
      "Epoch 558/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4297 - acc: 0.7865 - val_loss: 0.5173 - val_acc: 0.7552\n",
      "Epoch 559/1000\n",
      "576/576 [==============================] - 0s 90us/step - loss: 0.4297 - acc: 0.7865 - val_loss: 0.5173 - val_acc: 0.7552\n",
      "Epoch 560/1000\n",
      "576/576 [==============================] - 0s 72us/step - loss: 0.4297 - acc: 0.7865 - val_loss: 0.5173 - val_acc: 0.7552\n",
      "Epoch 561/1000\n",
      "576/576 [==============================] - 0s 90us/step - loss: 0.4297 - acc: 0.7865 - val_loss: 0.5173 - val_acc: 0.7552\n",
      "Epoch 562/1000\n",
      "576/576 [==============================] - 0s 89us/step - loss: 0.4296 - acc: 0.7865 - val_loss: 0.5173 - val_acc: 0.7552\n",
      "Epoch 563/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.4296 - acc: 0.7865 - val_loss: 0.5174 - val_acc: 0.7552\n",
      "Epoch 564/1000\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.4296 - acc: 0.7865 - val_loss: 0.5174 - val_acc: 0.7552\n",
      "Epoch 565/1000\n",
      "576/576 [==============================] - 0s 119us/step - loss: 0.4295 - acc: 0.7865 - val_loss: 0.5174 - val_acc: 0.7552\n",
      "Epoch 566/1000\n",
      "576/576 [==============================] - 0s 129us/step - loss: 0.4295 - acc: 0.7847 - val_loss: 0.5174 - val_acc: 0.7552\n",
      "Epoch 567/1000\n",
      "576/576 [==============================] - 0s 132us/step - loss: 0.4295 - acc: 0.7847 - val_loss: 0.5174 - val_acc: 0.7552\n",
      "Epoch 568/1000\n",
      "576/576 [==============================] - 0s 102us/step - loss: 0.4295 - acc: 0.7847 - val_loss: 0.5174 - val_acc: 0.7552\n",
      "Epoch 569/1000\n",
      "576/576 [==============================] - 0s 92us/step - loss: 0.4294 - acc: 0.7847 - val_loss: 0.5174 - val_acc: 0.7552\n",
      "Epoch 570/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4294 - acc: 0.7847 - val_loss: 0.5174 - val_acc: 0.7552\n",
      "Epoch 571/1000\n",
      "576/576 [==============================] - 0s 95us/step - loss: 0.4294 - acc: 0.7847 - val_loss: 0.5174 - val_acc: 0.7500\n",
      "Epoch 572/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4294 - acc: 0.7847 - val_loss: 0.5174 - val_acc: 0.7500\n",
      "Epoch 573/1000\n",
      "576/576 [==============================] - 0s 88us/step - loss: 0.4293 - acc: 0.7847 - val_loss: 0.5174 - val_acc: 0.7500\n",
      "Epoch 574/1000\n",
      "576/576 [==============================] - 0s 86us/step - loss: 0.4293 - acc: 0.7847 - val_loss: 0.5174 - val_acc: 0.7500\n",
      "Epoch 575/1000\n",
      "576/576 [==============================] - 0s 85us/step - loss: 0.4293 - acc: 0.7847 - val_loss: 0.5174 - val_acc: 0.7500\n",
      "Epoch 576/1000\n",
      "576/576 [==============================] - 0s 72us/step - loss: 0.4292 - acc: 0.7847 - val_loss: 0.5175 - val_acc: 0.7500\n",
      "Epoch 577/1000\n",
      "576/576 [==============================] - 0s 82us/step - loss: 0.4292 - acc: 0.7847 - val_loss: 0.5175 - val_acc: 0.7500\n",
      "Epoch 578/1000\n",
      "576/576 [==============================] - 0s 73us/step - loss: 0.4292 - acc: 0.7847 - val_loss: 0.5175 - val_acc: 0.7500\n",
      "Epoch 579/1000\n",
      "576/576 [==============================] - 0s 85us/step - loss: 0.4291 - acc: 0.7847 - val_loss: 0.5175 - val_acc: 0.7500\n",
      "Epoch 580/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4292 - acc: 0.7847 - val_loss: 0.5175 - val_acc: 0.7500\n",
      "Epoch 581/1000\n",
      "576/576 [==============================] - 0s 69us/step - loss: 0.4291 - acc: 0.7847 - val_loss: 0.5175 - val_acc: 0.7500\n",
      "Epoch 582/1000\n",
      "576/576 [==============================] - 0s 101us/step - loss: 0.4291 - acc: 0.7830 - val_loss: 0.5175 - val_acc: 0.7500\n",
      "Epoch 583/1000\n",
      "576/576 [==============================] - 0s 87us/step - loss: 0.4291 - acc: 0.7847 - val_loss: 0.5175 - val_acc: 0.7500\n",
      "Epoch 584/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4290 - acc: 0.7847 - val_loss: 0.5175 - val_acc: 0.7500\n",
      "Epoch 585/1000\n",
      "576/576 [==============================] - 0s 94us/step - loss: 0.4290 - acc: 0.7830 - val_loss: 0.5175 - val_acc: 0.7500\n",
      "Epoch 586/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4290 - acc: 0.7847 - val_loss: 0.5175 - val_acc: 0.7500\n",
      "Epoch 587/1000\n",
      "576/576 [==============================] - 0s 101us/step - loss: 0.4290 - acc: 0.7847 - val_loss: 0.5175 - val_acc: 0.7500\n",
      "Epoch 588/1000\n",
      "576/576 [==============================] - 0s 148us/step - loss: 0.4289 - acc: 0.7830 - val_loss: 0.5175 - val_acc: 0.7500\n",
      "Epoch 589/1000\n",
      "576/576 [==============================] - 0s 179us/step - loss: 0.4289 - acc: 0.7830 - val_loss: 0.5175 - val_acc: 0.7500\n",
      "Epoch 590/1000\n",
      "576/576 [==============================] - 0s 159us/step - loss: 0.4289 - acc: 0.7830 - val_loss: 0.5175 - val_acc: 0.7500\n",
      "Epoch 591/1000\n",
      "576/576 [==============================] - 0s 157us/step - loss: 0.4289 - acc: 0.7830 - val_loss: 0.5175 - val_acc: 0.7500\n",
      "Epoch 592/1000\n",
      "576/576 [==============================] - 0s 185us/step - loss: 0.4288 - acc: 0.7830 - val_loss: 0.5175 - val_acc: 0.7500\n",
      "Epoch 593/1000\n",
      "576/576 [==============================] - 0s 207us/step - loss: 0.4288 - acc: 0.7830 - val_loss: 0.5176 - val_acc: 0.7500\n",
      "Epoch 594/1000\n",
      "576/576 [==============================] - 0s 112us/step - loss: 0.4288 - acc: 0.7830 - val_loss: 0.5176 - val_acc: 0.7500\n",
      "Epoch 595/1000\n",
      "576/576 [==============================] - 0s 156us/step - loss: 0.4288 - acc: 0.7830 - val_loss: 0.5176 - val_acc: 0.7500\n",
      "Epoch 596/1000\n",
      "576/576 [==============================] - 0s 159us/step - loss: 0.4288 - acc: 0.7830 - val_loss: 0.5176 - val_acc: 0.7500\n",
      "Epoch 597/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 173us/step - loss: 0.4287 - acc: 0.7830 - val_loss: 0.5176 - val_acc: 0.7500\n",
      "Epoch 598/1000\n",
      "576/576 [==============================] - 0s 152us/step - loss: 0.4287 - acc: 0.7830 - val_loss: 0.5176 - val_acc: 0.7500\n",
      "Epoch 599/1000\n",
      "576/576 [==============================] - 0s 114us/step - loss: 0.4287 - acc: 0.7830 - val_loss: 0.5176 - val_acc: 0.7500\n",
      "Epoch 600/1000\n",
      "576/576 [==============================] - 0s 154us/step - loss: 0.4286 - acc: 0.7830 - val_loss: 0.5176 - val_acc: 0.7500\n",
      "Epoch 601/1000\n",
      "576/576 [==============================] - 0s 131us/step - loss: 0.4286 - acc: 0.7830 - val_loss: 0.5176 - val_acc: 0.7500\n",
      "Epoch 602/1000\n",
      "576/576 [==============================] - 0s 142us/step - loss: 0.4286 - acc: 0.7830 - val_loss: 0.5176 - val_acc: 0.7500\n",
      "Epoch 603/1000\n",
      "576/576 [==============================] - 0s 155us/step - loss: 0.4286 - acc: 0.7830 - val_loss: 0.5176 - val_acc: 0.7500\n",
      "Epoch 604/1000\n",
      "576/576 [==============================] - 0s 125us/step - loss: 0.4285 - acc: 0.7830 - val_loss: 0.5177 - val_acc: 0.7500\n",
      "Epoch 605/1000\n",
      "576/576 [==============================] - 0s 122us/step - loss: 0.4285 - acc: 0.7830 - val_loss: 0.5177 - val_acc: 0.7500\n",
      "Epoch 606/1000\n",
      "576/576 [==============================] - 0s 123us/step - loss: 0.4285 - acc: 0.7830 - val_loss: 0.5177 - val_acc: 0.7500\n",
      "Epoch 607/1000\n",
      "576/576 [==============================] - 0s 109us/step - loss: 0.4285 - acc: 0.7830 - val_loss: 0.5177 - val_acc: 0.7500\n",
      "Epoch 608/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4284 - acc: 0.7830 - val_loss: 0.5177 - val_acc: 0.7500\n",
      "Epoch 609/1000\n",
      "576/576 [==============================] - 0s 88us/step - loss: 0.4284 - acc: 0.7830 - val_loss: 0.5177 - val_acc: 0.7500\n",
      "Epoch 610/1000\n",
      "576/576 [==============================] - 0s 74us/step - loss: 0.4284 - acc: 0.7830 - val_loss: 0.5177 - val_acc: 0.7500\n",
      "Epoch 611/1000\n",
      "576/576 [==============================] - 0s 88us/step - loss: 0.4284 - acc: 0.7830 - val_loss: 0.5177 - val_acc: 0.7500\n",
      "Epoch 612/1000\n",
      "576/576 [==============================] - 0s 82us/step - loss: 0.4283 - acc: 0.7830 - val_loss: 0.5177 - val_acc: 0.7500\n",
      "Epoch 613/1000\n",
      "576/576 [==============================] - 0s 82us/step - loss: 0.4283 - acc: 0.7830 - val_loss: 0.5177 - val_acc: 0.7500\n",
      "Epoch 614/1000\n",
      "576/576 [==============================] - 0s 89us/step - loss: 0.4283 - acc: 0.7830 - val_loss: 0.5177 - val_acc: 0.7500\n",
      "Epoch 615/1000\n",
      "576/576 [==============================] - 0s 165us/step - loss: 0.4283 - acc: 0.7830 - val_loss: 0.5178 - val_acc: 0.7500\n",
      "Epoch 616/1000\n",
      "576/576 [==============================] - 0s 206us/step - loss: 0.4282 - acc: 0.7830 - val_loss: 0.5178 - val_acc: 0.7500\n",
      "Epoch 617/1000\n",
      "576/576 [==============================] - 0s 163us/step - loss: 0.4282 - acc: 0.7830 - val_loss: 0.5178 - val_acc: 0.7500\n",
      "Epoch 618/1000\n",
      "576/576 [==============================] - 0s 146us/step - loss: 0.4282 - acc: 0.7830 - val_loss: 0.5178 - val_acc: 0.7500\n",
      "Epoch 619/1000\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4282 - acc: 0.7830 - val_loss: 0.5178 - val_acc: 0.7500\n",
      "Epoch 620/1000\n",
      "576/576 [==============================] - 0s 111us/step - loss: 0.4281 - acc: 0.7830 - val_loss: 0.5178 - val_acc: 0.7500\n",
      "Epoch 621/1000\n",
      "576/576 [==============================] - 0s 114us/step - loss: 0.4281 - acc: 0.7830 - val_loss: 0.5178 - val_acc: 0.7500\n",
      "Epoch 622/1000\n",
      "576/576 [==============================] - 0s 145us/step - loss: 0.4281 - acc: 0.7830 - val_loss: 0.5178 - val_acc: 0.7500\n",
      "Epoch 623/1000\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4281 - acc: 0.7830 - val_loss: 0.5178 - val_acc: 0.7500\n",
      "Epoch 624/1000\n",
      "576/576 [==============================] - 0s 83us/step - loss: 0.4280 - acc: 0.7830 - val_loss: 0.5178 - val_acc: 0.7500\n",
      "Epoch 625/1000\n",
      "576/576 [==============================] - 0s 94us/step - loss: 0.4280 - acc: 0.7830 - val_loss: 0.5178 - val_acc: 0.7500\n",
      "Epoch 626/1000\n",
      "576/576 [==============================] - 0s 84us/step - loss: 0.4280 - acc: 0.7830 - val_loss: 0.5179 - val_acc: 0.7500\n",
      "Epoch 627/1000\n",
      "576/576 [==============================] - 0s 131us/step - loss: 0.4280 - acc: 0.7830 - val_loss: 0.5179 - val_acc: 0.7500\n",
      "Epoch 628/1000\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4279 - acc: 0.7830 - val_loss: 0.5179 - val_acc: 0.7500\n",
      "Epoch 629/1000\n",
      "576/576 [==============================] - 0s 105us/step - loss: 0.4279 - acc: 0.7830 - val_loss: 0.5179 - val_acc: 0.7500\n",
      "Epoch 630/1000\n",
      "576/576 [==============================] - 0s 116us/step - loss: 0.4279 - acc: 0.7847 - val_loss: 0.5179 - val_acc: 0.7500\n",
      "Epoch 631/1000\n",
      "576/576 [==============================] - 0s 88us/step - loss: 0.4279 - acc: 0.7830 - val_loss: 0.5179 - val_acc: 0.7500\n",
      "Epoch 632/1000\n",
      "576/576 [==============================] - 0s 92us/step - loss: 0.4279 - acc: 0.7830 - val_loss: 0.5179 - val_acc: 0.7500\n",
      "Epoch 633/1000\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4278 - acc: 0.7847 - val_loss: 0.5179 - val_acc: 0.7500\n",
      "Epoch 634/1000\n",
      "576/576 [==============================] - 0s 197us/step - loss: 0.4278 - acc: 0.7847 - val_loss: 0.5179 - val_acc: 0.7500\n",
      "Epoch 635/1000\n",
      "576/576 [==============================] - 0s 148us/step - loss: 0.4278 - acc: 0.7847 - val_loss: 0.5179 - val_acc: 0.7500\n",
      "Epoch 636/1000\n",
      "576/576 [==============================] - 0s 178us/step - loss: 0.4277 - acc: 0.7847 - val_loss: 0.5179 - val_acc: 0.7500\n",
      "Epoch 637/1000\n",
      "576/576 [==============================] - 0s 153us/step - loss: 0.4277 - acc: 0.7847 - val_loss: 0.5180 - val_acc: 0.7500\n",
      "Epoch 638/1000\n",
      "576/576 [==============================] - 0s 172us/step - loss: 0.4277 - acc: 0.7847 - val_loss: 0.5180 - val_acc: 0.7500\n",
      "Epoch 639/1000\n",
      "576/576 [==============================] - 0s 149us/step - loss: 0.4277 - acc: 0.7847 - val_loss: 0.5180 - val_acc: 0.7500\n",
      "Epoch 640/1000\n",
      "576/576 [==============================] - 0s 149us/step - loss: 0.4276 - acc: 0.7847 - val_loss: 0.5180 - val_acc: 0.7500\n",
      "Epoch 641/1000\n",
      "576/576 [==============================] - 0s 85us/step - loss: 0.4276 - acc: 0.7847 - val_loss: 0.5180 - val_acc: 0.7500\n",
      "Epoch 642/1000\n",
      "576/576 [==============================] - 0s 122us/step - loss: 0.4276 - acc: 0.7847 - val_loss: 0.5180 - val_acc: 0.7500\n",
      "Epoch 643/1000\n",
      "576/576 [==============================] - 0s 170us/step - loss: 0.4276 - acc: 0.7865 - val_loss: 0.5180 - val_acc: 0.7500\n",
      "Epoch 644/1000\n",
      "576/576 [==============================] - 0s 150us/step - loss: 0.4276 - acc: 0.7847 - val_loss: 0.5180 - val_acc: 0.7500\n",
      "Epoch 645/1000\n",
      "576/576 [==============================] - 0s 167us/step - loss: 0.4275 - acc: 0.7865 - val_loss: 0.5180 - val_acc: 0.7500\n",
      "Epoch 646/1000\n",
      "576/576 [==============================] - 0s 160us/step - loss: 0.4275 - acc: 0.7865 - val_loss: 0.5180 - val_acc: 0.7500\n",
      "Epoch 647/1000\n",
      "576/576 [==============================] - 0s 102us/step - loss: 0.4275 - acc: 0.7865 - val_loss: 0.5180 - val_acc: 0.7500\n",
      "Epoch 648/1000\n",
      "576/576 [==============================] - 0s 114us/step - loss: 0.4274 - acc: 0.7865 - val_loss: 0.5181 - val_acc: 0.7500\n",
      "Epoch 649/1000\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4274 - acc: 0.7865 - val_loss: 0.5181 - val_acc: 0.7500\n",
      "Epoch 650/1000\n",
      "576/576 [==============================] - 0s 153us/step - loss: 0.4274 - acc: 0.7865 - val_loss: 0.5181 - val_acc: 0.7500\n",
      "Epoch 651/1000\n",
      "576/576 [==============================] - 0s 131us/step - loss: 0.4274 - acc: 0.7865 - val_loss: 0.5181 - val_acc: 0.7500\n",
      "Epoch 652/1000\n",
      "576/576 [==============================] - 0s 143us/step - loss: 0.4273 - acc: 0.7865 - val_loss: 0.5181 - val_acc: 0.7500\n",
      "Epoch 653/1000\n",
      "576/576 [==============================] - 0s 157us/step - loss: 0.4273 - acc: 0.7865 - val_loss: 0.5181 - val_acc: 0.7500\n",
      "Epoch 654/1000\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4273 - acc: 0.7847 - val_loss: 0.5181 - val_acc: 0.7500\n",
      "Epoch 655/1000\n",
      "576/576 [==============================] - 0s 159us/step - loss: 0.4273 - acc: 0.7865 - val_loss: 0.5181 - val_acc: 0.7500\n",
      "Epoch 656/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 140us/step - loss: 0.4273 - acc: 0.7865 - val_loss: 0.5182 - val_acc: 0.7500\n",
      "Epoch 657/1000\n",
      "576/576 [==============================] - 0s 95us/step - loss: 0.4272 - acc: 0.7865 - val_loss: 0.5182 - val_acc: 0.7500\n",
      "Epoch 658/1000\n",
      "576/576 [==============================] - 0s 125us/step - loss: 0.4272 - acc: 0.7865 - val_loss: 0.5182 - val_acc: 0.7500\n",
      "Epoch 659/1000\n",
      "576/576 [==============================] - 0s 110us/step - loss: 0.4272 - acc: 0.7865 - val_loss: 0.5182 - val_acc: 0.7500\n",
      "Epoch 660/1000\n",
      "576/576 [==============================] - 0s 103us/step - loss: 0.4272 - acc: 0.7865 - val_loss: 0.5182 - val_acc: 0.7500\n",
      "Epoch 661/1000\n",
      "576/576 [==============================] - 0s 141us/step - loss: 0.4271 - acc: 0.7847 - val_loss: 0.5182 - val_acc: 0.7500\n",
      "Epoch 662/1000\n",
      "576/576 [==============================] - 0s 127us/step - loss: 0.4271 - acc: 0.7865 - val_loss: 0.5182 - val_acc: 0.7500\n",
      "Epoch 663/1000\n",
      "576/576 [==============================] - 0s 114us/step - loss: 0.4271 - acc: 0.7865 - val_loss: 0.5182 - val_acc: 0.7500\n",
      "Epoch 664/1000\n",
      "576/576 [==============================] - 0s 120us/step - loss: 0.4270 - acc: 0.7865 - val_loss: 0.5183 - val_acc: 0.7500\n",
      "Epoch 665/1000\n",
      "576/576 [==============================] - 0s 132us/step - loss: 0.4270 - acc: 0.7865 - val_loss: 0.5183 - val_acc: 0.7500\n",
      "Epoch 666/1000\n",
      "576/576 [==============================] - 0s 111us/step - loss: 0.4270 - acc: 0.7847 - val_loss: 0.5183 - val_acc: 0.7500\n",
      "Epoch 667/1000\n",
      "576/576 [==============================] - 0s 126us/step - loss: 0.4270 - acc: 0.7847 - val_loss: 0.5183 - val_acc: 0.7500\n",
      "Epoch 668/1000\n",
      "576/576 [==============================] - 0s 160us/step - loss: 0.4269 - acc: 0.7865 - val_loss: 0.5183 - val_acc: 0.7500\n",
      "Epoch 669/1000\n",
      "576/576 [==============================] - 0s 124us/step - loss: 0.4269 - acc: 0.7865 - val_loss: 0.5183 - val_acc: 0.7500\n",
      "Epoch 670/1000\n",
      "576/576 [==============================] - 0s 168us/step - loss: 0.4269 - acc: 0.7865 - val_loss: 0.5183 - val_acc: 0.7500\n",
      "Epoch 671/1000\n",
      "576/576 [==============================] - 0s 165us/step - loss: 0.4269 - acc: 0.7865 - val_loss: 0.5183 - val_acc: 0.7500\n",
      "Epoch 672/1000\n",
      "576/576 [==============================] - 0s 172us/step - loss: 0.4268 - acc: 0.7865 - val_loss: 0.5183 - val_acc: 0.7500\n",
      "Epoch 673/1000\n",
      "576/576 [==============================] - 0s 171us/step - loss: 0.4268 - acc: 0.7865 - val_loss: 0.5183 - val_acc: 0.7500\n",
      "Epoch 674/1000\n",
      "576/576 [==============================] - 0s 166us/step - loss: 0.4268 - acc: 0.7847 - val_loss: 0.5183 - val_acc: 0.7500\n",
      "Epoch 675/1000\n",
      "576/576 [==============================] - 0s 112us/step - loss: 0.4268 - acc: 0.7865 - val_loss: 0.5184 - val_acc: 0.7500\n",
      "Epoch 676/1000\n",
      "576/576 [==============================] - 0s 146us/step - loss: 0.4268 - acc: 0.7865 - val_loss: 0.5184 - val_acc: 0.7500\n",
      "Epoch 677/1000\n",
      "576/576 [==============================] - 0s 152us/step - loss: 0.4267 - acc: 0.7865 - val_loss: 0.5184 - val_acc: 0.7500\n",
      "Epoch 678/1000\n",
      "576/576 [==============================] - 0s 162us/step - loss: 0.4267 - acc: 0.7847 - val_loss: 0.5184 - val_acc: 0.7500\n",
      "Epoch 679/1000\n",
      "576/576 [==============================] - 0s 168us/step - loss: 0.4267 - acc: 0.7865 - val_loss: 0.5184 - val_acc: 0.7500\n",
      "Epoch 680/1000\n",
      "576/576 [==============================] - 0s 115us/step - loss: 0.4266 - acc: 0.7847 - val_loss: 0.5184 - val_acc: 0.7500\n",
      "Epoch 681/1000\n",
      "576/576 [==============================] - 0s 94us/step - loss: 0.4266 - acc: 0.7847 - val_loss: 0.5184 - val_acc: 0.7500\n",
      "Epoch 682/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.4266 - acc: 0.7865 - val_loss: 0.5184 - val_acc: 0.7500\n",
      "Epoch 683/1000\n",
      "576/576 [==============================] - 0s 90us/step - loss: 0.4266 - acc: 0.7865 - val_loss: 0.5184 - val_acc: 0.7500\n",
      "Epoch 684/1000\n",
      "576/576 [==============================] - 0s 104us/step - loss: 0.4266 - acc: 0.7865 - val_loss: 0.5185 - val_acc: 0.7500\n",
      "Epoch 685/1000\n",
      "576/576 [==============================] - 0s 143us/step - loss: 0.4265 - acc: 0.7865 - val_loss: 0.5185 - val_acc: 0.7500\n",
      "Epoch 686/1000\n",
      "576/576 [==============================] - 0s 104us/step - loss: 0.4265 - acc: 0.7830 - val_loss: 0.5185 - val_acc: 0.7500\n",
      "Epoch 687/1000\n",
      "576/576 [==============================] - 0s 124us/step - loss: 0.4265 - acc: 0.7865 - val_loss: 0.5185 - val_acc: 0.7500\n",
      "Epoch 688/1000\n",
      "576/576 [==============================] - 0s 143us/step - loss: 0.4265 - acc: 0.7830 - val_loss: 0.5185 - val_acc: 0.7500\n",
      "Epoch 689/1000\n",
      "576/576 [==============================] - 0s 103us/step - loss: 0.4264 - acc: 0.7847 - val_loss: 0.5185 - val_acc: 0.7500\n",
      "Epoch 690/1000\n",
      "576/576 [==============================] - 0s 82us/step - loss: 0.4264 - acc: 0.7830 - val_loss: 0.5185 - val_acc: 0.7500\n",
      "Epoch 691/1000\n",
      "576/576 [==============================] - 0s 92us/step - loss: 0.4264 - acc: 0.7847 - val_loss: 0.5185 - val_acc: 0.7500\n",
      "Epoch 692/1000\n",
      "576/576 [==============================] - 0s 108us/step - loss: 0.4264 - acc: 0.7830 - val_loss: 0.5185 - val_acc: 0.7500\n",
      "Epoch 693/1000\n",
      "576/576 [==============================] - 0s 91us/step - loss: 0.4263 - acc: 0.7847 - val_loss: 0.5185 - val_acc: 0.7500\n",
      "Epoch 694/1000\n",
      "576/576 [==============================] - 0s 113us/step - loss: 0.4263 - acc: 0.7830 - val_loss: 0.5185 - val_acc: 0.7500\n",
      "Epoch 695/1000\n",
      "576/576 [==============================] - 0s 152us/step - loss: 0.4263 - acc: 0.7830 - val_loss: 0.5185 - val_acc: 0.7500\n",
      "Epoch 696/1000\n",
      "576/576 [==============================] - 0s 98us/step - loss: 0.4263 - acc: 0.7847 - val_loss: 0.5186 - val_acc: 0.7500\n",
      "Epoch 697/1000\n",
      "576/576 [==============================] - 0s 85us/step - loss: 0.4262 - acc: 0.7830 - val_loss: 0.5186 - val_acc: 0.7500\n",
      "Epoch 698/1000\n",
      "576/576 [==============================] - 0s 82us/step - loss: 0.4262 - acc: 0.7847 - val_loss: 0.5186 - val_acc: 0.7500\n",
      "Epoch 699/1000\n",
      "576/576 [==============================] - 0s 86us/step - loss: 0.4262 - acc: 0.7830 - val_loss: 0.5186 - val_acc: 0.7500\n",
      "Epoch 700/1000\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.4262 - acc: 0.7830 - val_loss: 0.5186 - val_acc: 0.7500\n",
      "Epoch 701/1000\n",
      "576/576 [==============================] - 0s 93us/step - loss: 0.4261 - acc: 0.7847 - val_loss: 0.5186 - val_acc: 0.7500\n",
      "Epoch 702/1000\n",
      "576/576 [==============================] - 0s 200us/step - loss: 0.4261 - acc: 0.7830 - val_loss: 0.5186 - val_acc: 0.7500\n",
      "Epoch 703/1000\n",
      "576/576 [==============================] - 0s 234us/step - loss: 0.4261 - acc: 0.7830 - val_loss: 0.5186 - val_acc: 0.7500\n",
      "Epoch 704/1000\n",
      "576/576 [==============================] - 0s 172us/step - loss: 0.4260 - acc: 0.7830 - val_loss: 0.5186 - val_acc: 0.7500\n",
      "Epoch 705/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4260 - acc: 0.7830 - val_loss: 0.5186 - val_acc: 0.7500\n",
      "Epoch 706/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.4260 - acc: 0.7847 - val_loss: 0.5186 - val_acc: 0.7500\n",
      "Epoch 707/1000\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4260 - acc: 0.7830 - val_loss: 0.5186 - val_acc: 0.7500\n",
      "Epoch 708/1000\n",
      "576/576 [==============================] - 0s 106us/step - loss: 0.4260 - acc: 0.7865 - val_loss: 0.5187 - val_acc: 0.7500\n",
      "Epoch 709/1000\n",
      "576/576 [==============================] - 0s 128us/step - loss: 0.4259 - acc: 0.7830 - val_loss: 0.5187 - val_acc: 0.7500\n",
      "Epoch 710/1000\n",
      "576/576 [==============================] - 0s 151us/step - loss: 0.4259 - acc: 0.7830 - val_loss: 0.5187 - val_acc: 0.7500\n",
      "Epoch 711/1000\n",
      "576/576 [==============================] - 0s 297us/step - loss: 0.4259 - acc: 0.7830 - val_loss: 0.5187 - val_acc: 0.7500\n",
      "Epoch 712/1000\n",
      "576/576 [==============================] - 0s 272us/step - loss: 0.4259 - acc: 0.7847 - val_loss: 0.5187 - val_acc: 0.7500\n",
      "Epoch 713/1000\n",
      "576/576 [==============================] - 0s 156us/step - loss: 0.4259 - acc: 0.7830 - val_loss: 0.5187 - val_acc: 0.7500\n",
      "Epoch 714/1000\n",
      "576/576 [==============================] - 0s 101us/step - loss: 0.4258 - acc: 0.7847 - val_loss: 0.5187 - val_acc: 0.7500\n",
      "Epoch 715/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 146us/step - loss: 0.4258 - acc: 0.7847 - val_loss: 0.5187 - val_acc: 0.7500\n",
      "Epoch 716/1000\n",
      "576/576 [==============================] - 0s 91us/step - loss: 0.4258 - acc: 0.7847 - val_loss: 0.5187 - val_acc: 0.7500\n",
      "Epoch 717/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4257 - acc: 0.7847 - val_loss: 0.5187 - val_acc: 0.7500\n",
      "Epoch 718/1000\n",
      "576/576 [==============================] - 0s 68us/step - loss: 0.4257 - acc: 0.7847 - val_loss: 0.5188 - val_acc: 0.7500\n",
      "Epoch 719/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4257 - acc: 0.7847 - val_loss: 0.5188 - val_acc: 0.7500\n",
      "Epoch 720/1000\n",
      "576/576 [==============================] - 0s 82us/step - loss: 0.4257 - acc: 0.7847 - val_loss: 0.5188 - val_acc: 0.7500\n",
      "Epoch 721/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4257 - acc: 0.7847 - val_loss: 0.5188 - val_acc: 0.7500\n",
      "Epoch 722/1000\n",
      "576/576 [==============================] - 0s 87us/step - loss: 0.4256 - acc: 0.7847 - val_loss: 0.5188 - val_acc: 0.7500\n",
      "Epoch 723/1000\n",
      "576/576 [==============================] - 0s 67us/step - loss: 0.4256 - acc: 0.7847 - val_loss: 0.5188 - val_acc: 0.7500\n",
      "Epoch 724/1000\n",
      "576/576 [==============================] - 0s 146us/step - loss: 0.4256 - acc: 0.7847 - val_loss: 0.5188 - val_acc: 0.7500\n",
      "Epoch 725/1000\n",
      "576/576 [==============================] - 0s 206us/step - loss: 0.4255 - acc: 0.7847 - val_loss: 0.5188 - val_acc: 0.7500\n",
      "Epoch 726/1000\n",
      "576/576 [==============================] - 0s 168us/step - loss: 0.4256 - acc: 0.7847 - val_loss: 0.5188 - val_acc: 0.7500\n",
      "Epoch 727/1000\n",
      "576/576 [==============================] - 0s 95us/step - loss: 0.4255 - acc: 0.7847 - val_loss: 0.5188 - val_acc: 0.7500\n",
      "Epoch 728/1000\n",
      "576/576 [==============================] - 0s 84us/step - loss: 0.4255 - acc: 0.7847 - val_loss: 0.5189 - val_acc: 0.7500\n",
      "Epoch 729/1000\n",
      "576/576 [==============================] - 0s 92us/step - loss: 0.4255 - acc: 0.7847 - val_loss: 0.5189 - val_acc: 0.7500\n",
      "Epoch 730/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4255 - acc: 0.7847 - val_loss: 0.5189 - val_acc: 0.7500\n",
      "Epoch 731/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.4254 - acc: 0.7865 - val_loss: 0.5189 - val_acc: 0.7500\n",
      "Epoch 732/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.4254 - acc: 0.7847 - val_loss: 0.5189 - val_acc: 0.7500\n",
      "Epoch 733/1000\n",
      "576/576 [==============================] - 0s 119us/step - loss: 0.4254 - acc: 0.7865 - val_loss: 0.5189 - val_acc: 0.7500\n",
      "Epoch 734/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4254 - acc: 0.7847 - val_loss: 0.5189 - val_acc: 0.7500\n",
      "Epoch 735/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4253 - acc: 0.7865 - val_loss: 0.5190 - val_acc: 0.7448\n",
      "Epoch 736/1000\n",
      "576/576 [==============================] - 0s 95us/step - loss: 0.4253 - acc: 0.7847 - val_loss: 0.5190 - val_acc: 0.7448\n",
      "Epoch 737/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4253 - acc: 0.7865 - val_loss: 0.5190 - val_acc: 0.7448\n",
      "Epoch 738/1000\n",
      "576/576 [==============================] - 0s 85us/step - loss: 0.4252 - acc: 0.7865 - val_loss: 0.5190 - val_acc: 0.7448\n",
      "Epoch 739/1000\n",
      "576/576 [==============================] - 0s 86us/step - loss: 0.4252 - acc: 0.7865 - val_loss: 0.5190 - val_acc: 0.7448\n",
      "Epoch 740/1000\n",
      "576/576 [==============================] - 0s 107us/step - loss: 0.4252 - acc: 0.7865 - val_loss: 0.5190 - val_acc: 0.7448\n",
      "Epoch 741/1000\n",
      "576/576 [==============================] - 0s 123us/step - loss: 0.4252 - acc: 0.7865 - val_loss: 0.5190 - val_acc: 0.7448\n",
      "Epoch 742/1000\n",
      "576/576 [==============================] - 0s 151us/step - loss: 0.4252 - acc: 0.7865 - val_loss: 0.5190 - val_acc: 0.7448\n",
      "Epoch 743/1000\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4251 - acc: 0.7865 - val_loss: 0.5190 - val_acc: 0.7448\n",
      "Epoch 744/1000\n",
      "576/576 [==============================] - 0s 123us/step - loss: 0.4251 - acc: 0.7865 - val_loss: 0.5190 - val_acc: 0.7448\n",
      "Epoch 745/1000\n",
      "576/576 [==============================] - 0s 145us/step - loss: 0.4250 - acc: 0.7865 - val_loss: 0.5190 - val_acc: 0.7448\n",
      "Epoch 746/1000\n",
      "576/576 [==============================] - 0s 110us/step - loss: 0.4251 - acc: 0.7865 - val_loss: 0.5191 - val_acc: 0.7448\n",
      "Epoch 747/1000\n",
      "576/576 [==============================] - 0s 158us/step - loss: 0.4250 - acc: 0.7865 - val_loss: 0.5191 - val_acc: 0.7448\n",
      "Epoch 748/1000\n",
      "576/576 [==============================] - 0s 155us/step - loss: 0.4250 - acc: 0.7865 - val_loss: 0.5191 - val_acc: 0.7448\n",
      "Epoch 749/1000\n",
      "576/576 [==============================] - 0s 161us/step - loss: 0.4250 - acc: 0.7865 - val_loss: 0.5191 - val_acc: 0.7448\n",
      "Epoch 750/1000\n",
      "576/576 [==============================] - 0s 159us/step - loss: 0.4249 - acc: 0.7865 - val_loss: 0.5191 - val_acc: 0.7448\n",
      "Epoch 751/1000\n",
      "576/576 [==============================] - 0s 160us/step - loss: 0.4249 - acc: 0.7865 - val_loss: 0.5191 - val_acc: 0.7448\n",
      "Epoch 752/1000\n",
      "576/576 [==============================] - 0s 116us/step - loss: 0.4249 - acc: 0.7865 - val_loss: 0.5191 - val_acc: 0.7448\n",
      "Epoch 753/1000\n",
      "576/576 [==============================] - 0s 201us/step - loss: 0.4249 - acc: 0.7865 - val_loss: 0.5191 - val_acc: 0.7448\n",
      "Epoch 754/1000\n",
      "576/576 [==============================] - 0s 188us/step - loss: 0.4249 - acc: 0.7865 - val_loss: 0.5191 - val_acc: 0.7448\n",
      "Epoch 755/1000\n",
      "576/576 [==============================] - 0s 122us/step - loss: 0.4249 - acc: 0.7865 - val_loss: 0.5191 - val_acc: 0.7448\n",
      "Epoch 756/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4248 - acc: 0.7865 - val_loss: 0.5192 - val_acc: 0.7448\n",
      "Epoch 757/1000\n",
      "576/576 [==============================] - 0s 90us/step - loss: 0.4248 - acc: 0.7865 - val_loss: 0.5192 - val_acc: 0.7448\n",
      "Epoch 758/1000\n",
      "576/576 [==============================] - 0s 110us/step - loss: 0.4248 - acc: 0.7865 - val_loss: 0.5192 - val_acc: 0.7448\n",
      "Epoch 759/1000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.4247 - acc: 0.7865 - val_loss: 0.5192 - val_acc: 0.7448\n",
      "Epoch 760/1000\n",
      "576/576 [==============================] - 0s 83us/step - loss: 0.4247 - acc: 0.7865 - val_loss: 0.5192 - val_acc: 0.7448\n",
      "Epoch 761/1000\n",
      "576/576 [==============================] - 0s 98us/step - loss: 0.4247 - acc: 0.7865 - val_loss: 0.5192 - val_acc: 0.7448\n",
      "Epoch 762/1000\n",
      "576/576 [==============================] - 0s 85us/step - loss: 0.4247 - acc: 0.7865 - val_loss: 0.5192 - val_acc: 0.7448\n",
      "Epoch 763/1000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.4246 - acc: 0.7865 - val_loss: 0.5192 - val_acc: 0.7448\n",
      "Epoch 764/1000\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4246 - acc: 0.7865 - val_loss: 0.5193 - val_acc: 0.7448\n",
      "Epoch 765/1000\n",
      "576/576 [==============================] - 0s 94us/step - loss: 0.4247 - acc: 0.7865 - val_loss: 0.5193 - val_acc: 0.7448\n",
      "Epoch 766/1000\n",
      "576/576 [==============================] - 0s 101us/step - loss: 0.4246 - acc: 0.7865 - val_loss: 0.5193 - val_acc: 0.7448\n",
      "Epoch 767/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.4246 - acc: 0.7865 - val_loss: 0.5193 - val_acc: 0.7448\n",
      "Epoch 768/1000\n",
      "576/576 [==============================] - 0s 120us/step - loss: 0.4245 - acc: 0.7865 - val_loss: 0.5193 - val_acc: 0.7448\n",
      "Epoch 769/1000\n",
      "576/576 [==============================] - 0s 111us/step - loss: 0.4245 - acc: 0.7865 - val_loss: 0.5193 - val_acc: 0.7448\n",
      "Epoch 770/1000\n",
      "576/576 [==============================] - 0s 126us/step - loss: 0.4245 - acc: 0.7865 - val_loss: 0.5193 - val_acc: 0.7448\n",
      "Epoch 771/1000\n",
      "576/576 [==============================] - 0s 108us/step - loss: 0.4245 - acc: 0.7865 - val_loss: 0.5194 - val_acc: 0.7448\n",
      "Epoch 772/1000\n",
      "576/576 [==============================] - 0s 157us/step - loss: 0.4244 - acc: 0.7865 - val_loss: 0.5194 - val_acc: 0.7448\n",
      "Epoch 773/1000\n",
      "576/576 [==============================] - 0s 117us/step - loss: 0.4244 - acc: 0.7865 - val_loss: 0.5194 - val_acc: 0.7448\n",
      "Epoch 774/1000\n",
      "576/576 [==============================] - 0s 94us/step - loss: 0.4244 - acc: 0.7865 - val_loss: 0.5194 - val_acc: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 775/1000\n",
      "576/576 [==============================] - 0s 103us/step - loss: 0.4244 - acc: 0.7865 - val_loss: 0.5194 - val_acc: 0.7448\n",
      "Epoch 776/1000\n",
      "576/576 [==============================] - 0s 72us/step - loss: 0.4244 - acc: 0.7865 - val_loss: 0.5194 - val_acc: 0.7448\n",
      "Epoch 777/1000\n",
      "576/576 [==============================] - 0s 86us/step - loss: 0.4243 - acc: 0.7865 - val_loss: 0.5194 - val_acc: 0.7448\n",
      "Epoch 778/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4243 - acc: 0.7865 - val_loss: 0.5194 - val_acc: 0.7448\n",
      "Epoch 779/1000\n",
      "576/576 [==============================] - 0s 86us/step - loss: 0.4243 - acc: 0.7865 - val_loss: 0.5194 - val_acc: 0.7448\n",
      "Epoch 780/1000\n",
      "576/576 [==============================] - 0s 86us/step - loss: 0.4243 - acc: 0.7865 - val_loss: 0.5194 - val_acc: 0.7448\n",
      "Epoch 781/1000\n",
      "576/576 [==============================] - 0s 86us/step - loss: 0.4242 - acc: 0.7865 - val_loss: 0.5194 - val_acc: 0.7448\n",
      "Epoch 782/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4242 - acc: 0.7865 - val_loss: 0.5195 - val_acc: 0.7448\n",
      "Epoch 783/1000\n",
      "576/576 [==============================] - 0s 94us/step - loss: 0.4242 - acc: 0.7865 - val_loss: 0.5195 - val_acc: 0.7448\n",
      "Epoch 784/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4242 - acc: 0.7865 - val_loss: 0.5195 - val_acc: 0.7448\n",
      "Epoch 785/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4242 - acc: 0.7865 - val_loss: 0.5195 - val_acc: 0.7448\n",
      "Epoch 786/1000\n",
      "576/576 [==============================] - 0s 68us/step - loss: 0.4241 - acc: 0.7865 - val_loss: 0.5195 - val_acc: 0.7448\n",
      "Epoch 787/1000\n",
      "576/576 [==============================] - 0s 93us/step - loss: 0.4241 - acc: 0.7865 - val_loss: 0.5195 - val_acc: 0.7448\n",
      "Epoch 788/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4241 - acc: 0.7865 - val_loss: 0.5195 - val_acc: 0.7448\n",
      "Epoch 789/1000\n",
      "576/576 [==============================] - 0s 83us/step - loss: 0.4241 - acc: 0.7865 - val_loss: 0.5196 - val_acc: 0.7448\n",
      "Epoch 790/1000\n",
      "576/576 [==============================] - 0s 84us/step - loss: 0.4240 - acc: 0.7865 - val_loss: 0.5196 - val_acc: 0.7448\n",
      "Epoch 791/1000\n",
      "576/576 [==============================] - 0s 84us/step - loss: 0.4240 - acc: 0.7865 - val_loss: 0.5196 - val_acc: 0.7448\n",
      "Epoch 792/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4240 - acc: 0.7865 - val_loss: 0.5196 - val_acc: 0.7448\n",
      "Epoch 793/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4240 - acc: 0.7865 - val_loss: 0.5196 - val_acc: 0.7448\n",
      "Epoch 794/1000\n",
      "576/576 [==============================] - 0s 93us/step - loss: 0.4239 - acc: 0.7865 - val_loss: 0.5197 - val_acc: 0.7448\n",
      "Epoch 795/1000\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.4239 - acc: 0.7865 - val_loss: 0.5197 - val_acc: 0.7448\n",
      "Epoch 796/1000\n",
      "576/576 [==============================] - 0s 91us/step - loss: 0.4239 - acc: 0.7865 - val_loss: 0.5197 - val_acc: 0.7448\n",
      "Epoch 797/1000\n",
      "576/576 [==============================] - 0s 72us/step - loss: 0.4239 - acc: 0.7865 - val_loss: 0.5197 - val_acc: 0.7448\n",
      "Epoch 798/1000\n",
      "576/576 [==============================] - 0s 93us/step - loss: 0.4238 - acc: 0.7865 - val_loss: 0.5197 - val_acc: 0.7448\n",
      "Epoch 799/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4238 - acc: 0.7865 - val_loss: 0.5197 - val_acc: 0.7448\n",
      "Epoch 800/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4238 - acc: 0.7865 - val_loss: 0.5198 - val_acc: 0.7448\n",
      "Epoch 801/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4237 - acc: 0.7865 - val_loss: 0.5198 - val_acc: 0.7448\n",
      "Epoch 802/1000\n",
      "576/576 [==============================] - 0s 73us/step - loss: 0.4237 - acc: 0.7865 - val_loss: 0.5198 - val_acc: 0.7448\n",
      "Epoch 803/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4237 - acc: 0.7865 - val_loss: 0.5198 - val_acc: 0.7448\n",
      "Epoch 804/1000\n",
      "576/576 [==============================] - 0s 90us/step - loss: 0.4237 - acc: 0.7865 - val_loss: 0.5198 - val_acc: 0.7448\n",
      "Epoch 805/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4237 - acc: 0.7865 - val_loss: 0.5198 - val_acc: 0.7448\n",
      "Epoch 806/1000\n",
      "576/576 [==============================] - 0s 94us/step - loss: 0.4236 - acc: 0.7865 - val_loss: 0.5198 - val_acc: 0.7448\n",
      "Epoch 807/1000\n",
      "576/576 [==============================] - 0s 98us/step - loss: 0.4236 - acc: 0.7865 - val_loss: 0.5199 - val_acc: 0.7448\n",
      "Epoch 808/1000\n",
      "576/576 [==============================] - 0s 150us/step - loss: 0.4236 - acc: 0.7865 - val_loss: 0.5199 - val_acc: 0.7448\n",
      "Epoch 809/1000\n",
      "576/576 [==============================] - 0s 155us/step - loss: 0.4236 - acc: 0.7865 - val_loss: 0.5199 - val_acc: 0.7448\n",
      "Epoch 810/1000\n",
      "576/576 [==============================] - 0s 149us/step - loss: 0.4235 - acc: 0.7865 - val_loss: 0.5199 - val_acc: 0.7448\n",
      "Epoch 811/1000\n",
      "576/576 [==============================] - 0s 129us/step - loss: 0.4235 - acc: 0.7865 - val_loss: 0.5199 - val_acc: 0.7448\n",
      "Epoch 812/1000\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.4235 - acc: 0.7865 - val_loss: 0.5199 - val_acc: 0.7448\n",
      "Epoch 813/1000\n",
      "576/576 [==============================] - 0s 128us/step - loss: 0.4234 - acc: 0.7865 - val_loss: 0.5200 - val_acc: 0.7448\n",
      "Epoch 814/1000\n",
      "576/576 [==============================] - 0s 112us/step - loss: 0.4234 - acc: 0.7865 - val_loss: 0.5200 - val_acc: 0.7448\n",
      "Epoch 815/1000\n",
      "576/576 [==============================] - 0s 111us/step - loss: 0.4234 - acc: 0.7865 - val_loss: 0.5200 - val_acc: 0.7448\n",
      "Epoch 816/1000\n",
      "576/576 [==============================] - 0s 117us/step - loss: 0.4234 - acc: 0.7865 - val_loss: 0.5200 - val_acc: 0.7448\n",
      "Epoch 817/1000\n",
      "576/576 [==============================] - 0s 118us/step - loss: 0.4233 - acc: 0.7865 - val_loss: 0.5200 - val_acc: 0.7448\n",
      "Epoch 818/1000\n",
      "576/576 [==============================] - 0s 123us/step - loss: 0.4233 - acc: 0.7865 - val_loss: 0.5200 - val_acc: 0.7448\n",
      "Epoch 819/1000\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4233 - acc: 0.7865 - val_loss: 0.5200 - val_acc: 0.7448\n",
      "Epoch 820/1000\n",
      "576/576 [==============================] - 0s 150us/step - loss: 0.4233 - acc: 0.7865 - val_loss: 0.5200 - val_acc: 0.7448\n",
      "Epoch 821/1000\n",
      "576/576 [==============================] - 0s 141us/step - loss: 0.4232 - acc: 0.7865 - val_loss: 0.5201 - val_acc: 0.7448\n",
      "Epoch 822/1000\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4232 - acc: 0.7865 - val_loss: 0.5201 - val_acc: 0.7448\n",
      "Epoch 823/1000\n",
      "576/576 [==============================] - 0s 104us/step - loss: 0.4232 - acc: 0.7865 - val_loss: 0.5201 - val_acc: 0.7448\n",
      "Epoch 824/1000\n",
      "576/576 [==============================] - 0s 108us/step - loss: 0.4231 - acc: 0.7865 - val_loss: 0.5201 - val_acc: 0.7448\n",
      "Epoch 825/1000\n",
      "576/576 [==============================] - 0s 85us/step - loss: 0.4231 - acc: 0.7865 - val_loss: 0.5201 - val_acc: 0.7448\n",
      "Epoch 826/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.4231 - acc: 0.7865 - val_loss: 0.5201 - val_acc: 0.7448\n",
      "Epoch 827/1000\n",
      "576/576 [==============================] - 0s 86us/step - loss: 0.4231 - acc: 0.7865 - val_loss: 0.5202 - val_acc: 0.7448\n",
      "Epoch 828/1000\n",
      "576/576 [==============================] - 0s 102us/step - loss: 0.4231 - acc: 0.7865 - val_loss: 0.5202 - val_acc: 0.7448\n",
      "Epoch 829/1000\n",
      "576/576 [==============================] - 0s 92us/step - loss: 0.4230 - acc: 0.7865 - val_loss: 0.5202 - val_acc: 0.7448\n",
      "Epoch 830/1000\n",
      "576/576 [==============================] - 0s 145us/step - loss: 0.4230 - acc: 0.7865 - val_loss: 0.5202 - val_acc: 0.7448\n",
      "Epoch 831/1000\n",
      "576/576 [==============================] - 0s 171us/step - loss: 0.4230 - acc: 0.7865 - val_loss: 0.5202 - val_acc: 0.7448\n",
      "Epoch 832/1000\n",
      "576/576 [==============================] - 0s 189us/step - loss: 0.4230 - acc: 0.7865 - val_loss: 0.5202 - val_acc: 0.7448\n",
      "Epoch 833/1000\n",
      "576/576 [==============================] - 0s 167us/step - loss: 0.4229 - acc: 0.7865 - val_loss: 0.5202 - val_acc: 0.7448\n",
      "Epoch 834/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 180us/step - loss: 0.4229 - acc: 0.7882 - val_loss: 0.5202 - val_acc: 0.7448\n",
      "Epoch 835/1000\n",
      "576/576 [==============================] - 0s 100us/step - loss: 0.4229 - acc: 0.7899 - val_loss: 0.5202 - val_acc: 0.7448\n",
      "Epoch 836/1000\n",
      "576/576 [==============================] - 0s 140us/step - loss: 0.4229 - acc: 0.7899 - val_loss: 0.5202 - val_acc: 0.7448\n",
      "Epoch 837/1000\n",
      "576/576 [==============================] - 0s 122us/step - loss: 0.4229 - acc: 0.7865 - val_loss: 0.5203 - val_acc: 0.7448\n",
      "Epoch 838/1000\n",
      "576/576 [==============================] - 0s 106us/step - loss: 0.4228 - acc: 0.7865 - val_loss: 0.5203 - val_acc: 0.7448\n",
      "Epoch 839/1000\n",
      "576/576 [==============================] - 0s 123us/step - loss: 0.4228 - acc: 0.7899 - val_loss: 0.5203 - val_acc: 0.7448\n",
      "Epoch 840/1000\n",
      "576/576 [==============================] - 0s 148us/step - loss: 0.4228 - acc: 0.7882 - val_loss: 0.5203 - val_acc: 0.7448\n",
      "Epoch 841/1000\n",
      "576/576 [==============================] - 0s 123us/step - loss: 0.4228 - acc: 0.7882 - val_loss: 0.5203 - val_acc: 0.7448\n",
      "Epoch 842/1000\n",
      "576/576 [==============================] - 0s 131us/step - loss: 0.4227 - acc: 0.7917 - val_loss: 0.5203 - val_acc: 0.7448\n",
      "Epoch 843/1000\n",
      "576/576 [==============================] - 0s 131us/step - loss: 0.4227 - acc: 0.7917 - val_loss: 0.5203 - val_acc: 0.7448\n",
      "Epoch 844/1000\n",
      "576/576 [==============================] - 0s 129us/step - loss: 0.4227 - acc: 0.7899 - val_loss: 0.5203 - val_acc: 0.7448\n",
      "Epoch 845/1000\n",
      "576/576 [==============================] - 0s 124us/step - loss: 0.4227 - acc: 0.7917 - val_loss: 0.5203 - val_acc: 0.7448\n",
      "Epoch 846/1000\n",
      "576/576 [==============================] - 0s 102us/step - loss: 0.4226 - acc: 0.7899 - val_loss: 0.5203 - val_acc: 0.7448\n",
      "Epoch 847/1000\n",
      "576/576 [==============================] - 0s 146us/step - loss: 0.4226 - acc: 0.7882 - val_loss: 0.5203 - val_acc: 0.7448\n",
      "Epoch 848/1000\n",
      "576/576 [==============================] - 0s 152us/step - loss: 0.4226 - acc: 0.7899 - val_loss: 0.5203 - val_acc: 0.7448\n",
      "Epoch 849/1000\n",
      "576/576 [==============================] - 0s 91us/step - loss: 0.4225 - acc: 0.7917 - val_loss: 0.5204 - val_acc: 0.7448\n",
      "Epoch 850/1000\n",
      "576/576 [==============================] - 0s 122us/step - loss: 0.4225 - acc: 0.7899 - val_loss: 0.5204 - val_acc: 0.7448\n",
      "Epoch 851/1000\n",
      "576/576 [==============================] - 0s 116us/step - loss: 0.4225 - acc: 0.7917 - val_loss: 0.5204 - val_acc: 0.7448\n",
      "Epoch 852/1000\n",
      "576/576 [==============================] - 0s 102us/step - loss: 0.4225 - acc: 0.7917 - val_loss: 0.5204 - val_acc: 0.7448\n",
      "Epoch 853/1000\n",
      "576/576 [==============================] - 0s 157us/step - loss: 0.4224 - acc: 0.7917 - val_loss: 0.5204 - val_acc: 0.7448\n",
      "Epoch 854/1000\n",
      "576/576 [==============================] - 0s 149us/step - loss: 0.4224 - acc: 0.7917 - val_loss: 0.5204 - val_acc: 0.7448\n",
      "Epoch 855/1000\n",
      "576/576 [==============================] - 0s 154us/step - loss: 0.4224 - acc: 0.7934 - val_loss: 0.5204 - val_acc: 0.7448\n",
      "Epoch 856/1000\n",
      "576/576 [==============================] - 0s 151us/step - loss: 0.4224 - acc: 0.7917 - val_loss: 0.5204 - val_acc: 0.7448\n",
      "Epoch 857/1000\n",
      "576/576 [==============================] - 0s 159us/step - loss: 0.4223 - acc: 0.7934 - val_loss: 0.5204 - val_acc: 0.7448\n",
      "Epoch 858/1000\n",
      "576/576 [==============================] - 0s 158us/step - loss: 0.4223 - acc: 0.7934 - val_loss: 0.5204 - val_acc: 0.7448\n",
      "Epoch 859/1000\n",
      "576/576 [==============================] - 0s 147us/step - loss: 0.4223 - acc: 0.7934 - val_loss: 0.5204 - val_acc: 0.7448\n",
      "Epoch 860/1000\n",
      "576/576 [==============================] - 0s 164us/step - loss: 0.4223 - acc: 0.7934 - val_loss: 0.5205 - val_acc: 0.7448\n",
      "Epoch 861/1000\n",
      "576/576 [==============================] - 0s 143us/step - loss: 0.4223 - acc: 0.7934 - val_loss: 0.5205 - val_acc: 0.7448\n",
      "Epoch 862/1000\n",
      "576/576 [==============================] - 0s 175us/step - loss: 0.4222 - acc: 0.7917 - val_loss: 0.5205 - val_acc: 0.7448\n",
      "Epoch 863/1000\n",
      "576/576 [==============================] - 0s 145us/step - loss: 0.4222 - acc: 0.7917 - val_loss: 0.5205 - val_acc: 0.7448\n",
      "Epoch 864/1000\n",
      "576/576 [==============================] - 0s 140us/step - loss: 0.4222 - acc: 0.7934 - val_loss: 0.5205 - val_acc: 0.7448\n",
      "Epoch 865/1000\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4222 - acc: 0.7917 - val_loss: 0.5205 - val_acc: 0.7448\n",
      "Epoch 866/1000\n",
      "576/576 [==============================] - 0s 161us/step - loss: 0.4221 - acc: 0.7934 - val_loss: 0.5205 - val_acc: 0.7448\n",
      "Epoch 867/1000\n",
      "576/576 [==============================] - 0s 166us/step - loss: 0.4221 - acc: 0.7934 - val_loss: 0.5205 - val_acc: 0.7448\n",
      "Epoch 868/1000\n",
      "576/576 [==============================] - 0s 133us/step - loss: 0.4221 - acc: 0.7917 - val_loss: 0.5205 - val_acc: 0.7448\n",
      "Epoch 869/1000\n",
      "576/576 [==============================] - 0s 129us/step - loss: 0.4221 - acc: 0.7934 - val_loss: 0.5206 - val_acc: 0.7448\n",
      "Epoch 870/1000\n",
      "576/576 [==============================] - 0s 122us/step - loss: 0.4221 - acc: 0.7934 - val_loss: 0.5206 - val_acc: 0.7448\n",
      "Epoch 871/1000\n",
      "576/576 [==============================] - 0s 159us/step - loss: 0.4220 - acc: 0.7917 - val_loss: 0.5206 - val_acc: 0.7448\n",
      "Epoch 872/1000\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4220 - acc: 0.7917 - val_loss: 0.5206 - val_acc: 0.7448\n",
      "Epoch 873/1000\n",
      "576/576 [==============================] - 0s 151us/step - loss: 0.4220 - acc: 0.7917 - val_loss: 0.5206 - val_acc: 0.7448\n",
      "Epoch 874/1000\n",
      "576/576 [==============================] - 0s 145us/step - loss: 0.4220 - acc: 0.7917 - val_loss: 0.5206 - val_acc: 0.7448\n",
      "Epoch 875/1000\n",
      "576/576 [==============================] - 0s 117us/step - loss: 0.4219 - acc: 0.7917 - val_loss: 0.5206 - val_acc: 0.7448\n",
      "Epoch 876/1000\n",
      "576/576 [==============================] - 0s 163us/step - loss: 0.4219 - acc: 0.7917 - val_loss: 0.5206 - val_acc: 0.7448\n",
      "Epoch 877/1000\n",
      "576/576 [==============================] - 0s 158us/step - loss: 0.4219 - acc: 0.7917 - val_loss: 0.5206 - val_acc: 0.7448\n",
      "Epoch 878/1000\n",
      "576/576 [==============================] - 0s 128us/step - loss: 0.4218 - acc: 0.7917 - val_loss: 0.5206 - val_acc: 0.7448\n",
      "Epoch 879/1000\n",
      "576/576 [==============================] - 0s 104us/step - loss: 0.4218 - acc: 0.7917 - val_loss: 0.5207 - val_acc: 0.7448\n",
      "Epoch 880/1000\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4218 - acc: 0.7917 - val_loss: 0.5207 - val_acc: 0.7448\n",
      "Epoch 881/1000\n",
      "576/576 [==============================] - 0s 153us/step - loss: 0.4218 - acc: 0.7917 - val_loss: 0.5207 - val_acc: 0.7448\n",
      "Epoch 882/1000\n",
      "576/576 [==============================] - 0s 161us/step - loss: 0.4218 - acc: 0.7917 - val_loss: 0.5207 - val_acc: 0.7448\n",
      "Epoch 883/1000\n",
      "576/576 [==============================] - 0s 158us/step - loss: 0.4217 - acc: 0.7917 - val_loss: 0.5207 - val_acc: 0.7448\n",
      "Epoch 884/1000\n",
      "576/576 [==============================] - 0s 165us/step - loss: 0.4217 - acc: 0.7917 - val_loss: 0.5207 - val_acc: 0.7448\n",
      "Epoch 885/1000\n",
      "576/576 [==============================] - 0s 163us/step - loss: 0.4217 - acc: 0.7917 - val_loss: 0.5207 - val_acc: 0.7448\n",
      "Epoch 886/1000\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4217 - acc: 0.7917 - val_loss: 0.5207 - val_acc: 0.7448\n",
      "Epoch 887/1000\n",
      "576/576 [==============================] - 0s 91us/step - loss: 0.4216 - acc: 0.7917 - val_loss: 0.5207 - val_acc: 0.7448\n",
      "Epoch 888/1000\n",
      "576/576 [==============================] - 0s 105us/step - loss: 0.4216 - acc: 0.7917 - val_loss: 0.5208 - val_acc: 0.7448\n",
      "Epoch 889/1000\n",
      "576/576 [==============================] - 0s 83us/step - loss: 0.4216 - acc: 0.7917 - val_loss: 0.5208 - val_acc: 0.7448\n",
      "Epoch 890/1000\n",
      "576/576 [==============================] - 0s 100us/step - loss: 0.4215 - acc: 0.7917 - val_loss: 0.5208 - val_acc: 0.7448\n",
      "Epoch 891/1000\n",
      "576/576 [==============================] - 0s 101us/step - loss: 0.4215 - acc: 0.7917 - val_loss: 0.5208 - val_acc: 0.7448\n",
      "Epoch 892/1000\n",
      "576/576 [==============================] - 0s 110us/step - loss: 0.4215 - acc: 0.7917 - val_loss: 0.5208 - val_acc: 0.7448\n",
      "Epoch 893/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 135us/step - loss: 0.4215 - acc: 0.7917 - val_loss: 0.5209 - val_acc: 0.7448\n",
      "Epoch 894/1000\n",
      "576/576 [==============================] - 0s 91us/step - loss: 0.4215 - acc: 0.7917 - val_loss: 0.5209 - val_acc: 0.7448\n",
      "Epoch 895/1000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.4214 - acc: 0.7917 - val_loss: 0.5209 - val_acc: 0.7448\n",
      "Epoch 896/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4214 - acc: 0.7917 - val_loss: 0.5209 - val_acc: 0.7448\n",
      "Epoch 897/1000\n",
      "576/576 [==============================] - 0s 90us/step - loss: 0.4214 - acc: 0.7917 - val_loss: 0.5209 - val_acc: 0.7448\n",
      "Epoch 898/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4214 - acc: 0.7917 - val_loss: 0.5209 - val_acc: 0.7448\n",
      "Epoch 899/1000\n",
      "576/576 [==============================] - 0s 91us/step - loss: 0.4213 - acc: 0.7917 - val_loss: 0.5209 - val_acc: 0.7448\n",
      "Epoch 900/1000\n",
      "576/576 [==============================] - 0s 106us/step - loss: 0.4213 - acc: 0.7917 - val_loss: 0.5209 - val_acc: 0.7448\n",
      "Epoch 901/1000\n",
      "576/576 [==============================] - 0s 82us/step - loss: 0.4213 - acc: 0.7917 - val_loss: 0.5209 - val_acc: 0.7448\n",
      "Epoch 902/1000\n",
      "576/576 [==============================] - 0s 115us/step - loss: 0.4213 - acc: 0.7917 - val_loss: 0.5209 - val_acc: 0.7448\n",
      "Epoch 903/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.4212 - acc: 0.7917 - val_loss: 0.5209 - val_acc: 0.7448\n",
      "Epoch 904/1000\n",
      "576/576 [==============================] - 0s 82us/step - loss: 0.4213 - acc: 0.7917 - val_loss: 0.5209 - val_acc: 0.7448\n",
      "Epoch 905/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4212 - acc: 0.7917 - val_loss: 0.5209 - val_acc: 0.7448\n",
      "Epoch 906/1000\n",
      "576/576 [==============================] - 0s 87us/step - loss: 0.4212 - acc: 0.7917 - val_loss: 0.5210 - val_acc: 0.7448\n",
      "Epoch 907/1000\n",
      "576/576 [==============================] - 0s 84us/step - loss: 0.4211 - acc: 0.7917 - val_loss: 0.5210 - val_acc: 0.7448\n",
      "Epoch 908/1000\n",
      "576/576 [==============================] - 0s 89us/step - loss: 0.4212 - acc: 0.7917 - val_loss: 0.5210 - val_acc: 0.7448\n",
      "Epoch 909/1000\n",
      "576/576 [==============================] - 0s 82us/step - loss: 0.4211 - acc: 0.7917 - val_loss: 0.5210 - val_acc: 0.7448\n",
      "Epoch 910/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.4211 - acc: 0.7917 - val_loss: 0.5210 - val_acc: 0.7448\n",
      "Epoch 911/1000\n",
      "576/576 [==============================] - 0s 74us/step - loss: 0.4210 - acc: 0.7917 - val_loss: 0.5210 - val_acc: 0.7448\n",
      "Epoch 912/1000\n",
      "576/576 [==============================] - 0s 111us/step - loss: 0.4210 - acc: 0.7917 - val_loss: 0.5210 - val_acc: 0.7448\n",
      "Epoch 913/1000\n",
      "576/576 [==============================] - 0s 82us/step - loss: 0.4210 - acc: 0.7917 - val_loss: 0.5210 - val_acc: 0.7448\n",
      "Epoch 914/1000\n",
      "576/576 [==============================] - 0s 84us/step - loss: 0.4210 - acc: 0.7917 - val_loss: 0.5210 - val_acc: 0.7448\n",
      "Epoch 915/1000\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.4210 - acc: 0.7917 - val_loss: 0.5210 - val_acc: 0.7448\n",
      "Epoch 916/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4209 - acc: 0.7917 - val_loss: 0.5210 - val_acc: 0.7448\n",
      "Epoch 917/1000\n",
      "576/576 [==============================] - 0s 89us/step - loss: 0.4209 - acc: 0.7917 - val_loss: 0.5210 - val_acc: 0.7448\n",
      "Epoch 918/1000\n",
      "576/576 [==============================] - 0s 141us/step - loss: 0.4209 - acc: 0.7917 - val_loss: 0.5211 - val_acc: 0.7448\n",
      "Epoch 919/1000\n",
      "576/576 [==============================] - 0s 109us/step - loss: 0.4209 - acc: 0.7917 - val_loss: 0.5211 - val_acc: 0.7448\n",
      "Epoch 920/1000\n",
      "576/576 [==============================] - 0s 203us/step - loss: 0.4208 - acc: 0.7917 - val_loss: 0.5211 - val_acc: 0.7448\n",
      "Epoch 921/1000\n",
      "576/576 [==============================] - 0s 185us/step - loss: 0.4208 - acc: 0.7917 - val_loss: 0.5211 - val_acc: 0.7448\n",
      "Epoch 922/1000\n",
      "576/576 [==============================] - 0s 173us/step - loss: 0.4208 - acc: 0.7917 - val_loss: 0.5211 - val_acc: 0.7448\n",
      "Epoch 923/1000\n",
      "576/576 [==============================] - 0s 103us/step - loss: 0.4208 - acc: 0.7917 - val_loss: 0.5211 - val_acc: 0.7448\n",
      "Epoch 924/1000\n",
      "576/576 [==============================] - 0s 142us/step - loss: 0.4207 - acc: 0.7917 - val_loss: 0.5211 - val_acc: 0.7448\n",
      "Epoch 925/1000\n",
      "576/576 [==============================] - 0s 140us/step - loss: 0.4207 - acc: 0.7917 - val_loss: 0.5211 - val_acc: 0.7448\n",
      "Epoch 926/1000\n",
      "576/576 [==============================] - 0s 169us/step - loss: 0.4207 - acc: 0.7934 - val_loss: 0.5211 - val_acc: 0.7448\n",
      "Epoch 927/1000\n",
      "576/576 [==============================] - 0s 158us/step - loss: 0.4207 - acc: 0.7934 - val_loss: 0.5211 - val_acc: 0.7448\n",
      "Epoch 928/1000\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4206 - acc: 0.7934 - val_loss: 0.5211 - val_acc: 0.7448\n",
      "Epoch 929/1000\n",
      "576/576 [==============================] - 0s 216us/step - loss: 0.4206 - acc: 0.7934 - val_loss: 0.5211 - val_acc: 0.7448\n",
      "Epoch 930/1000\n",
      "576/576 [==============================] - 0s 169us/step - loss: 0.4206 - acc: 0.7934 - val_loss: 0.5212 - val_acc: 0.7448\n",
      "Epoch 931/1000\n",
      "576/576 [==============================] - 0s 147us/step - loss: 0.4206 - acc: 0.7934 - val_loss: 0.5212 - val_acc: 0.7448\n",
      "Epoch 932/1000\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4206 - acc: 0.7934 - val_loss: 0.5212 - val_acc: 0.7448\n",
      "Epoch 933/1000\n",
      "576/576 [==============================] - 0s 176us/step - loss: 0.4205 - acc: 0.7934 - val_loss: 0.5212 - val_acc: 0.7448\n",
      "Epoch 934/1000\n",
      "576/576 [==============================] - 0s 160us/step - loss: 0.4205 - acc: 0.7934 - val_loss: 0.5212 - val_acc: 0.7448\n",
      "Epoch 935/1000\n",
      "576/576 [==============================] - 0s 169us/step - loss: 0.4205 - acc: 0.7934 - val_loss: 0.5212 - val_acc: 0.7448\n",
      "Epoch 936/1000\n",
      "576/576 [==============================] - 0s 115us/step - loss: 0.4205 - acc: 0.7934 - val_loss: 0.5212 - val_acc: 0.7448\n",
      "Epoch 937/1000\n",
      "576/576 [==============================] - 0s 158us/step - loss: 0.4204 - acc: 0.7934 - val_loss: 0.5212 - val_acc: 0.7448\n",
      "Epoch 938/1000\n",
      "576/576 [==============================] - 0s 163us/step - loss: 0.4204 - acc: 0.7934 - val_loss: 0.5212 - val_acc: 0.7448\n",
      "Epoch 939/1000\n",
      "576/576 [==============================] - 0s 147us/step - loss: 0.4204 - acc: 0.7934 - val_loss: 0.5212 - val_acc: 0.7448\n",
      "Epoch 940/1000\n",
      "576/576 [==============================] - 0s 160us/step - loss: 0.4204 - acc: 0.7934 - val_loss: 0.5212 - val_acc: 0.7448\n",
      "Epoch 941/1000\n",
      "576/576 [==============================] - 0s 173us/step - loss: 0.4203 - acc: 0.7934 - val_loss: 0.5213 - val_acc: 0.7448\n",
      "Epoch 942/1000\n",
      "576/576 [==============================] - 0s 176us/step - loss: 0.4203 - acc: 0.7934 - val_loss: 0.5213 - val_acc: 0.7448\n",
      "Epoch 943/1000\n",
      "576/576 [==============================] - 0s 153us/step - loss: 0.4203 - acc: 0.7934 - val_loss: 0.5213 - val_acc: 0.7448\n",
      "Epoch 944/1000\n",
      "576/576 [==============================] - 0s 146us/step - loss: 0.4203 - acc: 0.7934 - val_loss: 0.5213 - val_acc: 0.7448\n",
      "Epoch 945/1000\n",
      "576/576 [==============================] - 0s 150us/step - loss: 0.4203 - acc: 0.7934 - val_loss: 0.5213 - val_acc: 0.7448\n",
      "Epoch 946/1000\n",
      "576/576 [==============================] - 0s 126us/step - loss: 0.4202 - acc: 0.7934 - val_loss: 0.5213 - val_acc: 0.7448\n",
      "Epoch 947/1000\n",
      "576/576 [==============================] - 0s 183us/step - loss: 0.4202 - acc: 0.7934 - val_loss: 0.5213 - val_acc: 0.7448\n",
      "Epoch 948/1000\n",
      "576/576 [==============================] - 0s 141us/step - loss: 0.4202 - acc: 0.7934 - val_loss: 0.5213 - val_acc: 0.7448\n",
      "Epoch 949/1000\n",
      "576/576 [==============================] - 0s 154us/step - loss: 0.4202 - acc: 0.7917 - val_loss: 0.5213 - val_acc: 0.7448\n",
      "Epoch 950/1000\n",
      "576/576 [==============================] - 0s 165us/step - loss: 0.4202 - acc: 0.7917 - val_loss: 0.5213 - val_acc: 0.7448\n",
      "Epoch 951/1000\n",
      "576/576 [==============================] - 0s 168us/step - loss: 0.4201 - acc: 0.7934 - val_loss: 0.5213 - val_acc: 0.7448\n",
      "Epoch 952/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 96us/step - loss: 0.4201 - acc: 0.7934 - val_loss: 0.5213 - val_acc: 0.7448\n",
      "Epoch 953/1000\n",
      "576/576 [==============================] - 0s 100us/step - loss: 0.4201 - acc: 0.7917 - val_loss: 0.5214 - val_acc: 0.7448\n",
      "Epoch 954/1000\n",
      "576/576 [==============================] - 0s 92us/step - loss: 0.4201 - acc: 0.7917 - val_loss: 0.5214 - val_acc: 0.7448\n",
      "Epoch 955/1000\n",
      "576/576 [==============================] - 0s 86us/step - loss: 0.4200 - acc: 0.7917 - val_loss: 0.5214 - val_acc: 0.7448\n",
      "Epoch 956/1000\n",
      "576/576 [==============================] - 0s 88us/step - loss: 0.4200 - acc: 0.7917 - val_loss: 0.5214 - val_acc: 0.7448\n",
      "Epoch 957/1000\n",
      "576/576 [==============================] - 0s 91us/step - loss: 0.4200 - acc: 0.7917 - val_loss: 0.5214 - val_acc: 0.7448\n",
      "Epoch 958/1000\n",
      "576/576 [==============================] - 0s 102us/step - loss: 0.4200 - acc: 0.7917 - val_loss: 0.5214 - val_acc: 0.7448\n",
      "Epoch 959/1000\n",
      "576/576 [==============================] - 0s 92us/step - loss: 0.4199 - acc: 0.7917 - val_loss: 0.5214 - val_acc: 0.7448\n",
      "Epoch 960/1000\n",
      "576/576 [==============================] - 0s 83us/step - loss: 0.4199 - acc: 0.7917 - val_loss: 0.5214 - val_acc: 0.7448\n",
      "Epoch 961/1000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.4199 - acc: 0.7917 - val_loss: 0.5215 - val_acc: 0.7448\n",
      "Epoch 962/1000\n",
      "576/576 [==============================] - 0s 85us/step - loss: 0.4199 - acc: 0.7917 - val_loss: 0.5215 - val_acc: 0.7448\n",
      "Epoch 963/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4198 - acc: 0.7917 - val_loss: 0.5215 - val_acc: 0.7448\n",
      "Epoch 964/1000\n",
      "576/576 [==============================] - 0s 90us/step - loss: 0.4198 - acc: 0.7917 - val_loss: 0.5215 - val_acc: 0.7448\n",
      "Epoch 965/1000\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.4198 - acc: 0.7917 - val_loss: 0.5215 - val_acc: 0.7448\n",
      "Epoch 966/1000\n",
      "576/576 [==============================] - 0s 91us/step - loss: 0.4198 - acc: 0.7917 - val_loss: 0.5215 - val_acc: 0.7448\n",
      "Epoch 967/1000\n",
      "576/576 [==============================] - 0s 85us/step - loss: 0.4197 - acc: 0.7917 - val_loss: 0.5215 - val_acc: 0.7448\n",
      "Epoch 968/1000\n",
      "576/576 [==============================] - 0s 104us/step - loss: 0.4197 - acc: 0.7917 - val_loss: 0.5215 - val_acc: 0.7448\n",
      "Epoch 969/1000\n",
      "576/576 [==============================] - 0s 130us/step - loss: 0.4197 - acc: 0.7917 - val_loss: 0.5215 - val_acc: 0.7448\n",
      "Epoch 970/1000\n",
      "576/576 [==============================] - 0s 108us/step - loss: 0.4197 - acc: 0.7917 - val_loss: 0.5215 - val_acc: 0.7448\n",
      "Epoch 971/1000\n",
      "576/576 [==============================] - 0s 118us/step - loss: 0.4196 - acc: 0.7917 - val_loss: 0.5215 - val_acc: 0.7448\n",
      "Epoch 972/1000\n",
      "576/576 [==============================] - 0s 117us/step - loss: 0.4196 - acc: 0.7917 - val_loss: 0.5215 - val_acc: 0.7448\n",
      "Epoch 973/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4196 - acc: 0.7917 - val_loss: 0.5215 - val_acc: 0.7448\n",
      "Epoch 974/1000\n",
      "576/576 [==============================] - 0s 107us/step - loss: 0.4196 - acc: 0.7917 - val_loss: 0.5215 - val_acc: 0.7448\n",
      "Epoch 975/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4196 - acc: 0.7917 - val_loss: 0.5215 - val_acc: 0.7448\n",
      "Epoch 976/1000\n",
      "576/576 [==============================] - 0s 91us/step - loss: 0.4196 - acc: 0.7917 - val_loss: 0.5216 - val_acc: 0.7448\n",
      "Epoch 977/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4195 - acc: 0.7917 - val_loss: 0.5216 - val_acc: 0.7448\n",
      "Epoch 978/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4195 - acc: 0.7917 - val_loss: 0.5216 - val_acc: 0.7448\n",
      "Epoch 979/1000\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.4195 - acc: 0.7917 - val_loss: 0.5216 - val_acc: 0.7448\n",
      "Epoch 980/1000\n",
      "576/576 [==============================] - 0s 89us/step - loss: 0.4195 - acc: 0.7917 - val_loss: 0.5216 - val_acc: 0.7448\n",
      "Epoch 981/1000\n",
      "576/576 [==============================] - 0s 89us/step - loss: 0.4194 - acc: 0.7917 - val_loss: 0.5216 - val_acc: 0.7448\n",
      "Epoch 982/1000\n",
      "576/576 [==============================] - 0s 85us/step - loss: 0.4194 - acc: 0.7917 - val_loss: 0.5216 - val_acc: 0.7448\n",
      "Epoch 983/1000\n",
      "576/576 [==============================] - 0s 82us/step - loss: 0.4194 - acc: 0.7917 - val_loss: 0.5216 - val_acc: 0.7448\n",
      "Epoch 984/1000\n",
      "576/576 [==============================] - 0s 86us/step - loss: 0.4194 - acc: 0.7917 - val_loss: 0.5216 - val_acc: 0.7448\n",
      "Epoch 985/1000\n",
      "576/576 [==============================] - 0s 84us/step - loss: 0.4194 - acc: 0.7917 - val_loss: 0.5216 - val_acc: 0.7448\n",
      "Epoch 986/1000\n",
      "576/576 [==============================] - 0s 86us/step - loss: 0.4193 - acc: 0.7917 - val_loss: 0.5217 - val_acc: 0.7448\n",
      "Epoch 987/1000\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.4193 - acc: 0.7917 - val_loss: 0.5216 - val_acc: 0.7448\n",
      "Epoch 988/1000\n",
      "576/576 [==============================] - 0s 91us/step - loss: 0.4193 - acc: 0.7917 - val_loss: 0.5217 - val_acc: 0.7448\n",
      "Epoch 989/1000\n",
      "576/576 [==============================] - 0s 84us/step - loss: 0.4193 - acc: 0.7917 - val_loss: 0.5217 - val_acc: 0.7448\n",
      "Epoch 990/1000\n",
      "576/576 [==============================] - 0s 91us/step - loss: 0.4192 - acc: 0.7917 - val_loss: 0.5217 - val_acc: 0.7448\n",
      "Epoch 991/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4192 - acc: 0.7917 - val_loss: 0.5217 - val_acc: 0.7448\n",
      "Epoch 992/1000\n",
      "576/576 [==============================] - 0s 84us/step - loss: 0.4192 - acc: 0.7917 - val_loss: 0.5217 - val_acc: 0.7448\n",
      "Epoch 993/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4192 - acc: 0.7917 - val_loss: 0.5217 - val_acc: 0.7448\n",
      "Epoch 994/1000\n",
      "576/576 [==============================] - 0s 90us/step - loss: 0.4191 - acc: 0.7917 - val_loss: 0.5217 - val_acc: 0.7448\n",
      "Epoch 995/1000\n",
      "576/576 [==============================] - 0s 90us/step - loss: 0.4191 - acc: 0.7917 - val_loss: 0.5217 - val_acc: 0.7448\n",
      "Epoch 996/1000\n",
      "576/576 [==============================] - 0s 87us/step - loss: 0.4191 - acc: 0.7917 - val_loss: 0.5217 - val_acc: 0.7448\n",
      "Epoch 997/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4191 - acc: 0.7917 - val_loss: 0.5217 - val_acc: 0.7448\n",
      "Epoch 998/1000\n",
      "576/576 [==============================] - 0s 86us/step - loss: 0.4190 - acc: 0.7917 - val_loss: 0.5217 - val_acc: 0.7396\n",
      "Epoch 999/1000\n",
      "576/576 [==============================] - 0s 85us/step - loss: 0.4190 - acc: 0.7917 - val_loss: 0.5217 - val_acc: 0.7396\n",
      "Epoch 1000/1000\n",
      "576/576 [==============================] - 0s 91us/step - loss: 0.4190 - acc: 0.7917 - val_loss: 0.5217 - val_acc: 0.7396\n"
     ]
    }
   ],
   "source": [
    "## Note that when we call \"fit\" again, it picks up where it left off\n",
    "run_hist_1b = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fc79fd3eb00>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6UAAAHVCAYAAAAJnF2uAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzs3Xt8VdWd9/HPzg0UuRguItIWbVXuhpgBjoIcwCoVCuhQK9ah4oVKx1KmlWodxltrVbSKPrV2VGofRiv10XqpisyUEtFOauUmtoBKrZeAUogaQdCQZD9/7JAL5HKSnHCS8Hm/Xnntvc/ZZ+11Qv7w61rrt4IwDJEkSZIkKRXSUt0BSZIkSdKhy1AqSZIkSUoZQ6kkSZIkKWUMpZIkSZKklDGUSpIkSZJSxlAqSZIkSUoZQ6kkSZIkKWUMpZIkSZKklDGUSpIkSZJSJiNVD+7Ro0fYr1+/VD1ekiRJktSCVq9evSMMw54N3ZeyUNqvXz9WrVqVqsdLkiRJklpQEARvJ3Kf03clSZIkSSljKJUkSZIkpYyhVJIkSZKUMilbUypJkiTp4Nq7dy+FhYV8+umnqe6K2pGOHTvSt29fMjMzm/R5Q6kkSZJ0iCgsLKRz587069ePIAhS3R21A2EYUlRURGFhIccee2yT2nD6riRJknSI+PTTT+nevbuBVEkTBAHdu3dv1ui7oVSSJEk6hBhIlWzN/ZsylEqSJEmSUsZQKkmSJOmgKCoqIicnh5ycHHr37s0xxxxTeV1SUpJQGzNnzuS1115L+Jn3338/c+fObWqXm23+/PmV33PgwIE88sgjSWv7zjvv5Itf/CJBEPDRRx8lrd2DzUJHkiRJkupWUAD5+RCPQyzWrKa6d+/OunXrALjuuus44ogjuOKKK2rcE4YhYRiSllb7+NkDDzzQrD6kwrx585g7dy6bNm1ixIgR/PM//zPp6enNbve0005j6tSpnHrqqUnoZeoYSiVJkqRD0dy5UBEQ61RcDOvXQ3k5pKXB0KHQtWvd9+fkwMKFje7K5s2bmTx5MsOGDWPt2rX8z//8D9dffz1r1qxhz549fP3rX+eaa64BYNSoUfzsZz9j8ODB9OjRg8suu4ylS5dy+OGH8+STT9KrV6+Envnggw9yyy23EIYhkydP5ic/+QmlpaXMnDmTdevWEYYhs2bNYs6cOdxxxx3cd999ZGRkMHToUB588MFGf0eA/v37k5mZSXFxMdnZ2ZXfJScnh/fff59Ro0axefNm7r//fp577jl27tzJm2++ybRp07jpppsOaG/YsGFN6kdrk1AoDYJgAnAnkA7cH4bhzfu9/wXgl0BP4APggjAMC5PcV0mSJEkHU3FxFEghOhYX1x9Km2HTpk0sXryYvLw8AG6++Ways7MpLS1l7NixTJs2jYEDB+7XvWLGjBnDzTffzPe+9z1++ctfctVVVzX4rMLCQubPn8+qVavo2rUrp59+Ok8//TQ9e/Zkx44dvPrqqwCVU2IXLFjA22+/TVZWVrOmyb788ssMHjyY7OzsBu995ZVXWL16NZmZmZxwwgl85zvfoU+fPk1+dmvWYCgNgiAduBv4MlAIvBwEwVNhGG6odtttwOIwDP9vEATjgJuAf2mJDkuSJElKgkRGNAsKYPx4KCmBrCx46KFmT+Gtyxe/+MXKQArw8MMPs2jRIkpLS9m6dSsbNmw4IJQedthhfOUrXwHg5JNP5oUXXkjoWS+99BLjxo2jR48eAJx//vmsXLmSK6+8ktdee405c+YwceJEzjjjDAAGDRrEBRdcwJQpU5g6dWqjv9utt97KvffeyxtvvMGzzz6b0GdOP/10unTpAkQjrO+88067DaWJFDoaDmwOw/DNMAxLgCXAlP3uGQj8oeJ8RS3vS5IkSWprYjFYvhx+9KPo2EKBFKBTp06V52+88QZ33nknf/jDH1i/fj0TJkyodR/MrKysyvP09HRKS0ub1Yfu3buzfv16Ro8ezd133823vvUtAJYtW8Zll13Gyy+/zPDhwykrK6vxuRkzZpCTk8PkyZNrbXfevHls2LCB3/zmN1x88cV89tlnAGRkZFBeMRK9//fr0KFDUr9ba5ZIKD0GeLfadWHFa9W9ApxTcX420DkIgu77NxQEwawgCFYFQbBq+/btTemvJEmSpIMpFoMf/rBFA+n+Pv74Yzp37kyXLl147733WLZsWVLbHzFiBCtWrKCoqIjS0lKWLFnCmDFj2L59O2EY8rWvfY0bbriBNWvWUFZWRmFhIePGjWPBggXs2LGD3bt312hv8eLFrFu3jqeeeqre555zzjkMGTKkck1qv379WL16NQCPPvpoUr9jW5KsLWGuAMYEQbAWGANsAcr2vykMw3vDMMwLwzCvZ8+eSXq0JEmSpPYkNzeXgQMH0r9/f2bMmNHs6rKLFi2ib9++lT8ZGRn86Ec/Ih6Pk5OTw8iRI5k4cSLvvvsup512Gjk5OcycObOy+NH555/P0KFDyc3N5YorrqBz585N7ss111zDT3/6U8IwZN68edx5553k5uby4YcfNrqt22+/nb59+/L+++8zaNCgypHdtiYIw7D+G4IgBlwXhuGZFdc/BAjD8MDyT9H7RwCbwjDsW1+7eXl54apVq5rU6ZYWhvD730dT6L/85YP6P4UkSZKkFrNx40YGDBiQ6m6oHartbysIgtVhGObV8ZFKiYyUvgwcHwTBsUEQZAHnATXGpYMg6BEEwb62fkhUibfNeuopOOMMuO66aF13QUGqeyRJkiRJ7VODoTQMw1LgcmAZsBF4JAzDvwZBcEMQBPtW8saB14IgeB04Crixhfp7UKxdGx3DMCo0lp+f0u5IkiRJUruV0D6lYRg+Czy732vXVDt/FGg3K3PPOAOuvx6CIKp8HY+nukeSJEmS1D4lq9BRu3LKKdC5M4wY0eKVryVJkiTpkGYorUOPHvClLxlIJUmSJKklGUrr0K0bfPRRqnshSZIkSe2bobQOXbtCcXGqeyFJkiS1H0VFReTk5JCTk0Pv3r055phjKq9LSkoSamPmzJm89tprCT/z/vvvZ+7cuU3tcrPNnz+/8nsOHDiQRx55JGltn3feeZx44okMHjyYSy65hNLS0qS1fTAZSuvgSKkkSZIEvPkhPLc5OjZT9+7dWbduHevWreOyyy7j3/7t3yqvs7KyAAjDkPLy8jrbeOCBBzjxxBOb3ZeDad68eaxbt47f/va3XHrppZSVlSWl3RkzZrBp0ybWr19PcXExDzzwQFLaPdgSqr57KHKkVJIkSe3a//srFH5c/z179sKWnRACAXBMZzgss+77+3aBrw1qdFc2b97M5MmTGTZsGGvXruV//ud/uP7661mzZg179uzh61//OtdcE23+MWrUKH72s58xePBgevTowWWXXcbSpUs5/PDDefLJJ+nVq1dCz3zwwQe55ZZbCMOQyZMn85Of/ITS0lJmzpzJunXrCMOQWbNmMWfOHO644w7uu+8+MjIyGDp0KA8++GCjvyNA//79yczMpLi4mOzs7MrvkpOTw/vvv8+oUaPYvHkz999/P8899xw7d+7kzTffZNq0adx0000HtHfWWWcBEAQBw4cPp7CwsEn9SjVDaR26dnWkVJIkSYe4PaVRIIXouKe0/lDaDJs2bWLx4sXk5eUBcPPNN5OdnU1paSljx45l2rRpDBw4sMZniouLGTNmDDfffDPf+973+OUvf8lVV13V4LMKCwuZP38+q1atomvXrpx++uk8/fTT9OzZkx07dvDqq68C8FFFIFiwYAFvv/02WVlZla81xcsvv8zgwYPJzs5u8N5XXnmF1atXk5mZyQknnMB3vvMd+vTpU+u9JSUlPPTQQ9xzzz1N7lsqGUrrsHMnfPwx/PGPcOqpqe6NJEmSlGSJjGi++SHc+ScoK4f0NJg5DI47skW688UvfrEykAI8/PDDLFq0iNLSUrZu3cqGDRsOCKWHHXYYX/nKVwA4+eSTeeGFFxJ61ksvvcS4cePo0aMHAOeffz4rV67kyiuv5LXXXmPOnDlMnDiRM844A4BBgwZxwQUXMGXKFKZOndro73brrbdy77338sYbb/Dss88m9JnTTz+dLl26ANEI6zvvvFNnKP3Wt77F6aefTqyNbh3imtJaFBTAvhH5L385upYkSZIOOccdCd8dCZNOjI4tFEgBOnXqVHn+xhtvcOedd/KHP/yB9evXM2HCBD799NMDPrNvHSpAenp6swv9dO/enfXr1zN69GjuvvtuvvWtbwGwbNkyLrvsMl5++WWGDx9+wJrQGTNmkJOTw+TJk2ttd968eWzYsIHf/OY3XHzxxXz22WcAZGRkVK6f3f/7dejQIaHv9h//8R/s3LmTBQsWNO1LtwKG0lrk58O+f/OSkuhakiRJOiQddyRM+FKLBtL9ffzxx3Tu3JkuXbrw3nvvsWzZsqS2P2LECFasWEFRURGlpaUsWbKEMWPGsH37dsIw5Gtf+xo33HADa9asoaysjMLCQsaNG8eCBQvYsWMHu3fvrtHe4sWLWbduHU899VS9zz3nnHMYMmRI5ZrUfv36sXr1agAeffTRRn+PX/ziF+Tn5/Pggw+SltZ2o13b7XkLischs2KqfEZGdC1JkiTp4MjNzWXgwIH079+fGTNmcGoz19MtWrSIvn37Vv5kZGTwox/9iHg8Tk5ODiNHjmTixIm8++67nHbaaeTk5DBz5szK4kfnn38+Q4cOJTc3lyuuuILOnTs3uS/XXHMNP/3pTwnDkHnz5nHnnXeSm5vLhx82rrpxWVkZl19+Oe+99x4jR44kJyeHG2+8scn9SqUgDMOG72oBeXl54apVq1Ly7ET8n/8Dc+bA3XfDt7+d6t5IkiRJzbdx40YGDBiQ6m6oHartbysIgtVhGObV8ZFKjpTWYd8a4b59U9sPSZIkSWrPDKV16NYtOrpXqSRJkiS1HENpHbp2jY7uVSpJkiRJLcdQWod9odSRUkmSJElqOYbSOmRlwWGHOVIqSZIkSS3JUFqPbt0cKZUkSZKklmQorUfXro6USpIkSckyduxYli1bVuO1hQsXMnv27Ho/d8QRRwCwdetWpk2bVus98XichracXLhwIbt37668Puuss/goCf/Bf91113Hbbbc1u52muvDCCzn22GPJycnhpJNOYvny5Ulr+9///d/53Oc+V/lv0BIMpfVIT4d166CgINU9kSRJklKjoABuuik5/008ffp0lixZUuO1JUuWMH369IQ+36dPHx599NEmP3//UPrss8/Sbd+2G23crbfeyrp161i4cCGXXXZZ0tr96le/yp///OektVcbQ2kdCgpg40bYvBnGjzeYSpIkqX2ZOxfi8fp/hg2DUaPg6quj47Bh9d8/d279z5w2bRrPPPMMJSUlALz11lts3bqV0aNHs2vXLsaPH09ubi5DhgzhySefPODzb731FoMHDwZgz549nHfeeQwYMICzzz6bPXv2VN43e/Zs8vLyGDRoENdeey0Ad911F1u3bmXs2LGMHTsWgH79+rFjxw4Abr/9dgYPHszgwYNZuHBh5fMGDBjApZdeyqBBgzjjjDNqPKchtbX5ySefMHHiRE466SQGDx7Mb37zGwCuuuoqBg4cyNChQ7niiisSfsb+YrEYW7Zsqbyu/h1XrVpFPB4HotHdiy66iHg8znHHHcddd91Va3sjR47k6KOPbnJ/EpHRoq23YfmL36a8/PNAQEkJ5OdDLJbqXkmSJEkHT3ExlJdH5+Xl0fW+XSqaIjs7m+HDh7N06VKmTJnCkiVLOPfccwmCgI4dO/L444/TpUsXduzYwciRI5k8eTJBENTa1j333MPhhx/Oxo0bWb9+Pbm5uZXv3XjjjWRnZ1NWVsb48eNZv349c+bM4fbbb2fFihX06NGjRlurV6/mgQce4KWXXiIMQ0aMGMGYMWM48sgjeeONN3j44Ye57777OPfcc3nssce44IILGvyudbX55ptv0qdPH5555hkAiouLKSoq4vHHH2fTpk0EQdCsKcXPPfccU6dOTejeTZs2sWLFCnbu3MmJJ57I7NmzyczMbPKzm8pQWpv8fOKLriWd5ZSRTlZGOfF4eqp7JUmSJCVNxcBdvQoKolmDJSXR7hQPPdT8gZp9U3j3hdJFixYBEIYhV199NStXriQtLY0tW7awbds2evfuXWs7K1euZM6cOQAMHTqUoUOHVr73yCOPcO+991JaWsp7773Hhg0bary/vxdffJGzzz6bTp06AXDOOefwwgsvMHny5Mq1mgAnn3wyb731VkLfs642J0yYwPe//32uvPJKJk2axOjRoyktLaVjx45cfPHFTJo0iUmTJiX0jOrmzZvH1VdfTWFhIQUJTvOcOHEiHTp0oEOHDvTq1Ytt27bRt2/fRj+7uZy+W5v//m9ie1dyHg+TTinLZz7kKKkkSZIOObEYLF8OP/pRdEzGfxNPmTKF5cuXs2bNGnbv3s3JJ58MwEMPPcT27dtZvXo169at46ijjuLTTz9tdPt///vfue2221i+fDnr169n4sSJTWpnnw4dOlSep6enU1pa2uS2AE444QTWrFnDkCFDmD9/PjfccAMZGRn8+c9/Ztq0aTz99NNMmDDhgM+deeaZ5OTkcMkll9Ta7q233srrr7/OLbfcwkUXXVT5ekZGBuUVw937/x6S/d2aylBamzPOAGAgmygjk2FfPyHFHZIkSZJSIxaDH/4weUvZjjjiCMaOHctFF11Uo8BRcXExvXr1IjMzkxUrVvD222/X285pp53Gr3/9awD+8pe/sH79egA+/vhjOnXqRNeuXdm2bRtLly6t/Eznzp3ZuXPnAW2NHj2aJ554gt27d/PJJ5/w+OOPM3r06GZ9z7ra3Lp1K4cffjgXXHAB8+bNY82aNezatYvi4mLOOuss7rjjDl555ZUD2lu2bBnr1q3j/vvvr/e5l19+OeXl5ZVVjvv168fq1asBeOyxx5r1nVqKobQ28ThkZNDtS9Fc8+IBI1PbH0mSJKkdmT59Oq+88kqNUPqNb3yDVatWMWTIEBYvXkz//v3rbWP27Nns2rWLAQMGcM0111SOuJ500kkMGzaM/v37c/7553PqqadWfmbWrFlMmDChstDRPrm5uVx44YUMHz6cESNGcMkllzBs2LBGfacf//jH9O3bt/KnrjZfffVVhg8fTk5ODtdffz3z589n586dTJo0iaFDhzJq1Chuv/32Rj27uiAImD9/PgsWLADg2muv5bvf/S55eXmkpzd+SeIPfvAD+vbty+7du+nbty/XXXddk/tWlyAMw6Q3moi8vLywoX2EUuqoo3ho8E1c8IeL2LQJTjwx1R2SJEmSmmfjxo0MGDAg1d1QO1Tb31YQBKvDMMxr6LOOlNalWze67o1KJxcXp7gvkiRJktROGUrr0rUr3Ur+AUAzKjJLkiRJkuphKK1Lt2503fM+AL/6VVQOW5IkSZKUXIbSunTtyt+KugGwZEm0P5PBVJIkSZKSy1Bal27dWFfcD4AwjDYMzs9PaY8kSZIkqd0xlNalWzfOKHkagCCArKxopxhJkiRJUvIYSutSXMwpJc9zZOe95OXB8uXJ2zBYkiRJOhSNHTuWZcuW1Xht4cKFzJ49u97PHXHEEQBs3bqVadOm1XpPPB6noS0nFy5cyO7duyuvzzrrLD5KQlXT6667jttuu63Z7TTVhRdeyLHHHktOTg4nnXQSy5cvT0q7u3fvZuLEifTv359BgwZx1VVXJaXd/RlKa1NQEFU3Ao7a9Te+cESRgVSSJEmHpC2flFPwfhlbPilvdlvTp09nyZIlNV5bsmQJ06dPT+jzffr04dFHH23y8/cPpc8++yzdunVrcnutya233sq6detYuHAhl112WdLaveKKK9i0aRNr167lj3/8I0uXLk1a2/sYSmuTnw9lZQBkhx/wwds7U9sfSZIkKcl+X1jGQ2+U1vvzy017efD1Mp5/r5wHXy/jl5v21nv/7wvL6n3mtGnTeOaZZygpKQHgrbfeYuvWrYwePZpdu3Yxfvx4cnNzGTJkCE8++eQBn3/rrbcYPHgwAHv27OG8885jwIABnH322ezZs6fyvtmzZ5OXl8egQYO49tprAbjrrrvYunUrY8eOZezYsQD069ePHTt2AHD77bczePBgBg8ezMKFCyufN2DAAC699FIGDRrEGWecUeM5DamtzU8++YSJEydy0kknMXjwYH7zm98AcNVVVzFw4ECGDh3KFVdckfAz9heLxdiyZUvldfXvuGrVKuIVaxKvu+46LrroIuLxOMcddxx33XXXAW0dfvjhlb+rrKwscnNzKSwsbHLf6pKR9Bbbg3gcMjKgpITstA8pTD8p1T2SJEmSDrrPyiCsOA8rrjukN7297Oxshg8fztKlS5kyZQpLlizh3HPPJQgCOnbsyOOPP06XLl3YsWMHI0eOZPLkyQRBUGtb99xzD4cffjgbN25k/fr15ObmVr534403kp2dTVlZGePHj2f9+vXMmTOH22+/nRUrVtCjR48aba1evZoHHniAl156iTAMGTFiBGPGjOHII4/kjTfe4OGHH+a+++7j3HPP5bHHHuOCCy5o8LvW1eabb75Jnz59eOaZZwAoLi6mqKiIxx9/nE2bNhEEQbOmFD/33HNMnTo1oXs3bdrEihUr2LlzJyeeeCKzZ88mMzOz1ns/+ugjfve73/Hd7363yX2ri6G0NrEYLFwI3/423fOOZf37nVLdI0mSJCmpTu/bcLrc8kk5D79RRlkI6QFM7pfOMZ2aN9ly3xTefaF00aJFAIRhyNVXX83KlStJS0tjy5YtbNu2jd69e9fazsqVK5kzZw4AQ4cOZejQoZXvPfLII9x7772Ulpby3nvvsWHDhhrv7+/FF1/k7LPPplOn6L/7zznnHF544QUmT55cuVYT4OSTT+att95K6HvW1eaECRP4/ve/z5VXXsmkSZMYPXo0paWldOzYkYsvvphJkyYxadKkhJ5R3bx587j66qspLCykIMG9LCdOnEiHDh3o0KEDvXr1Ytu2bfTt2/eA+0pLS5k+fTpz5szhuOOOa3TfGuL03bqMGgVAds8MPvggxX2RJEmSUuCYTmlMPz6d046Ojs0NpABTpkxh+fLlrFmzht27d3PyyScD8NBDD7F9+3ZWr17NunXrOOqoo/j0008b3f7f//53brvtNpYvX8769euZOHFik9rZp0OHDpXn6enplJaWNrktgBNOOIE1a9YwZMgQ5s+fzw033EBGRgZ//vOfmTZtGk8//TQTJkw44HNnnnkmOTk5XHLJJbW2e+utt/L6669zyy23cNFFF1W+npGRQXl5tB54/99Dot9t1qxZHH/88cydO7fR3zcRhtK6dO0KwK6Py9i1C1auTHF/JEmSpBQ4plMasd7JCaQQVdIdO3YsF110UY0CR8XFxfTq1YvMzExWrFjB22+/XW87p512Gr/+9a8B+Mtf/sL69esB+Pjjj+nUqRNdu3Zl27ZtNQrzdO7cmZ07D6wXM3r0aJ544gl2797NJ598wuOPP87o0aOb9T3ranPr1q0cfvjhXHDBBcybN481a9awa9cuiouLOeuss7jjjjt45ZVXDmhv2bJlrFu3jvvvv7/e515++eWUl5dXVjnu168fq1evBuCxxx5r9PeYP38+xcXFlWtiW4KhtC7dulHASH71vycAcOaZUVFeSZIkSc0zffp0XnnllRqh9Bvf+AarVq1iyJAhLF68mP79+9fbxuzZs9m1axcDBgzgmmuuqRxxPemkkxg2bBj9+/fn/PPP59RTT638zKxZs5gwYUJl8Z59cnNzufDCCxk+fDgjRozgkksuYdiwYY36Tj/+8Y/p27dv5U9dbb766qsMHz6cnJwcrr/+eubPn8/OnTuZNGkSQ4cOZdSoUdx+++2NenZ1QRAwf/58FixYAMC1117Ld7/7XfLy8khPb9yC4MLCQm688UY2bNhAbm4uOTk5DYbiJvU5DMOG72oBeXl5YUP7CKVUeTk3ZcxnfvhjykkjPR1+9CP44Q9T3TFJkiSpaTZu3MiAAQNS3Q21Q7X9bQVBsDoMw7yGPutIaV3S0oh3WkVmWlTWOiMjKsorSZIkSUoeQ2k9Yj3e4OcjfgVEo6SxWGr7I0mSJEntjaG0PpmZxLc9AkCvXinuiyRJkpQEqVq+p/aruX9ThtK6FBTA3/5G9psvA/DBmrdS2x9JkiSpmTp27EhRUZHBVEkThiFFRUV07NixyW1kJLE/7Ut+PpSX04WPSaOMovVbgH4p7pQkSZLUdH379qWwsJDt27enuitqRzp27Ejfvn2b/HlDaV3icUhPJ62sjCP5kA+O/GKqeyRJkiQ1S2ZmJscee2yquyHV4PTdusRicM450KED2Z/rxAdZvVPdI0mSJElqdwyl9RkwAD77jMwjOrJ6dbTMVJIkSZKUPIbS+nTrRgEj2fQabN4M48cbTCVJkiQpmQyl9enalXzilJdHlyUlUf0jSZIkSVJyGErr060bcfLJSI8us7Ki+keSJEmSpOQwlNanWzdi/Ilvnvk+AMuWRfWPJEmSJEnJYSitT9euAJzUJ9rHacCAVHZGkiRJktofQ2l9unUDIHv9CgA++CCVnZEkSZKk9sdQWp833gAg+8/LAPjg+VdT2RtJkiRJancMpfVZvRqAbIoA+OCPG1PZG0mSJElqdwyl9Rk3DoBsPgTgV++Oc59SSZIkSUoiQ2l9YjHo04e/HXs6AI+u6MH48RhMJUmSJClJDKUN6dOH1RnDAQhDKCmB/PzUdkmSJEmS2gtDaUOysxmX8QIAQQBZWRCPp7ZLkiRJktReGEob0r07sZLn+cIXYOBAWL48mtUrSZIkSWq+jFR3oNXLzoYPPuDzgyEtzUAqSZIkScnkSGlDsrPho4/o2SNk+/ZUd0aSJEmS2hdDaUM+/hjCkJ6fFRpKJUmSJCnJDKX1KSiAe+4BoOeyBykqCikvT3GfJEmSJKkdMZTWJz8fSksB2FV2GOXlAcuWpbZLkiRJktSeGErrE49DZiYFjOTnzAbgnHOiAVRJkiRJUvMZSusTi8GvfkU+cUrJBKCkJBpAlSRJkiQ1n6G0IaefTpx8MjOixaQZGdEAqiRJkiTkTIcPAAAgAElEQVSp+QylDenWjRh/4pFp/w+AuXPdq1SSJEmSksVQ2pCMDOjalTOzXwagc+cU90eSJEmS2hFDaSKys+lQ/A+6dIEdO1LdGUmSJElqPxIKpUEQTAiC4LUgCDYHQXBVLe9/PgiCFUEQrA2CYH0QBGclv6sp1KEDvPwyPTt/yvbtqe6MJEmSJLUfDYbSIAjSgbuBrwADgelBEAzc77b5wCNhGA4DzgN+nuyOpkxBAbz+Orz+Oh22vMmfn9/jljCSJEmSlCSJjJQOBzaHYfhmGIYlwBJgyn73hECXivOuwNbkdTHF8vOhvJwCRrKJE9m8pSPjx7tXqSRJkiQlQyKh9Bjg3WrXhRWvVXcdcEEQBIXAs8B3amsoCIJZQRCsCoJg1fa2Mg82HoeMDPKJExIAgXuVSpIkSVKSJKvQ0XTgV2EY9gXOAv4rCIID2g7D8N4wDPPCMMzr2bNnkh7dwmIx+Jd/IU4+6enRS1lZ7lUqSZIkScmQSCjdAnyu2nXfitequxh4BCAMwwKgI9AjGR1sFYYOJcaf+NbMEgCeesq9SiVJkiQpGRIJpS8DxwdBcGwQBFlEhYye2u+ed4DxAEEQDCAKpW1kfm4CsrMB+KcTPgbguONS2RlJkiRJaj8aDKVhGJYClwPLgI1EVXb/GgTBDUEQTK647fvApUEQvAI8DFwYhmHYUp0+6CpCaY/0DwHcFkaSJEmSkiQjkZvCMHyWqIBR9deuqXa+ATg1uV1rRSpCac/0DwBDqSRJkiQlS7IKHbVv3bsD0PO/HwLgV79ySxhJkiRJSgZDaSL+9jcA3nx2IwC//W3oXqWSJEmSlASG0kSsXQvASwwHQsLQvUolSZIkKRkSWlN6yBs3DoCxPE9AVL8pKytwr1JJkiRJaiZDaSJiMfj854l12cng3XvYHXTiv/7LvUolSZIkqbmcvpuoz38eevTg+JxOdOxoIJUkSZKkZDCUJqpnT9i+nd694f33U90ZSZIkSWofDKWJ6tkT/vEPeveGoiIoKUl1hyRJkiSp7TOUJqpXLygq4pNd5QAsXZri/kiSJElSO2AoTdSuXRSUD+eO26PLr3/dfUolSZIkqbkMpYkoKICf/5x84pSWRiOle/e6T6kkSZIkNZehNBH5+VBaSpx8stgLQHo67lMqSZIkSc1kKE1EPA6ZmcT4E8vSJwLwzW+6LYwkSZIkNZehNBGxGDzyCACnfS+P7t0hKyvFfZIkSZKkdsBQmqgJE6Jj587uVSpJkiRJSWIoTVRWFnTtCtu3c9hhsGqV1XclSZIkqbkMpY3RqxcFG7uxdi288w6MH28wlSRJkqTmMJQ2RseO5K/uTHlZCEBJidvCSJIkSVJzGEoTVVAAf/0r8Q9/S0bFtjBZWW4LI0mSJEnNYShNVH4+hCEx/sQPuRmABx5wWxhJkiRJag5DaaLicUhPB2B01ksAHH10CvsjSZIkSe2AoTRRsRh8+9sA9L7rasBtYSRJkiSpuQyljfFP/wRA75OOAuC//svqu5IkSZLUHIbSxujZE4DX1u4G4Jln3BZGkiRJkprDUNoYvXoBsPJ/o7WlYei2MJIkSZLUHIbSxqgYKY2/81+kBdFepW4LI0mSJElNZyhtjL/9DYDYCwsYG/yB7l33sny528JIkiRJUlMZShvjf/83OoYhOeEr7N4NI0emtkuSJEmS1JYZShsjHocgAKA0LYs9ezP57/9ObZckSZIkqS0zlDZGLAY5ORT0Ppt70qI9S6dMsfquJEmSJDWVobSxTjyR/JJTKC2LfnV791p9V5IkSZKaylDaWEcfTXzPUrKyosv0dKvvSpIkSVJTGUob67PPiO35A/990yqCAC64wOq7kiRJktRUhtLGKCiA++8HYPQPR3N095IUd0iSJEmS2jZDaWPk50NpaXReUkLXoJgXXrDQkSRJkiQ1laG0MeJx9i0mLUg7ldeLerB5M4wfbzCVJEmSpKYwlDZGLAa//S0A+SOupDyM9iwtKbECryRJkiQ1haG0sc48EzIyiB/3DhkZ0UtZWVbglSRJkqSmMJQ2VloaHHUUsYyX+fd/j15atMgKvJIkSZLUFIbSpujcGV58kXG9/gJAjx4p7o8kSZIktVEZqe5Am1NQAK+/DuXl9P23rwEb+c//hCOOcLRUkiRJkhrLkdLGys+HMATgnZKjgKj2kRV4JUmSJKnxDKWNFY9DejoA/5t+GhAShlbglSRJkqSmMJQ2ViwG3/0uAPGbziAtLdoWxgq8kiRJktR4htKmOOUUAGKnH8G4cZCdDcuXu6ZUkiRJkhrLUNoURx8dHd97j7w82LkThg9PbZckSZIkqS0ylDZF797RcdEiyt8tZO9e+N3vUtslSZIkSWqLDKVN8fbbABQ8tpU7H+oJwHnnWX1XkiRJkhrLUNoUFekznzHsJarEu3ev1XclSZIkqbEMpU0Rj0MQECefDpQAIWlpVt+VJEmSpMYylDZFLAbDhxPr8w7L//NvdOkScMYZVt+VJEmSpMYylDbVkCFQVkZs1hC+8AXYuNE1pZIkSZLUWIbSpurbF7Zto2DlXjZsgL//HcaPN5hKkiRJUmMYSpvqs88AyL/3NcrLo5dKSix2JEmSJEmNYShtioICuP12AOKP/CsZ6VEqzcy02JEkSZIkNYahtCny86M9YIBY2Yv8dMLvAViwwGJHkiRJktQYhtKmiMehQ4foPD2did/sAURZ1TWlkiRJkpQ4Q2lTxGKwfDlkZcHZZ7PlqFwAHn/cYkeSJEmS1BiG0qaKxeCLX4SyMl58MXopDC12JEmSJEmNYShtjiOOgJdeIt79VdIqfpNZWRY7kiRJkqREGUqbqqAA1qyBwkJic0cwZVQRHTvC739vsSNJkiRJSpShtKny86m+QemoI9by6aewdKlrSiVJkiQpUYbSporHISMjOs/MpOzYLwHwk59Y7EiSJEmSEmUobapYDG66KTq/6y7ey+oHRIOnFjuSJEmSpMQYSpvjy1+OjkceydSp0WkQWOxIkiRJkhJlKG2Ovn2j469+xWmZBRx9NAwZEm1harEjSZIkSWqYobQ5Nm2Kjs8+C+PH87luOykqSm2XJEmSJKktMZQ2x/PPR8cwpOCzXNa81oktWyx0JEmSJEmJMpQ2RzwOadGvMD9tHGVhAFjoSJIkSZISZShtjlgMpk6Fjh2J3/01MjOjUJqRYaEjSZIkSUqEobS5jj4aPv2U2LHvs3hx9NIpp6S2S5IkSZLUVhhKm6OgAO67Lzr/6lfp88FfgGjqrutKJUmSJKlhhtLmyM+H0tLofO9eXnxiBwBh6LpSSZIkSUqEobQ54nHIyorO09OJ/3P3fXWPyMpyXakkSZIkNSShUBoEwYQgCF4LgmBzEARX1fL+HUEQrKv4eT0Igo+S39VWKBaD5cujBDp1KrFZQ5g+HdLTYdmy6G1JkiRJUt0aDKVBEKQDdwNfAQYC04MgGFj9njAM/y0Mw5wwDHOA/wP8tiU62yqdcgqceCJ89hkAX/4ylJXBE0+4plSSJEmSGpLISOlwYHMYhm+GYVgCLAGm1HP/dODhZHSuzejSBV56CQoKKpeYLlxosSNJkiRJakgiofQY4N1q14UVrx0gCIIvAMcCf6jj/VlBEKwKgmDV9u3bG9vX1qmgIAqk27bB+PG8+7/Rr6q83GJHkiRJktSQZBc6Og94NAzDstreDMPw3jAM88IwzOvZs2eSH50i+fnRfF2AkhLOzFpBEEAQWOxIkiRJkhqSSCjdAnyu2nXfitdqcx6H2tTdeBwyM6PzjAxiM45nwAA44ohoCq/FjiRJkiSpbomE0peB44MgODYIgiyi4PnU/jcFQdAfOBI4tFZRxmJw773R+X/8BwXEeP112LkT5s51TakkSZIk1afBUBqGYSlwObAM2Ag8EobhX4MguCEIgsnVbj0PWBKGYdgyXW3FplTUfXrxRfIXv119Nq9rSiVJkiSpHhmJ3BSG4bPAs/u9ds1+19clr1ttzMaN0XHZMuKZ3yQr4w98tjeN9HTXlEqSJElSfZJd6OjQtG84NAyJlb3Ik994BIDc3NR1SZIkSZLaAkNpMsTjkJ4enWdl0SU2CIh2inGvUkmSJEmqm6E0GWIxmDEj2gfmuefILxoCQBi6rlSSJEmS6mMoTZaxY6MU+sQTxLu/SkbFal33KpUkSZKkuhlKk2XPnuh4553E5o7gh//yLgBf/WoK+yRJkiRJrZyhNFneeSc6lpdDSQnH71wLwKOPuq5UkiRJkupiKE2Ws86KjkEAWVm8fWQOUJlRXVcqSZIkSbUwlCbLKafAF74ARx4JCxcyfubnK99yv1JJkiRJqp2hNFkKCqCwED74AObOhVdfJa3itxsEqe2aJEmSJLVWhtJkyc+P5uoClJSQ/1gRYRhdlpY6fVeSJEmSamMoTZZ4HDIzo/PMTOL/3J2srOgyI8Ppu5IkSZJUG0NpssRi8LOfRec33EBs1hCefDK6HDYsdd2SJEmSpNbMUJpM55wTHfPzoaCALl2i9aR/+pPbwkiSJElSbQylyfTaa9Fx6VIYP578xW9Xrit1WxhJkiRJOpChNJmefz46hiGUlBDn+cplpkEA3bunrmuSJEmS1BoZSpMpHo82JQXIyiI243hmz44uy8qinWKcwitJkiRJVQylyRSLwaxZ0fl55wHQpUt0WTF46hReSZIkSarGUJps/fpFx//7f2H8eM763KuVb6WnuzWMJEmSJFVnKE22bduiY3l5NDS6di1pFb/lIEhdtyRJkiSpNTKUJtvUqdExCCAri3zGVFbgLS11+q4kSZIkVWcoTbbRo+HYY+HEE2H5cuIzvkBWVvSW03clSZIkqSZDaUvo1w/+8Q8gqn30zDPRy0OGpK5LkiRJktQaGUqTraAAXngBPvgAxo+HggIOPzyazbt6deVLkiRJkiQMpcmXnx8VOYLKPWCqryN1WxhJkiRJqpKR6g60O/E4ZGbCZ59VLiKNE71UUhKNmHbvnuI+SpIkSVIr4UhpssVi8Oyz0fnQoZUvXXNN9FJZGcyd6xReSZIkSQJDacs47LBoSHTVqspFpPv2KA1Dp/BKkiRJ0j6G0paQn0/l5qQVCXTsWEir+G27NYwkSZIkRQylLSEeh4yK5bpZWZUJNM3ftiRJkiTVYExqCdUXkU6cCNQsylta6vRdSZIkSQJDacv50pei429/C+PHE+/+Kh06VL1tBV5JkiRJMpS2nDffjI7l5VBSQqzoaRYujOoflZdbgVeSJEmSwFDacsaNqzqvqGxUVFT10qefwuLFB79bkiRJktSaGEpb0r7KRhX7wcTjUT6FqDjvAw84WipJkiTp0GYobSnVt4WpqGwUi8G//EvVLRY8kiRJknSoM5S2lHg82g4Gou1hKraFufTSqlvcr1SSJEnSoc5Q2lJisajyLsCwYTXe2jeFt2JWryRJkiQdsgylLenII6Pjn/4E48dDQUGNWb179zp9V5IkSdKhzVDakqonzpISyM8nHsf9SiVJkiSpgqG0JcXj0XpSiObqdu9OLIb7lUqSJElSBUNpS4rF4JJLovOyssoE6n6lkiRJkhQxlLa0rl2jYxjWmMK7bwDV/UolSZIkHcoMpS1t8uToGATRFjHxOLEYXHhh1S3uVypJkiTpUGUobWmnnAKDBkGnTtFi0lgMgJkzq7aEcb9SSZIkSYcqQ2lLKyiA116DXbsOqGq0b79SSZIkSTpUGUpbWn5+VGYX4LPPKufpVn95716LHUmSJEk6NBlKW1o8Hq0l3adiY1KLHUmSJEmSobTlxWJw553RebWNSWMxuOiiqttKShwtlSRJknToMZQeDNU3Jq3YFgZgxgzIzIxedrRUkiRJ0qHIUHowVJ+rGwSVU3jdGkaSJEnSoc5QejDEYvCv/xqdl5XVqMLr1jCSJEmSDmWG0oOla9foGIY1pvCCW8NIkiRJOnQZSg+WCROqzqsNiebnRzkVLHYkSZIk6dBjKD2Y0ip+3fvm6xJl0+ojpRY7kiRJknQoMZQeLNWHRKtVNHJrGEmSJEmHMkPpwRKPQ4cOVdcVFXgh2homKys6d2sYSZIkSYcSQ+nBEovBHXdE5/tV4I3Foiq8++zd69YwkiRJkg4NhtKD6cMPq873q8Cbm1v1Vnl5jYFUSZIkSWq3DKUHUzwOGRnReRDUSJ5FRTXqH7F27cHtmiRJkiSlgqH0YIrFYM6c6Hy/KbzxOGRmVt3qulJJkiRJhwJD6cHWpUt0DMMaU3itwitJkiTpUGQoPdjOOKNqnm56ejREWmHGjKrRUqvwSpIkSToUGEpTIa3i1159ESkHjpZahVeSJElSe2coPdjy86NhUKg1dVqFV5IkSdKhxFB6sMXj0KFD1fV+qbOoqGogFazCK0mSJKl9M5QebLEYLFwYnZeX16jACzV3jQHXlUqSJElq3wylqVB9U9JqFXjBKrySJEmSDi2G0lTYf1PS/abwzpgBWVnRuVV4JUmSJLVnhtJUiMXgJz+JzmuZwutoqSRJkqRDhaE0VUpKomMYwmefHVCFd8aMqrWljpZKkiRJaq8MpalSfcpuLXu/xGLwzW9WXbtnqSRJkqT2yFCaKtWLHQVBdL2f4cOrzsvL4aOPDlLfJEmSJOkgMZSmSjwOHTtG50FwwEgpHJhT77jDKbySJEmS2hdDaars2680CGotdgQH7llaWmrBI0mSJEntS0KhNAiCCUEQvBYEweYgCK6q455zgyDYEATBX4Mg+HVyu9lOVR8K/fTTAxJnLAZ33101y9eCR5IkSZLamwZDaRAE6cDdwFeAgcD0IAgG7nfP8cAPgVPDMBwEzG2BvrY/1YdC60ics2ZZ8EiSJElS+5XISOlwYHMYhm+GYVgCLAGm7HfPpcDdYRh+CBCG4T+S2812av8NSetInLFY1bkFjyRJkiS1J4mE0mOAd6tdF1a8Vt0JwAlBEPwxCII/BUEwobaGgiCYFQTBqiAIVm3fvr1pPW5vcnOrzmvZGgZqFuoFCx5JkiRJaj+SVegoAzgeiAPTgfuCIOi2/01hGN4bhmFeGIZ5PXv2TNKj27jqiTMtrdatYeJxSE+vurbgkSRJkqT2IpFQugX4XLXrvhWvVVcIPBWG4d4wDP8OvE4UUtWQeBw6dKi6rmWkdF/Bo7SKf60whEWLHC2VJEmS1PYlEkpfBo4PguDYIAiygPOAp/a75wmiUVKCIOhBNJ33zST2s/2KxeDOO+vdGgaigkdf/WrV9d69jpZKkiRJavsaDKVhGJYClwPLgI3AI2EY/jUIghuCIJhccdsyoCgIgg3ACmBeGIYHzkNV7RrYGmafo4+uef3++y3YJ0mSJEk6CIIwDFPy4Ly8vHDVqlUpeXarU1AAY8ZEw58QTeddsaJm2d1abktPh5//PBpFlSRJkqTWJAiC1WEY5jV0X7IKHak5GrE1zMUXV12XlcHll7u2VJIkSVLbZShtLRLYGgZgxgzIyKi6Li2tNb9KkiRJUptgKG0tqm8NEwS1bg0D0Wjp975XdR2G8NFHB6F/kiRJktQCDKWtRTwOHTtWXdcxUgrQrVtVfgW47Ta4996W65okSZIktRRDaWsRi8HChVHaDMM6t4aBKL+mp1ddl5e7tlSSJElS22QobU2qT+GtZ2uYWAzuvhvSqv3rubZUkiRJUltkKG1N4vGqKkZhCA88UOfw56xZcMUVVdeuLZUkSZLUFhlKW5MEt4bZx7WlkiRJkto6Q2lrM2xY1Xk9W8OAa0slSZIktX2G0tamqKjmYtG1a+u81bWlkiRJkto6Q2lrU31dKdS7rhRcWypJkiSpbTOUtjb7rystKamzCu8+ri2VJEmS1FYZSlujGTMgKys6b6AKL9S+tvTb33ZtqSRJkqTWz1DaGjVytHTf2tLqo6VlZbBgQQv2UZIkSZKSwFDaWs2YUXPP0kWLGlxbOmVKzdeefNJpvJIkSZJaN0NpaxWLwVlnVV3v3dvg2tIf/KDmNN4wdBqvJEmSpNbNUNqa9elT8/r99+u9PRaDn//cabySJEmS2g5DaWs2Y0bNoc+lSxsc9nQaryRJkqS2xFDamsVicMklVdcJbA8DTuOVJEmS1HYYSlu7b36zKmEmsD0MOI1XkiRJUtthKG3tYjE4//yq6717IT+/wY85jVeSJElSW2AobQtGjao6Ly+H7t0T+pjTeCVJkiS1dobStqCoqOZc3LVrE/qY03glSZIktXaG0rYgHofMzKrr++5LeB6u03glSZIktWaG0rYgFoOLLqq6LiuDyy9PeB6u03glSZIktVaG0rZixgzIyKi6Li1NqOAROI1XkiRJUutlKG0rYjH43veqrsMQPvoo4Y/XNo33iSfg7LMdMZUkSZKUOobStqRbt5rXd9zRqES5/zReiILpmDEGU0mSJEmpYShtS+LxA6fwLl6c8Mf3TeNN2+9ffe9ep/JKkiRJSg1DaVsSi8Hdd1ctDg1DeOCBRg1zzpoF99xTc30pWJFXkiRJUmoYStuaWbNg5syq6717Ey54VL2JX/yiZjANQ7jsMoOpJEmSpIPLUNoWjRhRdV5e3qiCR/sYTCVJkiS1BobStqioqGaabGTBo31qq8hrMJUkSZJ0MBlK26J4vGYZ3UYWPKruBz+AzMyarxlMJUmSJB0shtK2aF/Bo33BNAxh0aImjZbGYvD88zBwYM3XDaaSJEmSDgZDaVs1axZ89atV183Y1yUWg/vvr33E9FvfgiuvbEY/JUmSJKkehtK2rHfvmte/+12TRkuh7hFTiLKuwVSSJElSSzCUtmUzZtRcW1pe3uS1pVD3iCkYTCVJkiS1DENpWxaLwc9/DmkV/4zNWFtavcnnn4fTTjvwvQULYMyYZjUvSZIkSTUYStu6JK4t3WdfMP3BDw58b+VKGDXKAkiSJEmSksNQ2h4cfXTN62asLa3ulltqD6bl5RZAkiRJkpQchtL2IMlrS6urK5iC03klSZIkNZ+htD1ogbWl1d1yC/znf1Y1X53TeSVJkiQ1h6G0vWiBtaX7N//ii7UXQHI6ryRJkqSmMpS2Jy20tnSf+gogQZSBhw2D2bOd0itJkiQpMYbS9qQF15ZWV9903nXr4Be/cEqvJEmSpMQYStuTfWtL9wXTJK8tra6+6bxQNaXXQkiSJEmS6mMobW9aeG1pddWn8wZB7fesXAmnnGI4lSRJklQ7Q2l71Lt3zesnn2zRubS33AJ//CNMnWo4lSRJktQ4htL2aP+1pWEI3/52i6bBWAwefzwKp3VN6QXDqSRJkqSaDKXt0b61pdWHLcvKWmwa7/6Pfv75qBDSF75Q9337wqnVeiVJkqRDm6G0vZo1C6ZMqflakreIaejxb73VcDjdV633lFNg0CAr9v7/9u4+yK66vuP457uPeZQkJCWREJPUgMYHwG6BVXwYbRVbB8LoVBw7PkGX+DDajhqg/uHUjn8EO2o7VWAHHzuO6FCloR2LjLUKmKCbgiILKWkMgQyBQEIMm2Qf7v32j9852bt378O5u+fecx/er5k7d++5Z8+eZH9zdj/7/f5+BwAAAOg0hNJ2tm1bQ24RU0nScCpJo6Nhxd41a6Qrr6R6CgAAAHQCQmk7a+AtYqqpJZweOiTdcUeonp57rnTxxVRQAQAAgHZl7p7JFx4YGPCRkZFMvnbHufLKkPJiW7aEVYkyNDwsffnL0qOPhqycxKZNUk+PtGqVtHlzWM9pcLC+5wkAAABgbsxst7sPVNuPSmknaPAtYpIYGgrtuvfdJ23dKl1wQfXPeewx6ZFHwiJJ8TzUDRvCSr4slgQAAAC0JiqlnWDnTun1rw8r8Ma6u6V77mmqUuPOnWGB4F27QgvvXKxfLy1bJvX1SVdfHcIvAAAAgMZLWikllHaK4eFQkiz8fjdBG285w8Nh+uvRo9LevclbfIutXh0e4+O0/QIAALSzg2N5PfRcXs+ecp2ckrpMyvv088KesF+p9+b6XI9jJj12T5d0/pldumBld+n/kCZAKMVsxXNLzUIfbJOXE3fuDIsGj45Kjz8uHTgw95AaW79eWrcufHz4MIEVAAA0r4Njee06lNOR8dYKTYmeJeUUPUfHdEmnpsKvqu6SScpH++QL9i081kROGsvN+q/rCJed07zBlFCK2Uq18XZ1STfd1PTBtFA9QmqhuAV4fFzq7w/P550X7rBDYAUAoP4efDanXz+X11S+CUJTGsfUdIjKudRd9ByHr/4oV5zKRUHMw/svTGXxXUCr2LDU9O6X9mR9GiURSlHa8HBYFSifn97WhPNLa1EYUg8flqamwqJI9bBxo3TuH+f1lr/K6Yw1s3/orFhguuSsLp29mDXEAKCdVGsLbPnQNI9jx+GpOHDNeF/TVa7i/fu7QyAbz4d9TuXCxwCSaYdKaXNGatRPXBEtnF+ay4UVhpp0fmk1g4Oz83S8aNKePaHaefRoOhXVqSV5XfqpnCa7pOdOKfxkLfDcuOuxYzmd2Z/Tgu7wgzXJD/pWmBMANJs4JIxNhZDQyr/UN+MxW/V8F3TPPHapqlS5sFQuNHWZ9PxEnQbyeIscs57HnqzDMdHxXtQb/uDRytezdphTmhSV0k5VPL9UCv2p27dncz4NUFxRXbUqbK+lBfiNH8zprR/Nq6tOhdCF3dKinnCx6bYwp2I+Fz0qtyilVReCKAwK4znpOO1sADrMom5pcW/rhKZGH3Nhj7RyoelVK/jdp1lQKUVl27ZJd945c37pjTeG5zYNpqUqqrHiwBrPJe3vD7eniW9R87vdpvyUZL1RkdTSPceTufAoaQ5/nY4rt0t7curuChdtjwJvHHzzar4fKq32QzCz83XpRIlq0IwQJ82YyzSek05UWwii1So3ANrWsr5wbWu662/Kx6x27HaqiAGlUCntZKVuE9MiK/I2WnyLmokJafV5peeUjk0m+GUfANDySrUFNlPAack/shUdk04foD2w0BGSue666QpprMUXPl2Bd+wAABLKSURBVMpSvFpgd1RBTfJDO+d1nKsEdIhVC5r/F29CSGuf78IeaXEvbYEAUAvad5FM3KpbGExbfOGjLF2wsntOrTVJ7j9W6y9aVG6RRCsvBMHcIQAA2gOVUgQduPBRJ0h6n7dWCSGcbzrHJMwBAIBGoFKK2nTgwkedYK6VWwAAAKBR+BM5gsFB6atfDQsdFfrCF8IqPwAAAABQB4RSTBsakj796Znb3KWPfCTcMwUAAAAAUkYoxUzbt4dW3kK5nHTNNQRTAAAAAKkjlGK27dulLVtmbhsdld74RoIpAAAAgFQRSlHatm3hfqWFJiepmAIAAABIVaJQamaXmdkeM9trZteXeP8DZnbYzB6MHtekf6poqHILH1ExBQAAAJCiqqHUzLolfUXS2yVtlvQeM9tcYtfvufsF0ePWlM8TWRgakm6+eXYwpWIKAAAAICVJKqUXSdrr7vvcfULSbZKuqO9poWmUC6ZUTAEAAACkIEkoPVvSEwWvn4y2FXunmf3GzG43s3NKHcjMhsxsxMxGDh8+PIfTRSaomAIAAACok7QWOrpT0np3f7WkuyV9q9RO7j7s7gPuPrBq1aqUvjQaolLF9NJLpeHhbM4LAAAAQEtLEkoPSiqsfK6Ntp3m7s+5+3j08lZJf5TO6aGplAum+by0dSvBFAAAAEDNkoTSX0naZGYbzKxP0lWSdhTuYGZrCl5eLumR9E4RTaVcMHUnmAIAAACoWdVQ6u5Tkj4m6S6FsPl9d3/YzD5nZpdHu33czB42s19L+rikD9TrhNEE4mDaVTR83KVrr5WuvJJ5pgAAAAASMXfP5AsPDAz4yMhIJl8bKdm5Myx0NDo6+72uLummm0KABQAAANBxzGy3uw9U2y+thY7QiQYHpVtvlXp7Z7+Xz4eq6XXXNf68AAAAALQMQinmZ3BQ+tnPpC1bZs8zlaQbb+R+pgAAAADKIpRi/gYHpR/+sPQ8U0n6+c+5bQwAAACAkgilSM/QkHTvvdIb3jD7Pdp5AQAAAJRAKEW64nbebdtKv087LwAAAIAChFLUx/bt0i23lG/nfd3ruHUMAAAAAEIp6qhSO6+7dMcdzDUFAAAAOhyhFPVVrZ03nmtKSy8AAADQkQilaIxK7bxSaOl97WsJpwAAAECHIZSiceJ23nL3NJUIpwAAAECHIZSiseJ7mt53X+m5pjHCKQAAANARCKXIRjzX9JZbpJe8pPx+hFMAAACgrRFKka2hIWn//uThdMMGbiUDAAAAtBFCKZpD0nC6f3+4lQzVUwAAAKAtEErRXJKGU2m6enrhhdKHP0xABQAAAFoQoRTNqTCcvvzllfd98EHp5ptDQH3FK6Th4YacIgAAAID5I5SiuQ0NSaOj0i9+EW4ls3p15f1HR6Vrr5XWrAntvVRQAQAAgKZGKEVriG8l89RTyVp7Dx0K7b1UUAEAAICmRihF6ylu7TWr/jlUUAEAAICmZO6eyRceGBjwkZGRTL422szOndK3vy3t2hXmlyZlJp1/vtTXJ119dQi7AAAAAFJhZrvdfaDqfoRStJWdO6Ubb5QeeEA6cECqZXyvXi2de660ebP0vveFlmEAAAAAc0IoBeZaQY2tXy+tW0dIBQAAAOaAUAoUmk8FNUZIBQAAABJLGkp7GnEyQObi1Xul6QrqoUNhwaSkVdT9+8Nj3zFp/0rp/OelpYul3i7pteukS9fV6eQBAACA9kWlFKilinrWy6Qt2yWLFq4uXPl3aZ/0on4pl5fOWiL96R9KG5fX99wBAACAJkWlFEiqVBV1dFR6/PHZIfXFr5JkpW9Dc3wiPCTp0Jj066elFQulhT0EVQAAAKAMQilQaHBw5lzR4pB66LdSPhdCaZL7ox45Of1xHFRXLpJ6TOruIqwCAACg4xFKgUpKhdS7fin1vUya6pemXHr2RG3HLN6fsAoAAIAORigFalEcUiVp31Hpx/8nPfNCCJQnJ6Ujp2o/drWwuqQvbJ/Ks7ASAAAA2gahFJivjculrUXzt4uD6u/Hp+eb1up0WB2b3rb/IenOPdMLK1FdBQAAQIsilAL1UCqo3ntAuu9AqHTGQXI+YbVwYaVYuVbg7i5uXQMAAICmRCgFGuXSMoEw7bAqlZ/nWq7CuqRPWrNUungtVVYAAAA0FKEUyFrSsLqkTzo5JR08Pr+vV6rCqjFp71HpngPSyoVST9fMKiutwQAAAKgTQinQrMqF1eL5qmlVV2PPniy9/XRrcJnQSrUVAAAAc0AoBVpNqfmqsVKtwLn83G5dU0650FpYbV2+QDpzYdj8wgRzWwEAAFAWoRRoJ+Wqq1L5CmvaoVWSjp4Kj3LKzW2l6goAANBxCKVAp6hUYZXKV1nTbA0uVHJua6yo6rqod3ZolaarsFRfAQAAWhahFEBQqcoqVQ6tJyelIxUqo/NRsuo6Nnu/atVXqrAAAABNiVAKIJlqoXXfUWnXk9Kh46GCWVzNrEebcLGK1ddYmSpsqfNl5WEAAIC6I5QCSMfG5clCW6W5rfWuuhabUYUtUX2NxSsPr1gQWoV7uitXY2kpBgAASIxQCqCxqs1tlWZXXUu14ErhvXpXXwvVGpb3PyTteFT6gyWSSRor8W+hKgsAADocoRRA80ladY1Vq75mUYWNvTApvXA0+f6FVdmeLqm3TFW2XLsxFVoAANBiCKUAWl+S6musXBW2XMirx8rDSVQNzxXajeMK7ZJ+yfPJ2o2LA+/ivrBoFAtCAQCAOiOUAugstVZhpcorD5d6bmRLcTkvTIbHnBQE3nsOSMv6pYW9knvyYEtbMgAASIhQCgDVVFt5uJTCluJKK/s2Q1W2mufHw2M+4rbkM/qlhT1S3su3Jid5pk0ZAIC2Ye6eyRceGBjwkZGRTL42ADStpFXZLG6504wW90orF4WFpE5O1t6qTEUXAIC6MbPd7l51jhWVUgBoJnOpyhZKuuhTteeDx9P7N9XT2KQ0diy948UV3bMWSQt6pROToaKbn0fQJfgCAFARoRQA2kktiz5VUu22PLU8Z7Hq8Xw9XceK8+lW5r4wVzfnoR05P485u6zGDABoYYRSAMBsc1kQqpK0Krjt1KZ8bCI8UlFlNeY7HpWW9ko5hVsN1bIqc9I50QRhAMAcMacUANB65rKQVLXnZl1oqlUt6p0Owr1doQU6DsJpfc8IwgDQ1JLOKSWUAgAQixea6u0Kr9MKTa3cytxKFvVKZy6UuizMB+4pCsNptkcv6ZPWLOVevgBQAQsdAQBQq/kuNJVEmq3MrMY804nJ8EhdqfboMWnv0XAv36V90oIeySX1WJgnnDQQz6dqTDAG0CYIpQAANFJai1ElkUYAriU0dWIQlkLb95xbvyvMB07yuXEwPqMv3AN4SuF7ZpJOTMy/SlxtPNA6DSAFtO8CAID0JAnCac4p7dQg3GwW9YTva17T1eKkq0qnMR641RLQlGjfBQAAjdfISnCsHgtfVQpNzA2e7cRUeMzJfKrFkfhWS8v6Q3U4Dsanq8aT9W2Xp6UamBcqpQAAALVK616+cw3RBOPmd0Z/aKlu1BxjgjGaEJVSAACAekn7Xr5zUS4Y16NaXOrYtE5Xdmw8PGqSQtW4cK7xi/qkZQskS3lF6iRjjZZq1IBQCgAA0IqaJRg3cjGtUs/cY7i830+ER91UCNGFLdXdXVKvhYW4CoNxvs5zzlmMq2XQvgsAAIDWdu+BcI/hqXx9A06lY9JS3dwW9YT7GJuF+c+9UTjuLhOO6/FHlQ6sHtO+CwAAgM7QiHsMJzHfucbzDdEE4/JOTEknjtfhwDW0XBdXj3tMyql89bjaeGijKjChFAAAAEhDs7RUFwbjRs0xpqU6ueeTzjVOEHj3PxSeWzyYEkoBAACAdtEMwVgq31Jd72px4XOnLMb1wFOEUgAAAACYoZlaqht5H+MsFuS6cE19jttAhFIAAAAA7Wnjcmlr1XV2GqPW6jFzSgEAAAAAqWmW6nET6sr6BAAAAAAAnYtQCgAAAADIDKEUAAAAAJAZQikAAAAAIDOEUgAAAABAZgilAAAAAIDMEEoBAAAAAJkhlAIAAAAAMkMoBQAAAABkJlEoNbPLzGyPme01s+sr7PdOM3MzG0jvFAEAAAAA7apqKDWzbklfkfR2SZslvcfMNpfYb6mkT0i6P+2TBAAAAAC0pySV0osk7XX3fe4+Iek2SVeU2O/vJW2XdCrF8wMAAAAAtLEkofRsSU8UvH4y2naamb1G0jnu/h+VDmRmQ2Y2YmYjhw8frvlkAQAAAADtZd4LHZlZl6QvSvpktX3dfdjdB9x9YNWqVfP90gAAAACAFpcklB6UdE7B67XRtthSSa+U9N9mtl/SJZJ2sNgRAAAAAKCaJKH0V5I2mdkGM+uTdJWkHfGb7n7M3Ve6+3p3Xy9pl6TL3X2kLmcMAAAAAGgbPdV2cPcpM/uYpLskdUv6urs/bGafkzTi7jsqH6G03bt3P2tmj8/lcxtopaRnsz4JNCXGBsphbKASxgfKYWygEsYHymn2sfGSJDuZu9f7RFqWmY24O23ImIWxgXIYG6iE8YFyGBuohPGBctplbMx7oSMAAAAAAOaKUAoAAAAAyAyhtLLhrE8ATYuxgXIYG6iE8YFyGBuohPGBctpibDCnFAAAAACQGSqlAAAAAIDMEEoBAAAAAJkhlJZgZpeZ2R4z22tm12d9PmgsMzvHzH5qZqNm9rCZfSLavsLM7jazx6Ln5dF2M7N/isbLb8zsNdn+C1BvZtZtZg+Y2b9HrzeY2f3RGPiemfVF2/uj13uj99dned6oPzNbZma3m9mjZvaImQ1y7YAkmdnfRD9Tfmtm3zWzBVw7OpeZfd3MnjGz3xZsq/laYWbvj/Z/zMzen8W/BekqMza+EP1c+Y2Z/dDMlhW8d0M0NvaY2dsKtrdUniGUFjGzbklfkfR2SZslvcfMNmd7VmiwKUmfdPfNki6R9NFoDFwv6SfuvknST6LXUhgrm6LHkKSbGn/KaLBPSHqk4PV2SV9y95dKOirp6mj71ZKORtu/FO2H9vaPkv7T3V8m6XyFccK1o8OZ2dmSPi5pwN1fKalb0lXi2tHJvinpsqJtNV0rzGyFpM9KuljSRZI+GwdZtLRvavbYuFvSK9391ZL+V9INkhT9fnqVpFdEn/PV6A/nLZdnCKWzXSRpr7vvc/cJSbdJuiLjc0IDuftT7v4/0cfHFX6pPFthHHwr2u1bkrZEH18h6dse7JK0zMzWNPi00SBmtlbSn0u6NXptkt4s6fZol+KxEY+Z2yW9JdofbcjMzpD0BklfkyR3n3D358W1A0GPpIVm1iNpkaSnxLWjY7n7zyUdKdpc67XibZLudvcj7n5UIbgUhxm0mFJjw91/7O5T0ctdktZGH18h6TZ3H3f330naq5BlWi7PEEpnO1vSEwWvn4y2oQNFLVMXSrpf0lnu/lT01iFJZ0UfM2Y6y5clbZOUj16fKen5gh8Whd//02Mjev9YtD/a0wZJhyV9I2rvvtXMFotrR8dz94OS/kHSAYUwekzSbnHtwEy1Xiu4hnSmD0n6UfRx24wNQilQhpktkfSvkv7a3X9f+J6HeylxP6UOY2bvkPSMu+/O+lzQlHokvUbSTe5+oaQxTbffSeLa0amilsorFP5w8WJJi0VFCxVwrUApZvYZhWlm38n6XNJGKJ3toKRzCl6vjbahg5hZr0Ig/Y67/yDa/HTcWhc9PxNtZ8x0jtdJutzM9iu0wrxZYQ7hsqglT5r5/T89NqL3z5D0XCNPGA31pKQn3f3+6PXtCiGVawf+RNLv3P2wu09K+oHC9YRrBwrVeq3gGtJBzOwDkt4h6b3RHy2kNhobhNLZfiVpU7QiXp/C5OEdGZ8TGiiat/M1SY+4+xcL3tohKV7Z7v2S/q1g+/ui1fEukXSsoP0GbcTdb3D3te6+XuHa8F/u/l5JP5X0rmi34rERj5l3Rfvzl+825e6HJD1hZudFm94iaVRcOxDadi8xs0XRz5h4bHDtQKFarxV3SXqrmS2PqvFvjbahzZjZZQpThy539xMFb+2QdFW0YvcGhcWwfqkWzDPGNW42M/szhXlj3ZK+7u6fz/iU0EBmdqmkeyQ9pOl5g3+rMK/0+5LWSXpc0l+4+5HoF4x/VmjFOiHpg+4+0vATR0OZ2Zskfcrd32FmGxUqpyskPSDpL9193MwWSPoXhXnJRyRd5e77sjpn1J+ZXaCwCFafpH2SPqjwB2CuHR3OzP5O0rsVWu8ekHSNwhwvrh0dyMy+K+lNklZKelphFd07VOO1wsw+pPA7iiR93t2/0ch/B9JXZmzcIKlf0x0Tu9x9a7T/ZxTmmU4pTDn7UbS9pfIMoRQAAAAAkBnadwEAAAAAmSGUAgAAAAAyQygFAAAAAGSGUAoAAAAAyAyhFAAAAACQGUIpAAAAACAzhFIAAAAAQGb+H43VJMhc831EAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = len(run_hist_1.history[\"loss\"])\n",
    "m = len(run_hist_1b.history['loss'])\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"loss\"], 'hotpink', marker='.', label=\"Train Loss - Run 2\")\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"val_loss\"], 'LightSkyBlue', marker='.',  label=\"Validation Loss - Run 2\")\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this graph begins where the other left off.  While the training loss is still going down, it looks like the validation loss has stabilized (or even gotten worse!).  This suggests that our network will not benefit from further training.  What is the appropriate number of epochs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "Now it's your turn.  Do the following in the cells below:\n",
    "- Build a model with two hidden layers, each with 6 nodes\n",
    "- Use the \"relu\" activation function for the hidden layers, and \"sigmoid\" for the final layer\n",
    "- Use a learning rate of .003 and train for 1500 epochs\n",
    "- Graph the trajectory of the loss functions, accuracy on both train and test set\n",
    "- Plot the roc curve for the predictions\n",
    "\n",
    "Experiment with different learning rates, numbers of epochs, and network structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Type your code here to with layer 1,2 having activation relu and layer 3 with activation sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(6, input_shape = (8,), activation = 'relu'))\n",
    "model.add(Dense(6, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(SGD(lr = .003), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 6)                 54        \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 6)                 42        \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 103\n",
      "Trainable params: 103\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1500, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Type your code here to plot the loss accuracy and ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "figures, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "axes[0].plot(np.log(history.history[\"loss\"]),'r', marker='.', label=\"Train log(loss)\")\n",
    "axes[0].plot(np.log(history.history[\"val_loss\"]),'b', marker='.', label=\"Validation log(loss)\")\n",
    "axes[0].legend()\n",
    "axes[1].plot(history.history[\"acc\"],'r', marker='.', label=\"Train acc\")\n",
    "axes[1].plot(history.history[\"val_acc\"],'b', marker='.', label=\"Validation acc\")\n",
    "axes[1].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
